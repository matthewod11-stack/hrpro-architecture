# ENSURING ADA COMPLIANCE IN AI HIRING: REVIEW, ANALYSIS, AND DISABILITY DISCRIMINATION FRAMEWORK

# by

# STEPHEN FABEYO

## M.S., Eastern University, Pennsylvania, 2022

## A Research Proposal Submitted to the School of Computing Faculty of

# Middle Georgia State University in

## Partial Fulfillment of the Requirements for the Degree

## DOCTOR OF SCIENCE IN INFORMATION TECHNOLOGY

# MACON, GEORGIA

2025

1

Ensuring ADA compliance in AI hiring: Review, analysis, and disability discrimination framework

## Stephen Fabeyo, Middle Georgia State University, stephen.fabeyo@mga.edu

# Abstract

Artificial intelligence (AI) is revolutionizing hiring processes through the use of automated tools, including resume screening algorithms, video interviews, and scalability. However, these technologies often fail individuals, who already face disproportionately high unemployment rates. Thi s results in potential non - compliance with the Americans with Disa bilities Act (ADA), which mandates equal opportunit ies and reasonable accommodations in employment. The opacity of AI algorithms, often described as a “black box,” exacerbates challenges in detecting and correcting bias. This study uses a systematic review methodology to analyze existing literature, case studies, and regulatory frameworks, evaluating the alignment of AI hiring systems with ADA standards. Insights from this approach inform recom mendations for accessible design principles, explainable AI (XAI) technologies, bias audits, and the importance of human oversight. These findings provide a roadmap for harmonizing innovation with inclusivity , advancing policy discussions to ensure fairness, transparency, and equity in employment for individuals with disabilities.

chatbots, which offer increased efficiency and

to accommodate the diverse needs of disabled

Keywords: Artificial Intelligence (AI) in Hiring, Americans with Disabilities Act (ADA), Algorithmic Bias and Discrimination, Explainable AI (XAI), AI Ethics and Regulatory Compliance.

# Introduction

Artificial Intelligence (AI) is revolutionizing various industri redefines how companies find and select talent with tools such as algorithmic resume screening, chatbo t- led interviews, and data-driven candidate assessments promise efficiency and objectivity (Albaroudi et al., 2024; Fabris et al., 2024; Hunkenschroer & Luetge, 2022; Regina, 2023; Tippins et al., 2021) . By 2025, projections indicate up to 70% of large corporations will integrate AI into their hiring workflows (Sánchez- Monedero et al., 2020). A 2023 U.S. Equal Employment Opportunity Commission survey found 83 % of employers and 99% of Fortune 500 companies utilize automated tool demonstrating the technology’s widespread adoption.

es, including the hiring process, which

s to screen or rank candidates,

In October 2023, President Biden issued an executive order mandating the development of safe, secure, and trustworthy AI systems, emphasizing principles of national security, privacy, and ethics (Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence, 20 administration later repealed this policy, its original intent highlights the importance of establishing ethical AI frameworks, even as governance approaches continue to evolve. While AI hiring tools offer efficiency, they also carry the risk of exacerbating existing biases, particularly for marginalized groups such as people with disabilities (Sonderling et al., 2022).

# 23). Although the subsequent

The Americans with Disabilities Act (ADA) prohibits employment discrimination and mandates reasonable accommodations during the hiring process to ensure fairness and equity for individuals with disabilities (Americans with Disabilities Act of 1990, as amended, n.d.). However, many AI-driven hiring tools fail to account for the diverse needs of individuals with disabilities, inadvertently introducing or amplifying bias (Figueroa-Armijos et al., 2023; Kammerer, 2022; Kelly -Lyth, 2021). These biases manifest i n multiple ways, including resume-screening algorithms that penalize employment gaps due to medical conditions, video interview software that misinterprets speech or facial expressions, and rigid assessment tools t hat

2

lack adaptive accommodations. As a result, disabled employment despite legal protections intended to ensure equity.

candidates face additional barriers to securing

Disability encompasses a broad spectrum, requiring thoughtful consideration in system design, and is the reinforcing the need for only minority status anyone can acquire through a change in circumstances, inclusive AI frameworks (Binns & Kirkham, 2021; Fuchs, 2023). Despite these pr essing concerns, the challenges disabled individuals face in navig ating AI hiring systems remain underexplored (Kelly -Lyth, 2021). Addressing this gap is crucial as AI’s role in employment continue proactive policy measures to ensure fairness, transparency, and ADA compliance in hiring practices.

s to expand, necessitating

# Problem Statements

The increasing reliance on AI -driven hiring presents both opportunities and challenges, particular disabled individuals, who require accommodations tailored to a wid physical, cognitive, sensory, and mental health disorders (Goddard et al., 2024). However, many AI systems fail to account for this diversity, resulting in systemic bias and exclusion (Egger, 2021).

# ly for

e range of conditions, including

A key issue is the “black box” nature of AI hiring tools, where opaque al gorithms make decisions without clear explanations, complicating compliance with the ADA and creating regulatory hurdles for employers and policymakers (Sánchez -Monedero et al., 2020; Tilmes, 2022). For instance, the Derek Mobley v. Workday (2024) lawsuit revealed how proprietary algorithms disproportionately exclude individuals with disabilities and other minority groups, highlighting the need for transparency and inclusivity in AI hiring.

Without systemic oversight, these technologies risk violating ADA standards and worsening unemployment disparities for disabled job seekers (Ajunwa, 2021; Kaminski, 2023). The challenge lies in striking a balance between innovation and ethical hiring practices to ensure transparency, inclusivity, and equity.

# Purpose of the Study

This study critically examines the intersection of AI hiring systems and ADA compliance, assessing the ir impact on individuals with disabilities and the need for systemic reforms analyzing case studies, and evaluating regulatory frameworks, it aims to:

. By synthesizing literature,

- Identify the risks of disability discrimination in AI hiring systems. • Examine the legal and ethical implications of AI hiring decisions. • Advocate for policy reforms and accessible AI to enhance transparency, inclusivity, and fairness.

Findings from this study provide policymakers, industry leaders, and regul atory bodies with actionable insights, guiding the development of ethical AI hiring practices that align with ADA mandates. By ensuring AI-driven recruitment systems incorporate bias auditing, explainabili research supports the broader goal of equitable employment opportunities and responsible AI adoption.

# ty, and accessibility measures, this

# Research Questions

RQ1: To what extent do AI hiring systems meet ADA requirements for r fairness in recruitment?

# easonable accommodation and

RQ2: What specific features or design flaws in AI hiring tools contribute to discriminatory outcomes against individuals with disabilities?

3

RQ3: How effective are current regulatory frameworks in addressing bias and ensuring inclusivity in AI- driven hiring practices?

RQ4: What role can emerging technologies, such as Explainable AI (XAI), promoting transparency in AI-driven hiring systems?

play in mitigating bias and

# Literature Review

# Overview of AI in Hiring Systems

The integration of AI in recruitment promises efficiency and objectivi screening, video interviews, and gamified assessments (Hocken & King, 2023; Kam merer, 2022; Sonderling et al., 2022). However, scholars argue reliance on historical data and biased algorithmic design may reinforce discrimination against marginalized groups like disabled individuals (Kaminski, 2023).

ty, using tools such as resume

A parallel trend is the increasing use of generativ to automate tasks, le this technology including resume screening, job descriptions, and candidate communication. Whi improves workflow efficiency, it raises new equity concerns —access to AI-generated job materials is unequal, and biases embedded in training data may propagate through AI -generated hiring decisions (Farrell, 2023; Marshall et al., 2024). Additionally, job descriptions generated by AI risk excluding disabled candidates if they reinforce ableist language or assumptions, potentially violating the ADA.

e AI, such as ChatGPT, in hiring

## Challenges Faced by Disabled Individuals in AI-driven Hiring

Disabled job seekers already experience higher unemployment rates (7.2% ) compared to non -disabled individuals (3.5%), and AI hiring exacerbates these disparities ( Persons with a Disability , n.d.). The literature highlights five major challenges:

- Bias in AI Resume Screening: AI algorithms often penalize employment gaps, ignoring disability- - related medical absences or caregiving responsibili Monedero et al., 2020; Vogel et al., 2024).

Inaccessible AI Video Interviews: Platforms like HireVue, which analyze facial expressions, tone, and speech patterns, unfairly disadvantage candidat (Ajunwa, 2021; Kelly-Lyth, 2021). While some companies claim to improve accessibility, there is little external validation of whether adjustments effectively mitigate bias (Sheard, 2022).

# es with physical or speech impairments

- Lack of Alternative Assessments: Many AI-driven evaluations assume a “one-size-fits-all” model, disregarding cognitive and physical limitations tha t require alternative assessments (Marshall et offer alternative al., 2024; Tilmes, 2022). Few regulatory measures require AI hiring tools to assessments, leaving it up to individual employers to implement accommodations as needed.

- Bias in Training Data: AI models trained on historically biased data continue to underrepresent individuals with disabilities, thereby reinforcing exclusion (Binns & Kirk ham, 2021; Kaminski, 2023).

Ideal Candidate Stereotypes: AI hiring tools often prioritize able-bodied profiles, forcing disabled applicants to conform to biased norms that overlook diverse competencies (Burrell & McAndrew, 2023; Sánchez-Monedero et al., 2020).

4

## ADA Compliance, Legal, and Ethical Implications

The ADA mandates reasonable accommodations and proh ibits disability-based discrimination in hiring, extending compliance requirements to AI -powered tools (Americans with Disabilities Act of 1990, as gal standards due to amended, n.d.). However, scholars argue AI hiring tools frequently violate these le opaque decision -making and lack of regulatory oversight (Paez, 2021; Sheard, 2022). The lack of transparency in AI hiring tools has significant legal and ethical impli cations as candidates and regulators struggle to challenge potentially discriminatory outcomes or hold employers accountable for violations Derek Mobley v. Workday illustrate how proprietary (Vogel et al., 2024). For example, lawsuits like algorithms disproportionately exclude individuals with disabilities, a s well as other marginalized groups, highlighting the urgent need for regulatory intervention (Derek Mobley v. Workday Inc., 2024).

To address these shortcomings, scholars advocate for the adoption of explainable AI (XAI) and independent bias audits. XAI systems enhance interpretability by explaining how hiring managers make decisi ons, promoting fairness, and enabling candidates to understand their evaluations (Hickman et al., 2024; Hofeditz et al., 2022). However, XAI has limitations in hiring contexts, as even transparent explanations cannot fully eliminate bias if the underlying training data or algorith ms are flawed (Packin, 2021). Policy developments such as Illinois’ Artificial Intelligence Video Interview Act and New York City’s Bias Audit Law represent early efforts to regulate AI hiring tools by requiring applicant consent, audits, and increased transparency (820 ILCS 42/, n.d.; NYC Bias Audit Law, n.d.). At the global level, the European Union’s Artificial Intelligence Act provides a comprehensive regulatory framework that emphasizes accountability and inclusivity, which could serve as a model for enhancing ADA compliance in the United States (AI Act, 2024). Despite these advancements, the ethical and legal challenges posed by AI hiring systems remain significant, underscoring the importance of proactive measures , such as bias audits, inclusive design, and human oversight, to ensure AI hiring practices align with legal and ethical standards.

# Gaps in the Literature

Despite growing research, critical gaps remain:

- Disability Representation: Most studies focus on gender and racial biases, wi on AI-related disability discrimination (Moss, 2021).

- Disability Representation: Most studies focus on gender and racial biases, wi on AI-related disability discrimination (Moss, 2021).

Intersectionality: There is little exploration of how overlapping identities (e.g., disabled individuals from marginalized racial groups) compound discrimination in AI hiring (Moss, 2021).

- Policy Effectiveness: Although there is advocacy for bias audits, few studies have assessed whether these audits actually reduce disability-based discrimination (Hunkenschroer & Luetge, 2022).

# Methodology

This study employs a systematic review methodology to analyze scholarly literature, case studies, industry reports, and policy documents on the impact of AI hiring systems on individuals with disabilities. Following the PRISMA guidelines (Moher et al., 2009), the review ensures rigor and transparency through a structured approach, which includes defining the scope, applying selection criteria, systematically extracting data, and synthesizing findings to address the research questions.

5

# Data Collection and Selection Criteria

The study systematically searches Google Scholar, IEEE Xplore, and PubMed to r etrieve peer-reviewed journals, books, conference papers, and policy documents. Gray literature, including government reports, industry white papers, and regulatory guidelines, is also analyzed to inc orporate real-world perspectives. Boolean search operators and keywords such as “AI hiring systems,” “disability discrimination,” and “ADA compliance” optimize retrieval. A three-phase screening process refines the selection:

- 1. Filter by publication year (2019–2025) to ensure up-to-date research. 2. Title and abstract review to determine relevance to AI hiring and disability inclusion 3. Full-text evaluation to confirm alignment with research objectives and methodological rigor.

# Table 1: Content evaluation criteria

# S/N Inclusion Criteria

# Exclusion Criteria

1

# Language of publication: English.

## Language of Publication other than English.

2

Published between 2019 and 2025.

# Duplicate articles.

3

Directly answers one or more research questions.

# Opinion pieces.

4

# Peer-reviewed publications.

# Non-peer-reviewed publications.

5

Discussed the legal and ethical implications of ADA compliance.

Does not focus on ADA compliance.

6.

# Addresses disability discrimination.

Addresses other forms of discrimination.

7

Focused on AI applications in hiring, particularly those addressing fairness, bias, and inclusivity.

Focused on AI applications outside the context of hiring or employment.

8

Included case studies demonstrating the real- world implementation of AI hiring systems.

Did not provide empirical or theoretical insights relevant to the topic of disability discrimination.

# Analytical Methods

The study applies thematic synthesis to categorize findings into three key themes:

- 1. AI’s Impact on Disability Inclusion in Hiring Pract accommodate or exclude candidates with disabilities.

ices: Examines how AI hiring systems

- 2. Ethical and Legal Challenges in AI Hiring Systems : Investigates ADA compliance, regulatory gaps, and ethical considerations.

- 3. Bias Detection and Algorithmic Accountability in AI Hiring: Identifies biases in datasets and algorithms, emphasizing transparency and fairness.

Each selected study undergoes critical appraisal for methodologic al rigor, reliability, and relevance to AI hiring, disability inclusion, and ADA compliance. The study then synthesizes findings to offer actionable insights for policymakers, employers, and AI developers, ensuring p ractical contributions to disability - inclusive hiring reforms.

6

# Analysis and Results

# Findings from the Systematic Review

## Theme 1: AI’s Impact on Disability Inclusion in Hiring Practices

The analysis demonstrates AI hiring systems frequently fail to accommodate the diverse needs of disabled candidates, resulting in systemic exclusion. Many -recognition-based assessments and automated resume screeners, inadver patterns observed include:

of these tently penalize individuals with disabilities. Key

# tools, such as facial

- Speech and Facial Recognition Bias : AI-driven video interview platforms , such as HireVue, disproportionately disadvantage candidates with speech impairments, neu rological conditions, or facial differences. The software interprets standar d social cues, such as eye contact and voice modulation, which are not always applicable to individuals with disabilities (Ajunwa, 2021).

- Resume Screening Bias:

ext, disproportionately impacting individuals who have taken medical leaves or needed extended recovery periods due to disability. The algorithms, trained on profiles of non-disabled workers or similar language, fail to consider alternative employment histories (Vogel et al., 2024).

AI algorithms penalize employment gaps without cont

- Lack of Adaptive Testing: AI hiring assessments often

employ a one -size-fits-all approach, overlooking cognitive, motor, or sensory impairments that necessitate alternative assessment methods. Many candidates struggle to fully engage with these rigorous evaluations, which can lead to exclusion (Kelly-Lyth, 2021; Regina, 2023; Timmons, 2021).

- Underrepresentation in AI Training Data : AI hiring models often train on datasets that lack reinforcing biased outcomes. The -making in ways that representation from individuals with disabilities, thereby omission of disability -related employment experiences skews decision disadvantage these candidates (Burrell & McAndrew, 2023; Sánchez-Monedero et al., 2020).

## Theme 2 - Ethical and Legal Challenges in AI Hiring Systems

AI hiring systems operate within an uncertain regulatory environment where ADA compliance is often an afterthought. Key findings:

- Opaque Decision-Making (“Black Box AI”): Many AI hiring tools lack transparency, which prevents candidates from understanding how hiring decisions occur. This opacity makes it difficult for disabled applicants to challenge rejections, leaving them without recourse (Kammerer, 2022).

- Regulatory Gaps: Current legal frameworks, such as the ADA, prohibit hiring discrimina tion but lack explicit provisions addressing AI -driven hiring systems. The lack of proactive enforcement leaves room for biased algorithms to operate unchecked (Friedman, 2022).

- Growing Litigation Risks: Cases such as Derek Mobley v. Workday Inc. (2024) underscore how AI hiring tools disproportionately exclude individuals with disabilities. The legal scrutiny surrounding AI hiring underscores the urgent need for clearer compliance standards (Egger, 2021).

7

## Theme 3: Bias Detection and Algorithmic Accountability

Addressing algorithmic bias requires proactive meas ures, yet current industry practices often fall short Major concerns include:

- Historical Data Bias: AI models trained on historical hiring data inherit past biases, p erpetuating exclusionary practices. If an organization has historically hired fewer disabled workers, the AI may deem disabled candidates as less qualified (Binns & Kirkham, 2021).

- Lack of Bias Audits: While some companies conduct bias audits, these are neither standardized nor required. Many audits fail to account for disability -specific biases, focusing instead on gender or racial fairness (Ajunwa, 2021).

- Absence of Explainable AI (XAI): Without interpretable AI models, employers struggle to identify it difficult to detect and correct biased

## Case Studies: Real-World AI Hiring Challenges and Biases

The following case studies provide concrete examples of AI hiring system s failing to ensure fairness for disabled individuals:

- Case Study 1 - Workday AI Hiring Bias Lawsuit: Workday's AI hiring tool faced allegations of disproportionately filtering out candidates with disabilities (Derek Mobley v. Workday Inc., 2024). The case highlighted a lack of transparency and accountability in AI hiring decisi ons, resulting in increased scrutiny of compliance requirements.

- Case Study 2 - HireVue Video Interview Bias: HireVue’s AI video interviews relied on facial and speech analysis, disadvantaging candidates with autism, speech disorders , or other impairments (Ajunwa, 2021). Due to regulatory and public pressure, HireVue revised its system to reduce its reliance on facial analysis, instead emphasizing structured interviews.

- Case Study 3 - Facebook’s AI Hiring Discrimination: Facebook’s AI-driven job ad targeting algorithm excluded individuals with disabilities by inferring demographic traits from user data (Jan & Dwoskin, 2019). Civil rights complaints forced the company to revise its ad targeting system to ensure compliance with anti-discrimination laws.

- Case Study 4 - Pymetrics' Bias-Free Algorithms: Pymetrics, an AI-driven hiring platform, faced oscience-based candidate assessment tools

# Discussion of Findings

The findings of this study underscore the substantial challenges AI-driven hiring systems pose for individuals with disabilities, with AI frequently replicating historical biases and failing to accommodate diverse needs. The analysis of AI hiring tools, including video interviews and resume screeners, reveals a consistent pattern of discrimination due to the limited adaptive measures and biased training data.

8

.

These findings align with previous studies, such as Ajunwa (2021) and Kaminski (2023), which highlight how opaque AI decision-making processes disproportionately affect marginalized job seekers. Similarly, case studies such as Derek Mobley v. Workday Inc. (2024) and HireVue’s AI interview modifications illustrate the tangible consequences of deploying biased hiring tools (Ajunwa, 2021). However, this study extends the discussion by integrating emerging policy interventions, such as New York City’s Bias Audit Law, and global regulatory frameworks like the European Union’s AI Act (2024).

A key implication of these results is the need for Explainable AI (XAI) technologies to ensure transparency in AI-driven hiring. Previous research (Hickman et al., 2024; Hofeditz et al., 2022) emphasizes AI models must offer interpretability for candidates and regulators to understand hiring decisions. Additionally, bias audits, as suggested by Binns and Kirkham (2021), should become a standardized practice to mitigate discriminatory outcomes. By contextualizing these findings within the existing literature and emerging legal frameworks, this study contributes to the ongoing discussion on the ethical application of AI in hiring.

# Implications of Findings

The findings of this study underscore the critical need for a comprehensive policy framework that ensures ADA compliance and promotes the inclusion of people with disabilities within AI-driven hiring systems. This study proposes an implementation framework for AI hiring t structured approach for policymakers, employers, and AI developers to enhance fairness, mitigate bias, and promote inclusi ve hiring practices. The framework advocates for adaptive assessment meth ods and enhanced transparency in AI decision-making to create equitable employment opportunities for individuals with disabilities. The table below outlines the framework, detailing key issues, recommended interventions, and their anticipated impact on fostering equitable hiring processes.

o tackle these challenges, offering a

## Table 2: AI-driven Hiring Compliance and Fairness Framework

# Category

# Key Issue

# Recommendation

# Expected Impact

# Transparency & Accountability

## Opaque AI decision- making (“Black Box AI”).

# Algorithmic Transparency: Require disclosure of decision- making criteria through public transparency portals.

Enables candidates, employers, and regulators to understand AI decisions.

# No interpretability in AI hiring tools.

Explainable AI (XAI) Models: Mandate interpretable models to provide clear explanations for decisions.

Reduces bias and increases trust in AI hiring systems.

# Lack of audit trails for AI decisions.

Audit Trails: Ensure traceability with detailed records of AI hiring decisions.

## Enhances compliance and reduces litigation risks.

# Inclusive Design & Accessibility

AI hiring tools lack design features that promote inclusivity.

Inclusive Design Protocols: Enforce designs that accommodate diverse disabilities.

# Ensures equal access for all candidates.

## No alternative assessment methods for candidates with disabilities.

Alternative Assessments: Offer flexible testing methods to accommodate diverse needs.

## Reduce exclusion of disabled job seekers.

9

# Bias Detection & Mitigation

# Data Diversity & Representation

# Behavioral & Contextual Data Integration

# Regulatory Compliance & Standards

# Stakeholder Collaboration

# Legal Recourse & Remedies

AI amplifies historical hiring biases.

No standardized method for detecting AI bias.

## AI training data lacks disability representation.

AI fails to consider intersectionality.

AI lacks nuanced evaluation methods.

AI hiring operates without clear legal guidelines.

## No comprehensive AI diversity impact assessments.

## No certification process for ethical AI tools.

AI hiring discrimination lacks compensation measures.

AI hiring is developed without input from disabled individuals.

# Lack of human oversight in AI hiring.

No mechanisms for candidates to report AI biases.

No legal pathways for AI hiring discrimination.

# Real-Time Bias Monitoring: Continuously assess AI’s impact on diverse demographic groups

# Regular Bias Audits: Conduct independent audits with publicly available findings.

Diverse Training Data: Ensure datasets reflect all demographic groups, including individuals with disabilities.

Intersectional Analysis: Address compounded biases across multiple demographic factors.

Behavioral and Contextual Data Integration: Incorporate behavioral and contextual data to ensure fairer evaluations and recognize individual accommodations.

## National Standards: Develop enforceable ADA-compliant standards for AI systems.

## Diversity Impact Assessments: Evaluating AI’s Impact on Underrepresented Groups.

Ethical Certification: Certify AI tools based on inclusivity, transparency, and fairness.

AI Bias Compensation Fund: Establish a fund to support individuals affected by AI discrimination.

Collaborative Development: Engage developers, employers, individuals with disabilities, and advocates in the design of AI.

## Human-AI Collaboration: Ensure Human Oversight in Nuanced Hiring Decisions.

Candidate Feedback: Implement mechanisms for candidates to report perceived biases.

Complaint Mechanisms: Develop clear pathways for

10

## Enables early detection and correction of bias.

# Promotes accountability and compliance.

Reduces underrepresentation and biased outcomes.

Improves fairness for individuals with overlapping identities.

Enhances AI's ability to assess candidates equitably.

## Strengthens legal accountability for AI- driven hiring.

# Supports data-driven policy decisions.

# Encourages responsible AI development.

## Provides restitution to victims of biased AI hiring.

Ensures hiring tools reflect diverse perspectives.

Reduces automated bias and improves fairness.

Strengthens fairness and allows affected candidates to seek redress.

Improves access to justice for affected individuals.

reporting discriminatory AI decisions.

Candidates struggle to challenge biased AI decisions.

Legal Support: Provide resources for individuals seeking redress under the ADA.

Enhances candidates’ ability to fight AI discrimination.

# Continuous Improvement

AI hiring bias evolves with technology.

Ongoing Research: Invest in developing advanced, fair AI models.

Keeps hiring systems adaptable and inclusive.

## No industry-wide knowledge-sharing on ethical AI use

Best Practices Sharing: Facilitate the exchange of successful strategies in ethical AI use.

Helps employers and regulators adopt best AI hiring practices.

# Education & Training

Developers lack awareness of AI bias risks.

## Developer Training: Educate developers on bias mitigation and ADA compliance.

## Encourages responsible AI system development.

Employers are unaware of ethical AI hiring risks.

Privacy Safeguards: Protect candidates’ privacy rights through secure data handling.

## Ensures responsible AI adoption in organizations.

# Privacy & Oversight

AI hiring tools collect excessive candidate data.

Privacy Safeguards: Protect candidates’ privacy rights through secure data handling.

## Prevents misuse of candidate information.

No independent oversight for AI hiring systems.

## Oversight Committees: Monitor AI systems with ethical review boards.

## Enhances accountability and fairness in AI hiring.

## Conclusion, Limitations of the Study, and Recommendations for Future Research

This study underscores the urgent need to align AI -driven hiring practices with ADA compliance by addressing systemic biases and promoting inclusive design. The research reveals how AI hiring tools gorithmic bias, opaque decision - disproportionately disadvantage individuals with disabilities due to al making processes, and inadequate accessibility measures. Through the analysis of existing literature, case studies, and regulatory frameworks, this study underscores the necessity for stronger policy interventions, including mandatory bias audits, Explainable AI (XAI), and human oversight in AI hiring processes.

The findings underscore the significance of ethical AI development in emp loyment, drawing on existing literature (e.g., Kaminski, 2023; Marshall et al., 2024; Vogel et al., 2023). The study reveals the legal risks and ethical challenges organizations encounter when deploying AI without sufficient safeguards. It connects ategies for legal frameworks, techn ological advancements, and disability rights advocacy to propose str reducing bias, promoting fair hiring practices, and emphasizing the need for regulatory oversight in AI hiring systems.

bility discrimination, it has While this study provides valuable insights into AI hiring systems and disa limitations. It relies on publicly available data and case studies, restricting direct analysis of proprietary AI algorithms. Access to confidential hi ring software would enable a more precise understanding of bias. Additionally, the focus on U.S. regulations, particularly the ADA, limit s its geographical relevance. is needed to ass ess AI hiring Although it compares findings with the EU’s AI Act (2024), more research biases in different legal and cultural contexts. The rapid evolution of AI technology also poses challenges

11

for maintaining current findings, as new tools may introduce unforeseen biases or require new mitigation strategies. Future research should address the following key areas to strengthen the field of AI in hiring:

- 1. Comparative Cross-Cultural Analysis: Expanding research beyond the U.S. to examine AI hiring regulations and biases in various global regions can provide valuable insights into best practices for mitigating discrimination.

- 2. Longitudinal Studies on AI Hiring: Investigating the long-term effects of AI-driven hiring on the career mobility and workplace integration of individuals with disabilities as job seekers can provide a deeper understanding of AI’s impact on employment equity.

- 3. Intersectionality in AI Bias Mitigation: Future research should explore how AI hiring tools affect individuals with multiple marginalized identities (e.g., disabled women of color) to develop more comprehensive fairness models.

By addressing these areas, future studies can help bridge existing researc development of fairer, more inclusive AI hiring systems.

# h gaps and contribute to the

# References

820 ILCS 42/—Artificial Intelligence Video Interview Act. (n.d.). Retrieved January 18, 2025, from

## https://www.ilga.gov/legislation/ilcs/ilcs3.asp?ActID=4015&ChapterID=68

AI Act | Shaping Europe’s digital future. (2024, December 12). https://digital-

## strategy.ec.europa.eu/en/policies/regulatory-framework-ai

Americans with Disabilities Act of 1990, 42 U.S.C. § 12101 et seq. (1990). ADA.Gov. Retrieved June 8,

## 2024, from https://www.ada.gov/law-and-regs/ada/

Ajunwa, I. (2021). An auditing imperative for automated hiring systems. Harvard Journal of Law &

Technology, 34(2), 621–699.

Ajunwa, I. (2021). Automated video interviewing as the new phrenology. Berkeley Technology Law

Journal, 36(3), 1173–1225. https://doi.org/10.15779/Z38RX93F1Q

Albaroudi, E., Mansouri, T., & Alameer, A. (2024). A comprehensive review of AI techniques for

addressing algorithmic bias in job hiring. AI, 5(1), 383–404. https://doi.org/10.3390/ai5010019

Binns, R., & Kirkham, R. (2021). How could equality and data protection law shape AI fairness for people with disabilities? ACM Transactions on Accessible Computing, 14(3), 1–32. https://doi.org/10.1145/3473673

Burrell, D. N., & McAndrew, I. (2023). Exploring the ethical dynamics of the use of artificial intelligence (AI) in hiring in healthcare organizations. Bialystok Legal Studies / Bialostockie Studia Prawnicze, 28(4), 309–321. https://doi.org/10.2478/raft-2023-0037

Derek Mobley v. Workday Inc. (2024). Findlaw. Retrieved from https://caselaw.findlaw.com/court/us-dis-

crt-n-d-cal/116378658.html

Egger, K. E. (2021). Artificial intelligence in the workplace: Exploring liability under the Americans with

Disabilities Act and regulatory solutions. Washburn Law Journal, 60(3), 527–559.

12

Fabris, A., Baranowska, N., Dennis, M. J., Graus, D., Hacker, P., Saldivar, J., Zuiderveen Borgesius, F., &

Biega, A. J. (2024). Fairness and bias in algorithmic hiring: A multidisciplinary survey. ACM Transactions on Intelligent Systems and Technology, 3696457. https://doi.org/10.1145/3696457

Farrell, K. (2023). Future regulation of AI and employment law considerations. Employee Relations Law

Journal, 49(2), 52–55.

Figueroa-Armijos, M., Clark, B. B., & da Motta Veiga, S. P. (2023). Ethical perceptions of AI in hiring

and organizational trust: The role of performance expectancy and social influence. Journal of Business Ethics, 186(1), 179–197. https://doi.org/10.1007/s10551-022-05166-2

Friedman, G. D. (2022). New York City imposes stringent requirements on use of artificial intelligence in

workplace hiring and promotions. Employee Relations Law Journal, 48(1), 43–46.

Fuchs, L. (2023). Hired by a machine: Can a New York City law enforce algorithmic fairness in hiring

## practices? Fordham Journal of Corporate & Financial Law, 28(1), 185–222.

Goddard, K. S., Kurth, N. K., Hall, J. P., Koon, L. M., Moore, C. L., & Dentleegrand, K. R. (2024).

Strategic insights from a Delphi study: Enhancing employment for multiply marginalized people with disabilities. Frontiers in Rehabilitation Sciences, 1–11. https://doi.org/10.3389/fresc.2024.1443302

Hickman, L., Huynh, C., Gass, J., Booth, B., Kuruzovich, J., & Tay, L. (2024). Whither bias goes, I will go: An integrative, systematic review of algorithmic bias mitigation. Journal of Applied Psychology. https://doi.org/10.1037/apl0001255

Hocken, E., & King, G. (2023). AI in the hiring process. Strategic HR Review, 22(3), 81–84.

https://doi.org/10.1108/SHR-03-2023-0014

Hofeditz, L., Clausen, S., Rieß, A., Mirbabaie, M., & Stieglitz, S. (2022). Applying XAI to an AI-based

system for candidate management to mitigate bias and discrimination in hiring. Electronic Markets, 32(4), 2207–2233. https://doi.org/10.1007/s12525-022-00600-9

Hunkenschroer, A. L., & Luetge, C. (2022). Ethics of AI-enabled recruiting and selection: A review and research agenda. Journal of Business Ethics, 178(4), 977–1007. https://doi.org/10.1007/s10551- 022-05049-6

Jan, T., & Dwoskin, E. (2019, March 19). Facebook agrees to dismantle targeted system for job and

housing ads after discrimination complaints. Los Angeles Times. https://www.latimes.com/business/la-fi-tn-facebook-discrimination-ads-20190319-story.html

Kaminski, M. E. (2023). Regulating the risks of AI. Boston University Law Review, 103(5), 1347–1411.

Kammerer, B. (2022). Hired by a robot: The legal implications of artificial intelligence video interviews

and advocating for greater protection of job applicants. Iowa Law Review, 107(2), 817–849.

Kelly-Lyth, A. (2021). Challenging biased hiring algorithms. Oxford Journal of Legal Studies, 41(4),

899–928. https://doi.org/10.1093/ojls/gqab006

Marshall, R. C., Plowman, J. N. W., Linnabary, M. P. F., & Ogunro, A. A. (2024). Artificial intelligence

and employment law. Employee Relations Law Journal, 50(1), 27–33.

Moher, D., Liberati, A., Tetzlaff, J., & Altman, D. G. (2009). Preferred reporting items for systematic reviews and meta-analyses: The PRISMA statement. PLoS Medicine, 6(7), e1000097. https://doi.org/10.1016/j.jclinepi.2009.06.005

13

Moss, H. (2021). Screened out onscreen: Disability discrimination, hiring bias, and artificial intelligence.

## SSRN Electronic Journal. https://doi.org/10.2139/ssrn.3906300

Packin, N. G. (2021). Disability discrimination using AI systems, social media, and digital platforms: Can

we disable digital bias? Journal of International and Comparative Law, 8(2), 487–511. https://doi.org/10.2139/ssrn.3724556

# Páez, A. (2021). Negligent algorithmic discrimination (SSRN Scholarly Paper No. 3765778). Social

## Science Research Network. https://doi.org/10.2139/ssrn.3765778

Persons with a Disability: Labor Force Characteristics Summary - 2023 A01 Results. (n.d.). Bureau of

# Labor Statistics. Retrieved January 18, 2025, from https://www.bls.gov/news.release/disabl.nr0.htm

Regina, G. (2023). Do you even know me?: AI and its discriminatory effects in the hiring process.

# Hofstra Law Review, 51(4), 8.

Safe, secure, and trustworthy development and use of artificial intelligence. (2023, November 1). Federal

# Register. https://www.federalregister.gov/documents/2023/11/01/2023-24283/safe-secure-and- trustworthy-development-and-use-of-artificial-intelligence

Sánchez-Monedero, J., Dencik, L., & Edwards, L. (2020). What does it mean to “solve” the problem of

discrimination in hiring? Social, technical and legal perspectives from the UK on automated hiring systems. Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 458–468. https://doi.org/10.1145/3351095.3372849

Sheard, N. (2022). Employment discrimination by algorithm: Can anyone be held accountable?

# University of New South Wales Law Journal, 45(2), 617–648. https://doi.org/10.53637/xtqy4027

Sonderling, K. E., Kelley, B. J., & Casimir, L. (2022). The promise and the peril: Artificial intelligence

and employment discrimination. University of Miami Law Review, 77, 1–87.

The New York City Council—File #: Int 1894-2020. (n.d.). Retrieved June 11, 2024, from

# https://legistar.council.nyc.gov/LegislationDetail.aspx?ID=4344524&GUID=B051915D-A9AC- 451E-81F8-6596032FA3F9

Tilmes, N. (2022). Disability, fairness, and algorithmic bias in AI recruitment. Ethics & Information

Technology, 24(2), 1–15. https://doi.org/10.1007/s10676-022-09633-2

Timmons, K. C. (2021). Pre-Employment Personality Tests, Algorithmic Bias, and the Americans with

## Disabilities Act. Penn State Law Review, 125(2), 389–452.

Tippins, N., Oswald, F., & McPhail, S. M. (2021). Scientific, legal, and ethical concerns about AI-based personnel selection tools: A call to action. Personnel Assessment and Decisions, 7(2). https://doi.org/10.25035/pad.2021.02.001

U.S. Equal Employment Opportunity Commission. (n.d.). Navigating employment discrimination: AI and automated systems – A new frontier [Meeting transcript]. Retrieved February 2, 2025, from https://www.eeoc.gov/meetings/meeting-january-31-2023-navigating-employment- discrimination-ai-and-automated-systems-new/transcript

Vogel, M., Chertoff, M., Wiley, J., & Kahn, R. (2023). Is your use of AI violating the law? An overview of the current legal landscape. New York University Journal of Legislation & Public Policy, 26, 1029.

14