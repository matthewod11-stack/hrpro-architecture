# **Building your first human-AI team: lessons from Google DeepMind\'s crystal discovery**

![Geoff Gibbins](media/image4.jpg){width="0.5in" height="0.5in"}

## **[Geoff Gibbins]{.underline}** 

Human-AI expert \| Managing Director at BOI \| Author

September 9, 2025

In November 2023, Google DeepMind announced a breakthrough that should
fundamentally change how you think about human-AI collaboration. Their
Graph Networks for Materials Exploration discovered 2.2 million new
crystal structures, equivalent to 800 years of traditional research.
Within weeks, external laboratories had synthesized 736 of these
predicted materials.

This wasn\'t AI replacing scientists. It was a new form of collaboration
where human creativity and scientific understanding combined with AI\'s
pattern recognition to achieve something neither could accomplish alone.
The humans designed the questions, selected algorithms, and validated
findings. The AI explored vast possibility spaces humans could never
traverse manually.

Most organizations approaching AI implementation miss this crucial
distinction.

They focus on automation or augmentation when they should be building
true human-AI teams. The difference determines whether you achieve
incremental improvements or breakthrough transformations.

### **Stage 1: Mapping complementary capabilities**

The first mistake organizations make is assuming AI should replicate
human work. DeepMind succeeded because they identified what each party
did best. Humans excel at formulating research questions, understanding
context, and recognizing significance. AI excels at pattern recognition
across vast datasets, consistent application of rules, and rapid
generation of possibilities.

Start by mapping your team\'s work into three categories:

1.  Human advantage zones: These include ethical reasoning, contextual
    > judgment incorporating organizational values, causal understanding
    > of why relationships exist, and creative problem-solving that
    > transcends existing patterns. A pharmaceutical research team found
    > their chemists\' understanding of synthesizability and side
    > effects couldn\'t be captured in training data. This human insight
    > proved essential for filtering AI-generated drug candidates.

2.  AI advantage zones: These encompass pattern recognition across large
    > datasets, consistent application of defined criteria without
    > fatigue, rapid generation of multiple options, and processing vast
    > information volumes. The same pharmaceutical team used AI to
    > screen thousands of molecular structures in hours rather than
    > months.

3.  Collaboration zones: These are areas where neither humans nor AI
    > alone are sufficient. Complex decision-making requiring both
    > pattern recognition and contextual judgment falls here. Strategic
    > planning that needs both data analysis and stakeholder
    > understanding belongs in this category.

### **Stage 2: Designing interaction protocols**

Once you\'ve mapped capabilities, you need to design how humans and AI
will actually work together. This isn\'t about installing software and
training people to use it. It\'s about creating new collaborative
workflows that leverage the strengths you\'ve identified.

Consider the spectrum of collaboration models:

-   Human-in-the-loop works for high-stakes decisions where AI generates
    > recommendations but humans retain veto power. A medical diagnosis
    > team might use this model, with AI suggesting possibilities but
    > physicians making final determinations.

-   AI-in-the-loop suits creative or strategic work where humans lead
    > but consult AI for specific insights. Marketing teams developing
    > campaigns might use AI to analyze consumer data or generate
    > headline variations while maintaining creative control.

-   Human-on-the-loop fits moderate-risk, high-volume operations where
    > AI handles routine cases independently while escalating
    > exceptions. Content moderation teams use this model effectively,
    > with AI managing clear policy violations while humans handle
    > nuanced cases.

The key is matching the model to the risk profile and complexity of the
work. Don\'t default to one approach for everything.

### **Stage 3: Establishing evaluation frameworks**

Here\'s where most human-AI team implementations fail: they don\'t
establish clear frameworks for evaluating outputs from both humans and
AI. Without systematic evaluation, you can\'t identify when the
collaboration is working versus when it\'s creating risk.

This evaluation must be multidirectional. Humans evaluate AI outputs for
accuracy, relevance, and potential bias. But AI should also analyze
patterns in human decisions to identify potential blind spots or
inconsistencies. And crucially, you need to evaluate the collaboration
itself, not just individual components.

A financial advisory firm implemented this multidirectional evaluation
by having AI analyze patterns in advisor recommendations while advisors
assessed AI-generated insights. They discovered advisors consistently
underweighted certain risk factors while the AI missed crucial
contextual information about client life circumstances. By identifying
these complementary blind spots, they designed workflows that
compensated for both.

### **Stage 4: Creating feedback loops**

Static human-AI teams quickly become obsolete as both technology and
business needs evolve. You need deliberate feedback mechanisms that
enable continuous improvement of the collaboration.

This means tracking not just outcomes but the process of collaboration
itself. Which types of prompts generate the most useful AI outputs?
Where does human intervention most improve AI recommendations? When does
AI assistance actually diminish human performance by creating
overreliance?

A legal firm discovered through systematic tracking that junior
associates using AI for research became better at identifying relevant
precedents but worse at constructing novel arguments. They adjusted
their workflow to use AI for discovery but required human-only sessions
for strategy development.

### **Stage 5: Scaling successful patterns**

The temptation is to immediately scale successful human-AI collaboration
across the entire organization. Resist this urge. Different teams,
different types of work, and different risk profiles require different
collaboration models.

Instead, identify patterns from your pilot that can be adapted rather
than replicated. If your pilot team succeeded through iterative
refinement with AI, that practice might transfer even if the specific
workflow doesn\'t. If clear role definition proved crucial, focus on
that element when expanding to new teams.

A manufacturing company learned this lesson when their successful AI
collaboration in quality control didn\'t translate directly to supply
chain management. But the principle of using AI for anomaly detection
while relying on humans for causal analysis proved valuable across both
domains.

### **The competitive advantage of true collaboration**

McKinsey found that inefficient decision-making costs Fortune 500
companies 530,000 days of managers\' time annually, equivalent to \$250
million in wages (De Smet et al., 2019). Organizations building
effective human-AI teams report dramatic improvements in both decision
speed and quality.

But the real advantage isn\'t efficiency. It\'s the ability to achieve
outcomes neither humans nor AI could accomplish independently. DeepMind
didn\'t just accelerate materials research. They discovered crystal
structures human researchers might never have imagined exploring.

This same potential exists in every industry. Financial services firms
combining human relationship management with AI pattern recognition are
identifying investment opportunities others miss. Healthcare providers
integrating clinical judgment with AI analysis are achieving diagnostic
accuracy neither could reach alone. Legal teams pairing human strategic
thinking with AI research capabilities are constructing arguments of
unprecedented sophistication.

### **The implementation imperative**

The question isn\'t whether to build human-AI teams but how quickly you
can develop this capability before competitors do. Organizations still
treating AI as a tool rather than a team member are constraining their
potential. Those building true collaborative partnerships are achieving
breakthrough results.

Start with a single team and a well-defined challenge. Map capabilities
carefully. Design interaction protocols deliberately. Establish
evaluation frameworks rigorously. Create feedback loops systematically.
Scale patterns thoughtfully.

The future belongs to organizations that master human-AI collaboration.
The blueprint exists. The only question is whether you\'ll follow it or
watch competitors pull ahead while you\'re still trying to use AI like a
better calculator.

Sources:

Merchant, A. et al. (2023). Scaling deep learning for materials
discovery. Nature.
[[https://doi.org/10.1038/s41586-023-06735-9]{.underline}](https://doi.org/10.1038/s41586-023-06735-9)

Google DeepMind. (2023). Millions of new materials discovered with deep
learning. DeepMind Blog.
[[https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/]{.underline}](https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/)

De Smet, A., Jost, G., & Weiss, L. (2019). Three keys to faster, better
decisions. McKinsey Quarterly.
[[https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/three-keys-to-faster-better-decisions]{.underline}](https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/three-keys-to-faster-better-decisions)

De Smet, A., Jost, G., & Weiss, L. (2019). Decision making in the age of
urgency. McKinsey & Company.
[[https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/decision-making-in-the-age-of-urgency]{.underline}](https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/decision-making-in-the-age-of-urgency)

# **[Building Human-AI teams: managing humans and AI agents together]{.underline}**

![Geoff Gibbins](media/image4.jpg){width="0.5in" height="0.5in"}

## **[Geoff Gibbins]{.underline}** 

[Human-AI expert \| Managing Director at BOI \| Author]{.underline}

[September 10, 2025]{.underline}

[As we all know, AI agents can \'do\' things now, not just respond to
chat queries. Book flights (I don\'t know why everybody uses that
example, but they do). Update sales records. Instruct a warehouse robot.
This isn\'t science fiction. It\'s Tuesday.]{.underline}

[For the world of work, this means that we need to treat AI as a
co-worker, a member of the team. The era of hybrid teams, where your
direct reports include both humans and AI agents, has arrived. And most
organizations are completely unprepared for what this
means.]{.underline}

[Welcome to management in 2025, where success depends on orchestrating
collaboration between carbon and silicon colleagues.]{.underline}

### **[The new org chart]{.underline}**

[Forget everything you know about organizational design. The \'org
chart\' looking forward shouldn\'t just show human relationships. It
shows AI agents as team members with specific roles, responsibilities,
and reporting structures.]{.underline}

[At Kaiser Permanente, the care team now includes AI agents that handle
ambient documentation, saving 16,000 hours in 15 months. These agents
don\'t just execute tasks --- they learn from feedback, adapt to
individual physician styles, and flag potential issues for human review
(Kaiser Permanente, 2025).]{.underline}

[The human physicians don\'t just use these agents as tools. They manage
them like team members. They provide feedback, adjust parameters, and
coordinate handoffs. The agents, in turn, provide performance data back
to help physicians improve their own practices. This bidirectional
management --- humans managing AI, AI providing feedback to humans ---
is the new normal. And most organizations are completely unprepared for
it.]{.underline}

### **[What changes when AI joins the team]{.underline}**

[Everything changes when you add AI agents to a team, starting with
communication protocols.]{.underline}

[Boston Dynamics recently demonstrated their Atlas robot taking natural
language commands in a warehouse setting, interpreting requests like
\"grab me that connector over there\" and understanding contextual
references (Boston Dynamics, 2025). This level of natural interaction
requires new protocols for human-AI communication.]{.underline}

[Parloa, a Berlin startup, solved this by creating what they call
\"multi-agent orchestration.\" Their customer service system routes
every interaction through specialized agents --- one flags spam, one
rates toxicity, one checks for self-harm indicators --- then hands
complex cases to human supervisors. The system reduced response time by
67% while improving accuracy (Parloa, 2025).]{.underline}

[Accountability structures also transform. When an AI agent makes an
error, who\'s responsible? Research by MIT on human-AI accountability
found that clear \"accountability matrices\" are essential --- defining
decision spaces where AI agents are autonomous versus where humans
retain responsibility (Brynjolfsson et al., 2023).]{.underline}

[Performance measurement becomes multidimensional. You\'re not just
measuring human performance or AI performance --- you\'re measuring the
effectiveness of their collaboration. Google\'s research on human-AI
teams found that the quality of handoffs between human and AI team
members was the strongest predictor of overall team performance (Google
Research, 2024).]{.underline}

### **[Leading beings that don\'t sleep, eat, or have emotions]{.underline}**

[Managing AI agents requires a fundamental shift in leadership thinking.
These team members never get tired, never have bad days, and never need
motivation. But they also never have intuitive leaps, never understand
context they weren\'t explicitly given, and never care about the mission
beyond their programmed objectives.]{.underline}

[Research by Stanford on hybrid team management identified key
leadership adaptations needed (Stanford HAI, 2024):]{.underline}

-   [Clear specifications replace motivational speeches.]{.underline}

-   [Version control replaces performance improvement
    > plans.]{.underline}

-   [API documentation replaces onboarding materials.]{.underline}

[But here\'s what\'s fascinating: managing AI agents well makes you
better at managing humans too. The clarity required to direct AI ---
explicit goals, measurable outcomes, unambiguous communication ---
benefits human team members as well. Many managers discover that their
\"AI management\" practices improve their overall leadership
effectiveness.]{.underline}

### **[The orchestration advantage]{.underline}**

[The magic of hybrid teams isn\'t in the individual capabilities of
humans or AI agents. It\'s in orchestration --- coordinating their
complementary strengths to achieve outcomes neither could accomplish
alone.]{.underline}

[Consider how modern financial trading firms operate. AI agents monitor
markets 24/7, executing trades within defined parameters. Human traders
set strategy, adjust parameters based on world events, and handle
exceptional situations. Neither could achieve the same results alone ---
it\'s the orchestration that creates value (Bank for International
Settlements, 2024).]{.underline}

[This orchestration requires what I call \"handoff design\" ---
deliberately structuring how work flows between human and artificial
team members. Each handoff needs clear triggers (when does work
transfer?), complete context (what information needs to be passed?), and
defined expectations (what should the receiving party do?).]{.underline}

### **[Building your first hybrid team]{.underline}**

[How can you get started? Here\'s a roadmap to follow:]{.underline}

-   [Start small. Choose a process with clear boundaries and measurable
    > outcomes. Customer service, content creation, and data analysis
    > are good candidates. Avoid starting with high-stakes, ambiguous,
    > or emotionally charged work (Gartner, 2024).]{.underline}

-   [Define roles explicitly. Document what AI agents will do, what
    > humans will do, and --- critically --- what they\'ll do together.
    > Be specific about decision rights, escalation triggers, and
    > handoff protocols.]{.underline}

-   [Create feedback loops. Hybrid teams improve through iteration.
    > Build mechanisms for humans to provide feedback to AI agents and
    > for AI agents to surface patterns in human
    > decision-making.]{.underline}

-   [Invest in translation layers. Humans and AI agents speak different
    > languages. You need interfaces --- both technical and procedural
    > --- that allow them to communicate effectively.]{.underline}

-   [Prepare for resistance. Some team members will fear AI agents as
    > threats to their jobs. Others will over-rely on AI, abdicating
    > critical thinking. Address both extremes through clear
    > communication about how hybrid teams enhance rather than replace
    > human capabilities.]{.underline}

### **[The competitive reality]{.underline}**

[Organizations running effective hybrid teams are already pulling ahead.
McKinsey\'s analysis of early adopters found that companies with
well-functioning hybrid teams show 31% higher productivity and 23%
better quality metrics than traditional teams (McKinsey,
2024).]{.underline}

[But they\'re not just doing things faster --- they\'re doing things
that weren\'t possible before. The combination of human creativity and
AI computation, human judgment and AI consistency, human empathy and AI
scalability creates genuinely new capabilities.]{.underline}

[American Express, for example, uses hybrid teams in fraud detection
where AI agents process millions of transactions while human experts
handle complex patterns and evolving fraud tactics. This combination
caught 23% more fraud with 45% fewer false positives than either
approach alone (American Express, 2024).]{.underline}

### **[The future of management]{.underline}**

[We\'re witnessing the biggest transformation in management since the
industrial revolution. The shift from managing only humans to managing
hybrid teams requires new skills, new structures, and new
mindsets.]{.underline}

[But here\'s what excites me: this isn\'t about replacing human
management with algorithmic management. It\'s about evolution. The best
hybrid team managers will be deeply human --- able to navigate the
complex interpersonal dynamics of human team members while also
orchestrating the capabilities of AI agents.]{.underline}

[Research by the World Economic Forum predicts that by 2027, 23% of jobs
will involve managing hybrid human-AI teams. The managers who develop
these skills now will have enormous competitive advantages (World
Economic Forum, 2024).]{.underline}

[Your first hybrid team is probably forming right now, whether you
realize it or not. The question is: are you ready to lead
it?]{.underline}

[References:]{.underline}

[American Express. (2024). Annual report: Innovations in fraud
detection. New York: American Express.]{.underline}

[Anthropic. (2025). Research swarms: Scaling multi-agent reasoning. San
Francisco: Anthropic AI.]{.underline}

[AWS. (2025). Announcing Amazon Bedrock AgentCore. Seattle: Amazon Web
Services.]{.underline}

[Bank for International Settlements. (2024). The rise of hybrid trading
systems. Basel: BIS Quarterly Review.]{.underline}

[Boston Dynamics. (2025). Atlas in the warehouse: Natural language
tasking demo. Waltham, MA: Boston Dynamics.]{.underline}

[Brynjolfsson, E., Li, D., & Raymond, L. (2023). Human-AI accountability
in organizational decisions. MIT Sloan Working Paper.]{.underline}

[Gartner. (2024). Building and managing hybrid human-AI teams. Gartner
Research Report.]{.underline}

[Google Research. (2024). Measuring collaboration quality in human-AI
teams. Mountain View: Google AI.]{.underline}

[Kaiser Permanente. (2025). Ambient AI scribes hit 16,000 hour
milestone. Oakland, CA: Permanente Medical Group.]{.underline}

[McKinsey. (2024). The performance impact of hybrid teams. McKinsey
Global Institute.]{.underline}

[Parloa. (2025). The ant colony playbook: Multi-agent moderation in
production. Berlin: Parloa White Paper.]{.underline}

[Stanford HAI. (2024). Leadership in the age of hybrid teams. Stanford
University Research Report.]{.underline}

[World Economic Forum. (2024). Future of jobs report 2024. Geneva:
WEF.]{.underline}

[\
]{.underline}

# **[Leadership in the age of AI: Why executives must relearn how to lead in the AI era]{.underline}**

![Geoff Gibbins](media/image4.jpg){width="0.5in" height="0.5in"}

## **[Geoff Gibbins]{.underline}** 

[Human-AI expert \| Managing Director at BOI \| Author]{.underline}

[August 26, 2025]{.underline}

[AI isn\'t just changing how we use technology, it\'s rewriting what
leadership means.]{.underline}

[Research reveals that 70% of AI transformation success depends on
people and process competencies, not technical capabilities. Yet most
executives are still leading with a playbook written for a pre-AI world.
This isn\'t about adding AI to your toolkit or becoming an expert prompt
engineer for a tool that will become obsolete in 6 months --- it\'s
about becoming a leader that navigates paradox, manages human potential
in new ways, and creates meaning in an age of artificial
intelligence.]{.underline}

### **[The paradigm shift in leading]{.underline}**

[In 1995, Andy Grove, Intel\'s legendary CEO, stood before his
leadership team with an uncomfortable message. The company that
dominated memory chips was being decimated by Japanese competitors.
Grove posed a simple question: \"If we got kicked out and the board
brought in a new CEO, what do you think he would do?\" The answer was
obvious --- exit memory chips and focus on microprocessors. Grove\'s
insight wasn\'t about the technology. It was recognizing that everything
Intel\'s leaders believed about their business --- their entire mental
model of success --- had become obsolete.]{.underline}

[Grove called these moments \"strategic inflection points\" --- times
when the fundamentals of a business shift so profoundly that the old
rules no longer apply. Leaders who recognize these moments early enough
can transform. Those who don\'t become case studies in business
schools.]{.underline}

[We\'re living through such a moment now, but it\'s not confined to a
single company or industry. AI is creating a strategic inflection point
for the very nature of leadership itself. Every leader is now leading in
the age of AI, whether they\'re actively using AI or not. The technology
is reshaping customer expectations, competitive dynamics, and the very
nature of work. You can choose not to use AI, but you can\'t choose to
lead in a world unaffected by it.]{.underline}

### **[The five fundamental shifts redefining leadership]{.underline}**

[To understand how leadership is changing in age of AI, we need to grasp
five shifts happening simultaneously:]{.underline}

### **[1. From answer-giver to question-master]{.underline}**

[For generations, leaders rose by having the answers. The boss knew
best. Experience meant expertise. Knowledge was power.]{.underline}

[But now, AI systems can process more information in an hour than you
can in a lifetime. They can identify patterns you\'ll never see,
calculate probabilities you can\'t fathom, and generate solutions you
wouldn\'t imagine. So where does that leave you?]{.underline}

[It leaves you with something AI systems don't have: the ability to ask
the questions that matter. Not \"What\'s the answer?\" but \"What should
we be solving for?\" Not \"What does the data say?\" but \"What does
this mean for human beings?\" Not \"How do we optimize?\" but \"Should
we do this at all?\"]{.underline}

[The new leadership premium isn\'t on knowing --- it\'s on judgment,
wisdom, and critical thinking. It\'s on building organizations that
question rather than just execute. Because in a world where AI provides
infinite answers, the scarcest resource becomes asking the right
questions. Critical thinking --- the ability to analyze, evaluate, and
challenge assumptions --- becomes more valuable than any technical
skill. Leaders must model and cultivate this deeper thinking, teaching
their teams to interrogate AI\'s outputs rather than accept them
blindly.]{.underline}

### **[2. From predictable pathways to perpetual adaptation]{.underline}**

[Remember when you could predict what skills would matter in a
decade?]{.underline}

[Exponential change has killed predictability. AI capabilities are
doubling while human development remains linear. The skills you\'re
building today might be obsolete before you master them. The strategy
you\'re implementing might be irrelevant before it\'s complete. The
future isn\'t just uncertain---it\'s fundamentally
unknowable.]{.underline}

[This demands a new kind of leadership: one that thrives on
discontinuity rather than stability. Leaders must now build resilience
when disruption is the norm, create stability through values rather than
processes, focus on building skills with a long 'half life', and embrace
\"strong opinions, loosely held\" as an operating
philosophy.]{.underline}

[The paradox? You must move faster while being more thoughtful. Act
decisively while staying adaptable. Commit fully while being ready to
pivot instantly.]{.underline}

### **[3. From human resources to human essence]{.underline}**

[Here\'s an uncomfortable truth: AI will soon do most routine cognitive
work better than humans. Not just data entry or basic analysis, but
complex problem-solving, creative writing, even strategic
planning.]{.underline}

[So what becomes of human value? Everything that makes us irreplaceably
human becomes infinitely more valuable. Not our ability to process
information, but our capacity for genuine empathy and connection, moral
imagination and ethical reasoning, meaning-making and purpose creation,
authentic creativity and pathbreaking original thought, and navigating
ambiguity and paradox.]{.underline}

[This shift redefines everything about talent. Hiring transforms from
focusing on credentials to character and creativity. Communication
skills and EQ in abundance. Development shifts from building skills to
unleashing human potential. Evaluation moves from measuring productivity
to assessing contribution to culture. Rewards transition from
recognizing execution to celebrating innovation and
insight.]{.underline}

[Leaders must now manage something unprecedented: identity crises at
scale as entire professions transform. The question isn\'t \"How do we
upskill?\" but \"How do we help people find meaning when machines do the
work?\"]{.underline}

### **[4. From hierarchical authority to network influence]{.underline}**

[Traditional org charts assumed knowledge flowed downward. Seniors knew
more. Experience meant expertise. Authority came from
position.]{.underline}

[AI destroys this assumption. When a junior employee with AI can
outperform a senior executive\'s analysis, what happens to
hierarchy?]{.underline}

[It evolves into something radically different. Influence without
position emerges in liquid, project-based structures. Credibility comes
through your contribution and the ability to find yourself in the right
places with the right problems where you can shine, not just title.
Leadership becomes a matter of orchestration, not command of
resources.]{.underline}

[You\'re no longer leading humans alone. You\'re leading hybrid Human-AI
teams where the AI might be the smartest participant in the room. Your
value isn\'t in being the expert - it\'s in being the integrator, the
sense-maker, the wisdom-keeper.]{.underline}

### **[5. From performance management to potential maximization]{.underline}**

[We\'ve spent a century optimizing human performance. Time and motion
studies. KPIs. Productivity metrics. Efficiency ratios.]{.underline}

[AI makes all of this less relevant. It will always be more efficient,
more consistent, more scalable than humans at defined
tasks.]{.underline}

[But here\'s what AI systems can\'t do yet: dream beyond its training
data. Feel genuine inspiration. Make leaps of illogical brilliance. Care
deeply about outcomes. Find meaning in struggle.]{.underline}

[This demands a fundamental shift from managing performance to
maximizing human potential. Stop measuring efficiency; start measuring
innovation. Stop optimizing productivity; start unleashing creativity.
Stop standardizing output; start celebrating uniqueness. Stop managing
tasks; start cultivating genius.]{.underline}

[The new performance paradigm isn\'t about doing more - it\'s about
becoming more. It\'s about creating environments where human brilliance
complements artificial intelligence, where people do what only humans
can do, where potential is maximized rather than productivity
measured.]{.underline}

### **[New leadership competencies for the AI age]{.underline}**

[These shifts demand new leadership capabilities. There are the five
meta-capabilities that will be important for leaders to become a new
type of leader in the age of AI:]{.underline}

1.  [The sense-maker: In a world of infinite information and
    > AI-generated insights, the scarcest resource is meaning. Leaders
    > must now synthesize insights across human and artificial
    > intelligence, create coherent narratives from chaos, help teams
    > find meaning amidst acceleration, and build shared understanding
    > when reality shifts daily. This isn\'t about having the answers
    > --- it\'s about making sense of the questions through critical
    > thinking and analysis. It\'s about helping humans understand not
    > just what\'s happening, but what it means for them, their work,
    > their future. The ability to think critically about AI\'s outputs,
    > to question its assumptions, and to identify what\'s missing
    > becomes essential.]{.underline}

2.  [The Human-AI culture architect: Culture used to evolve slowly. And
    > it used to just be about humans. Now it must be actively designed
    > for human-AI collaboration. This means preserving human connection
    > in digital environments, creating psychological safety during
    > existential shifts, building identity beyond job functions, and
    > fostering belonging when work itself transforms. You\'re not
    > managing culture---you\'re architecting it for a hybrid future
    > where humans and AI work together in ways we\'re just beginning to
    > imagine.]{.underline}

3.  [The paradox navigator: The AI age is full of contradictions that
    > can\'t be resolved, only navigated. Be efficient *and* human. Move
    > fast *and* be thoughtful. Embrace AI *and* preserve human agency.
    > Automate *and* create meaningful work. Scale *and* personalize.
    > Leaders must become comfortable holding multiple truths
    > simultaneously, making decisions when both options are right,
    > leading through *and* not *or*.]{.underline}

4.  [The learning orchestrator: When knowledge has an expiration date
    > measured in months, learning becomes the core capability. But this
    > isn\'t traditional learning. It\'s about unlearning faster than
    > learning --- letting go of what made you successful. It\'s
    > meta-learning --- learning how to learn in new ways. It\'s
    > collective learning --- building organizational intelligence.
    > It\'s experimental learning --- discovering through doing. And
    > crucially, it\'s about developing critical thinking skills across
    > the organization, ensuring everyone can evaluate and challenge
    > both human and AI-generated insights. You\'re not just learning
    > yourself --- you\'re orchestrating learning at scale, creating
    > organizations that evolve as fast as the technology around
    > them.]{.underline}

5.  [The ethical anchor: When AI systems can tell you what you can do,
    > leaders must decide what you should do. This requires making
    > values-based decisions when AI provides the data, protecting human
    > dignity in efficiency-driven systems, defining ethical boundaries
    > for AI use, and leading through moral complexity without clear
    > precedents. Most importantly, it demands rigorous critical
    > thinking --- the ability to question AI\'s recommendations,
    > identify hidden biases, and understand the broader implications of
    > automated decisions. In a world of artificial intelligence, human
    > wisdom and critical thinking become the ultimate
    > differentiators.]{.underline}

### **[The existential questions every leader must face]{.underline}**

[Before you can lead others through transformation, you must confront
fundamental questions about your own leadership:]{.underline}

-   [About your organization: What is our organization\'s purpose when
    > AI can do the work? How do we create meaning for our people? What
    > makes us irreplaceably human?]{.underline}

-   [About humans in the age of AI: How do we honor human dignity while
    > embracing efficiency? What becomes of careers and growth? How do
    > we prepare people for jobs that don\'t exist yet?]{.underline}

-   [About yourself as a leader: What is my role when AI might make
    > better decisions? How do I lead through others\' existential
    > anxiety? What unique value do I bring as a human
    > leader?]{.underline}

### **[What it means for CHROs: the evolution from human resources to human cultivation]{.underline}**

[The traditional CHRO role was built on predictable assumptions: defined
job roles, linear career paths, stable skill requirements, and humans as
the only workers. These assumptions are dissolving.]{.underline}

[Every framework underlying talent strategy now requires fundamental
rethinking. Succession planning assumes stable roles that may not exist
in two years. Leadership development programs train for a world that\'s
already changed. Performance management systems measure human output
against human benchmarks, ignoring that AI colleagues are redefining
what \"good\" looks like. Talent pipelines prepare people for jobs while
the definition of those jobs shifts monthly.]{.underline}

[But here\'s the deeper shift: CHROs must evolve from managing human
resources to cultivating human potential in a hybrid workforce. This
means thinking about AI systems not as tools but as colleagues --- team
members with their own capabilities, limitations, and development
trajectories. Your workforce now includes both human and artificial
intelligence, and your role is to help them work together
effectively.]{.underline}

[Consider what this means practically. You\'re no longer just developing
human leaders --- you\'re helping them learn to lead hybrid teams where
an AI might be the most knowledgeable member. You\'re not just building
culture among humans --- you\'re architecting collaboration patterns
between human and artificial colleagues. You\'re not just managing
change --- you\'re shepherding a fundamental redefinition of work
itself.]{.underline}

### **[The new reality of human-AI collaboration culture]{.underline}**

[Creating an effective human-AI collaboration culture requires
abandoning old mental models. This isn\'t about \"upskilling\" humans to
use AI tools. It\'s about reimagining how different forms of
intelligence work together.]{.underline}

[Think of AI systems as colleagues with unique characteristics: they
never tire but lack intuition, they process vastly more information but
miss emotional nuance, they identify patterns humans can\'t see but
can\'t explain why something matters to a human being. Your job is to
create a culture where these different intelligences complement rather
than compete.]{.underline}

[This demands new approaches to fundamental HR practices. Onboarding
must include not just introducing human colleagues but explaining AI
teammates\' capabilities. Team formation must consider the optimal mix
of human and artificial intelligence for different challenges.
Development conversations must help humans find their unique value when
AI can do much of what they previously did. Recognition systems must
celebrate human contributions that transcend productivity
metrics.]{.underline}

### **[The cultivation imperative]{.underline}**

[The shift from HR to human cultivation isn\'t semantic --- it\'s
fundamental. Cultivation implies growth, patience, and creating
conditions for flourishing. It recognizes that humans aren\'t resources
to be optimized but potential to be developed.]{.underline}

[In practical terms, this means helping humans discover capabilities
they didn\'t know they had. When AI handles routine cognitive work, what
dormant human capacities can emerge? When efficiency is automated, what
new forms of creativity become possible? When AI provides infinite
answers, what questions will humans learn to ask?]{.underline}

[Your role is to create environments where humans can explore these
questions safely. This requires psychological safety at a new level ---
not just safety to fail, but safety to fundamentally reimagine one\'s
professional identity. It requires learning approaches that are
experimental rather than prescribed. It requires patience with the
messiness of human transformation.]{.underline}

### **[The questions that matter now]{.underline}**

[The critical questions for CHROs have shifted from operational to
existential:]{.underline}

[Instead of \"How do we fill roles?\" ask \"What human capabilities will
matter when AI can do most tasks?\" Instead of \"How do we measure
performance?\" ask \"How do we recognize uniquely human contributions?\"
Instead of \"How do we develop leaders?\" ask \"How do we help leaders
navigate human-AI collaboration?\"]{.underline}

[Most fundamentally: Are you preparing your organization for a world
where humans and AI work as colleagues, or are you still treating AI as
just another tool in the toolkit?]{.underline}

[The CHROs who answer these questions thoughtfully --- who embrace their
role as cultivators of human potential in a hybrid workforce --- will
help their organizations navigate this transformation
successfully.]{.underline}

### **[Reimagining leadership development for the AI age]{.underline}**

[Leadership development must shift from programs to continuous
transformation. This means embracing real-time learning versus periodic
training --- learning in the flow of work. It requires philosophical
depth versus technical skills --- wisdom over knowledge. We need
adaptive capacity versus fixed competencies --- learning how to learn.
And we must build collaborative intelligence versus individual
brilliance --- collective wisdom.]{.underline}

[The goal isn\'t to develop leaders. It\'s to develop humans who can
lead through anything. This will be based on embodying the following
changes:]{.underline}

1.  [From programs to living laboratories: Stop thinking about
    > leadership development as an event. Start thinking about it as
    > continuous experimentation. Create living laboratories where
    > leaders can test new leadership approaches with real stakes, fail
    > safely and learn quickly, iterate based on what works in your
    > specific context, and build judgment through practice, not theory.
    > This isn\'t training --- it\'s transformation through
    > experimentation.]{.underline}

2.  [From teaching to unlearning: The biggest barrier to AI-age
    > leadership isn\'t learning new skills --- it\'s letting go of what
    > made leaders successful before. This requires structured
    > unlearning of obsolete mental models, challenging decades of
    > leadership muscle memory, creating space between stimulus and
    > response, and building comfort with not knowing. The hardest part?
    > Unlearning success. Letting go of the very approaches that got
    > leaders where they are.]{.underline}

3.  [From individual to collective intelligence: Stop developing
    > individual leaders. Start building collective leadership
    > intelligence. This means creating peer learning networks that
    > evolve together, facilitating cross-generational wisdom exchanges,
    > running human-AI collaboration workshops, and building shared
    > sensing capabilities. The goal isn\'t smarter individuals ---
    > it\'s smarter organizations.]{.underline}

4.  [From external experts to internal discovery: While guidance
    > matters, the answers must come from within. This requires coaching
    > that enables discovery, not prescription. It means facilitating
    > insight rather than providing solutions. It demands building
    > internal capacity for continuous reinvention and creating
    > organizational self-awareness. Nobody can tell you how to lead in
    > your specific context. But the right partner can help you discover
    > it yourself.]{.underline}

5.  [From simulations to real stakes: Learning must happen in the arena,
    > not the classroom. This means real projects with real
    > consequences, leading through actual transformation, making
    > decisions with incomplete information, and building judgment
    > through practice. The best leadership development is leading
    > through the challenge itself.]{.underline}

### **[The leaders who shape tomorrow]{.underline}**

[We stand at an inflection point in human history. The age of AI will be
shaped not by those who master the technology, but by those who
reimagine what it means to be human leaders in an era of artificial
intelligence.]{.underline}

[The leaders who transform now --- who embrace the discomfort of not
knowing, who experiment with courage, who manage human potential in new
ways --- these are the leaders who will define the future of
organizations and the meaning of work itself. The question isn\'t
whether leadership must change. It\'s whether you\'ll be among those who
lead that change.]{.underline}

### **[The call to action: Three actions for tomorrow morning]{.underline}**

[1. Map what\'s changing and what\'s enduring]{.underline}

[Gather your senior team to examine what\'s shifting and what remains
constant. Create two columns: \"What\'s changing about leadership\"
(decision speed, sources of expertise, team structures) and \"What\'s
enduring about leadership\" (trust, meaning, human dignity). This builds
shared awareness without creating anxiety --- many leaders sense
something is different but haven\'t articulated what.]{.underline}

[2. Identify one assumption to test together]{.underline}

[Choose one manageable leadership assumption to experiment with over 30
days. Maybe it\'s \"senior leaders should have all the answers\" ---
test it by including junior AI-fluent team members in strategy
discussions. Or \"annual planning works\" --- try a 90-day sprint
instead. Treat it as an experiment with clear metrics, not a
mandate.]{.underline}

[3. Create a learning ritual]{.underline}

[Establish a weekly practice where leaders share observations about how
AI systems are showing up in their areas --- customer behavior, employee
practices, competitive dynamics. Ask: What patterns do we see? What
surprises us? This normalizes not knowing and positions your team as
learners navigating change together.]{.underline}

[These aren\'t about revolutionary transformation overnight. They\'re
about beginning adaptation with curiosity rather than crisis, building
the organizational muscle for continuous evolution through small,
thoughtful steps taken together.]{.underline}

[\
]{.underline}

# **[The metacognition advantage: why thinking about thinking is your ultimate AI-era superpower]{.underline}**

![Geoff Gibbins](media/image4.jpg){width="0.5in" height="0.5in"}

## **[Geoff Gibbins]{.underline}** 

[Human-AI expert \| Managing Director at BOI \| Author]{.underline}

[September 2, 2025]{.underline}

[On September 23, 1999, NASA lost the Mars Climate Orbiter. Not to
cosmic radiation or equipment failure, but to something far more
mundane: one team used metric units while another used imperial. The
\$327 million spacecraft burned up in the Martian atmosphere because
nobody stepped back to think about how they were thinking.]{.underline}

[The investigation revealed something more troubling than the unit
mismatch. Team members had noticed trajectory discrepancies. They\'d
seen warning signs. But they never engaged in what cognitive scientists
call metacognition --- thinking about their thinking. They never asked:
\"What assumptions are we making? How confident should we be? What might
we be missing?\"]{.underline}

[Today, as we rush to integrate AI into every aspect of work, we\'re at
risk of making the same mistake on a civilization scale. We\'re so
focused on what AI can do that we\'re forgetting to think about how we
think alongside it. Yet metacognition --- this uniquely human ability to
observe and direct our own cognitive processes --- might be our greatest
advantage in the AI era.]{.underline}

[And here\'s the twist: AI systems, properly engaged, can become
powerful partners in developing our metacognitive abilities. Not as
tools we use, but as thinking coaches that help us see our own minds
more clearly.]{.underline}

### **[Understanding the metacognitive advantage]{.underline}**

[Metacognition is essentially having a conversation with yourself about
your own thinking. It\'s the mental equivalent of watching yourself on
video --- suddenly you notice habits and patterns invisible in the
moment. Do you jump to conclusions? Overlook certain types of evidence?
Become overconfident when you have moderate expertise?]{.underline}

[Research by David Dunning and Justin Kruger published in 1999 famously
showed that people with the least competence tend to be most confident
--- they literally don\'t know enough to recognize their ignorance. In
their study, participants scoring in the bottom quartile on tests of
humor, grammar, and logic estimated themselves to be in the 62nd
percentile when they were actually in the 12th. The researchers
attributed this to a lack of metacognitive ability: incompetence robs
people of the capacity to realize they are incompetent.]{.underline}

[This is where AI becomes fascinating as a metacognitive partner. Unlike
human colleagues who might hesitate to challenge a senior expert, AI
systems have no social inhibitions. They can serve as what I call a
\"cognitive mirror\" --- reflecting your thinking patterns back to you
without judgment or hierarchy.]{.underline}

### **[AI as metacognitive coach: the new collaboration model]{.underline}**

[When most people interact with AI, they ask for answers. But the real
power comes from asking AI to help you examine your questions. This
shifts AI from an oracle providing solutions to a coach developing your
thinking capabilities.]{.underline}

[At Wharton, professors Ethan and Lilach Mollick have pioneered this
approach in education. In their 2023 paper \"Assigning AI: Seven
Approaches for Students, with Prompts,\" they outline different ways to
use AI as a learning partner, including as a coach, mentor, and
simulator. These aren\'t just tools for getting homework done ---
they\'re methods for developing metacognitive skills.]{.underline}

[\"This metacognitive exercise can help you identify what you want to
explore and what you already understand,\" notes Stanford\'s Teaching
Commons in their guide on AI chatbots. \"Making connections to what you
already know can deepen your learning and support your
engagement.\"]{.underline}

[The Mollicks emphasize keeping humans \"in the loop,\" promoting active
oversight and critical assessment of AI outputs rather than passive
acceptance. This represents a fundamental shift from the tool paradigm.
You don\'t \"use\" a coach. You work with them to develop capabilities
that persist beyond individual sessions.]{.underline}

### **[The practice of AI-enhanced metacognition]{.underline}**

[Developing metacognitive skill with AI requires specific practices that
go beyond typical ChatGPT interactions:]{.underline}

-   [The \'assumption inventory\' exercise: Ask AI to identify every
    > assumption embedded in something you\'ve written --- a strategy
    > document, email, or proposal. You\'ll be stunned by how many
    > invisible beliefs shape your thinking.]{.underline}

-   [The \'confidence calibration\' game: Before making predictions or
    > decisions, state your confidence level (0-100%) to an AI system.
    > Have it track your accuracy over time. Research shows that even
    > weather forecasters --- who are actually among the best-calibrated
    > professionals precisely because they get daily feedback on their
    > predictions --- can benefit from systematic tracking. Unlike most
    > of us who tend toward overconfidence, meteorologists have learned
    > through repeated practice to accurately assess their
    > uncertainty.]{.underline}

-   [The perspective portfolio: Ask AI to analyze the same situation
    > from multiple viewpoints --- a competitor, regulator, customer,
    > employee, investor. This isn\'t about the AI being right but about
    > using its ability to simulate different frameworks to reveal your
    > own cognitive boundaries.]{.underline}

-   [The \"explain It back\" protocol: After explaining something
    > complex to AI, ask it to identify points where your explanation
    > was unclear, contradictory, or incomplete. This surfaces fuzzy
    > thinking that slides by in human conversation where people
    > politely nod along.]{.underline}

### **[Why AI makes a uniquely effective metacognitive partner]{.underline}**

[AI systems possess several characteristics that make them exceptional
metacognitive coaches:]{.underline}

-   [Infinite Patience: You can explore your thinking for hours without
    > wearing out your welcome. Try asking a human colleague to listen
    > to you think out loud about the same problem for three
    > hours.]{.underline}

-   [No Ego Involvement: AI won\'t feel threatened if you\'re smarter in
    > some areas or defensive if you challenge its suggestions. This
    > creates psychological safety for genuine self-examination that\'s
    > hard to achieve even with trusted colleagues.]{.underline}

-   [Pattern Recognition: Modern AI systems can identify patterns in
    > your thinking across multiple conversations, helping you spot
    > recurring biases or blind spots.]{.underline}

-   [Systematic Documentation: AI can help you build what I call a
    > \"thinking autobiography\" --- a record of your cognitive
    > patterns, biases, and growth over time.]{.underline}

### **[The metacognitive blind spot of AI systems]{.underline}**

[Here\'s the paradox that makes this collaboration so powerful: AI
systems excel at helping us develop metacognition precisely because they
lack it themselves. Current AI doesn\'t know what it knows. It can\'t
reflect on its own thinking or recognize the boundaries of its
understanding. When ChatGPT generates a response, it\'s not thinking
about thinking --- it\'s generating statistically probable
text.]{.underline}

[This limitation becomes a feature when properly understood. Because AI
lacks metacognition, it approaches your thinking with a kind of naive
directness. It won\'t unconsciously filter observations through its own
metacognitive biases because it doesn\'t have any.]{.underline}

### **[Building organizational metacognition]{.underline}**

[The most forward-thinking organizations are now using AI to develop
collective metacognition --- the ability to think about how the
organization thinks.]{.underline}

[Bridgewater Associates, the world\'s largest hedge fund famous for its
culture of \"radical transparency,\" has been at the forefront of this
approach. The firm has long used algorithmic decision-making and
systematic feedback loops to improve organizational thinking. As co-CIO
Greg Jensen explained at the MIT Sloan Investment Conference, their
systematic approach to decision-making creates a framework where
\"machines are better at finding patterns across times and across
countries.\"]{.underline}

[In 2024, Bridgewater launched a \$2 billion fund that uses machine
learning as the primary basis for decision-making, incorporating models
from OpenAI, Anthropic, and Perplexity. This isn\'t just about AI making
investment decisions --- it\'s about creating what CEO Nir Bar Dea calls
a system that generates \"unique alpha\" uncorrelated with human
strategies.]{.underline}

[The firm\'s AIA (Artificial Investment Associate) Labs uses AI agents
to break down complex investment strategies while keeping human analysts
in the loop. This balance is crucial: AI processes vast amounts of data
to identify patterns, while humans provide oversight on risk management,
data acquisition, and trade execution. As Jensen notes, \"You\'re going
to have intelligence that can read every newspaper in the
world.\"]{.underline}

### **[Educational transformation through metacognitive AI]{.underline}**

[In education, the Mollicks at Wharton have demonstrated how AI can act
as what they call a \"force multiplier\" for instructors. Their research
shows that AI can help implement evidence-based teaching strategies that
are proven effective but often too time-consuming to execute
regularly.]{.underline}

[These strategies include uncovering student misconceptions, providing
frequent low-stakes testing, and creating distributed practice
opportunities --- all metacognitive techniques that help students
understand their own learning processes. The key is not using AI to
provide answers, but to prompt reflection.]{.underline}

[Stanford\'s Teaching Commons emphasizes this metacognitive approach,
noting that \"metacognitive skills can help students understand how
learning works, increase awareness of gaps in their learning, and lead
them to develop study techniques.\" When AI is used as a thinking
partner rather than an answer machine, it enhances these crucial
skills.]{.underline}

### **[The path forward: from unconscious to conscious collaboration]{.underline}**

[The organizations and individuals who thrive in the AI era won\'t be
those with the best AI or the smartest people. They\'ll be those who
best understand how they think and can consciously direct that thinking
in partnership with AI.]{.underline}

[This requires a fundamental shift in how we engage with AI systems.
Stop asking AI what to think and start asking it to help you understand
how you think. Stop using it as an answer machine and start
collaborating with it as a thinking coach. Stop seeing it as a tool and
start engaging it as a partner in developing your metacognitive
capabilities.]{.underline}

[The Mars Climate Orbiter was lost because brilliant engineers never
stepped back to examine their own thinking. Today, we have AI partners
that can help us do exactly that --- if we\'re wise enough to engage
them as collaborators in understanding our own minds rather than just
tools for getting quick answers.]{.underline}

[The ultimate competitive advantage in the AI era isn\'t having the best
AI. It\'s having the best understanding of how your mind works in
partnership with AI. That\'s a capability no one can automate,
outsource, or commoditize. It\'s also a capability that grows stronger
with practice, creating compounding advantages over time.]{.underline}

[Start simple. Next time you open ChatGPT or Claude, don\'t ask it for
an answer. Ask it to help you understand how you\'re thinking about the
question. You might be surprised by what you discover about your own
mind.]{.underline}

[Sources:]{.underline}

-   [Basak, S. (2024, July 1). Bridgewater starts \$2 billion fund that
    > uses machine learning for decision-making. Fortune.]{.underline}

-   [Bridgewater Associates. (2024). Greg Jensen on Algorithmic Decision
    > Making and Artificial Intelligence. MIT Sloan Investment
    > Conference Presentation.]{.underline}

-   [Dunning, D., & Kruger, J. (1999). Unskilled and Unaware of It: How
    > Difficulties in Recognizing One\'s Own Incompetence Lead to
    > Inflated Self-Assessments. Journal of Personality and Social
    > Psychology, 77(6), 1121-1134.]{.underline}

-   [Mollick, E. R., & Mollick, L. (2023, September 23). Assigning AI:
    > Seven Approaches for Students, with Prompts. The Wharton School
    > Research Paper. SSRN.]{.underline}

-   [Stanford Teaching Commons. (2023). Exploring the pedagogical uses
    > of AI chatbots. Stanford University.]{.underline}
