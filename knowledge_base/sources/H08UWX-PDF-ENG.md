# Digital Article / Hiring and Recruitment

Job Interviews Aren’t Evaluating the Right Skills It’s time to close the gap between what we say we’re looking for and what we actually evaluate. by Joseph Fuller, Ben Sesser, and William Leeds

## Published on HBR.org / August 14, 2025 / Reprint H08UWX

# skegbydave/Getty Images

Every year, millions of job seekers carefully parse job descriptions,

tailoring their resumes to match the speciﬁc skills and qualiﬁcations

employers claim to value. Meanwhile, hiring managers conduct

interview after interview, believing they’re eﬀectively evaluating

candidates’ qualiﬁcations.

Copyright © 2025 Harvard Business School Publishing. All rights reserved.

1

This document is authorized for use only by Matt O'Donnell (matthew.od11@gmail.com). Copying or posting is an infringement of copyright. Please contact customerservice@harvardbusiness.org or 800-988-0886 for additional copies.

## HBR / Digital Article / Job Interviews Aren’t Evaluating the Right Skills

But what if this fundamental assumption about how hiring works is

# wrong?

For the ﬁrst time, we can answer that question with data rather

## than speculation. Thanks to advances in interview recording and

transcription technology, we are now able to peer inside the black box

of hiring to understand what actually happens when candidates and

interviewers sit down together. The results reveal a disconnect that may

be undermining hiring decisions across industries.

These results are drawn from a comprehensive analysis recently

conducted by BrightHire in conjunction with the Harvard Business

School’s Managing the Future of Work project, involving 23,000

## interview transcripts across 44 companies and 1,311 positions. The

analysis found that although job descriptions serve as detailed

roadmaps for what employers claim to need, interviews often veer oﬀ

course. Even more notable: As artiﬁcial intelligence reshapes the skills

landscape at unprecedented speed, companies are largely failing to

assess whether candidates have any AI experience at all.

# The Illusion of Systematic Assessment

The numbers initially appear reassuring. After just one interview, nearly

80% of skills listed in job descriptions have been touched upon. By

the second interview, that ﬁgure climbs to 91%. On the surface, that

suggests a hiring process that’s working as intended—systematically

evaluating candidates against clearly deﬁned criteria.

But this surface-level analysis masks a more concerning reality. When

we dug deeper to measure whether skills were not just mentioned but

meaningfully assessed, the picture changed signiﬁcantly. A coverage

gap emerged and varied for diﬀerent types of skills. Soft skills such as

communication and collaboration were discussed thoroughly in 76% of

Copyright © 2025 Harvard Business School Publishing. All rights reserved.

2

This document is authorized for use only by Matt O'Donnell (matthew.od11@gmail.com). Copying or posting is an infringement of copyright. Please contact customerservice@harvardbusiness.org or 800-988-0886 for additional copies.

## HBR / Digital Article / Job Interviews Aren’t Evaluating the Right Skills

the multi-interview processes that were analyzed, but technical skills

and experience requirements—often the most critical diﬀerentiators

between candidates—received deep evaluation only 55% and 66% of the

## time, respectively, even after ﬁve interviews.

Moreover, the research found that even if skills are thoroughly covered

in an initial interview, they’re often revisited in subsequent interviews.

Across all skill categories, 72% of well-covered skills are addressed again

later, with each skill revisited an average of 1.2 additional times. That

suggests that hiring teams don’t lack the time to evaluate more skills—

but instead are probing the same topics in diﬀerent interviews. Whether

that reﬂects an undisciplined process or an overfocus on a few skills that

are viewed as particularly critical to success, the end result is the same:

It puts the employer at risk of hiring a worker without fully vetting that

# candidate’s qualiﬁcations.

One remarkable ﬁnding relates to the role of structured questioning.

Skills that interviewers explicitly asked about ended up being well-

covered during the interview process only 53% of the time. This is

compared with just 1.6% for skills that were never asked about—which

suggests that candidates should make sure to mention signiﬁcant

attainments and emphasize points that they feel will advance their

candidacies if interviewers aren’t asking about them in detail early

on. Looking more broadly, when both the “well-covered” and “partially

covered” categories are combined, asked-about skills were addressed

## 95.9 % of the time, versus only 11.5 % for unasked skills.

The risk this creates is clear: At best, we ﬁnd that almost half of the

oﬀers extended through such a process will rely on incomplete or biased

information. At worst, when a skill is never asked about explicitly,

that share is over 90%. In this context, candidates who happen to

## volunteer information about certain skills during their interviews may

Copyright © 2025 Harvard Business School Publishing. All rights reserved.

3

This document is authorized for use only by Matt O'Donnell (matthew.od11@gmail.com). Copying or posting is an infringement of copyright. Please contact customerservice@harvardbusiness.org or 800-988-0886 for additional copies.

## HBR / Digital Article / Job Interviews Aren’t Evaluating the Right Skills

appear more qualiﬁed than those who don’t, regardless of their actual

# capabilities.

The importance of probing a candidate’s skills early in the process is

made stark by the extent of interviewing actually undertaken. In our

sample, the average number of interviews per candidate was 2.97, with

a standard deviation of 1.50 interviews. Candidates have a very limited

opportunity to present their credentials, so their odds of advancing

in a recruiting process are likely to hinge on the eﬀectiveness of

their interviewers. Those who cover more important topics thoroughly

probably enhance interviewees’ chances of advancing; those who

meander or cover redundant topics probably undermine them.

# The AI Blind Spot

Nowhere is the disconnect between stated priorities and actual

## assessment more apparent than in the realm of artiﬁcial intelligence.

While business leaders regularly proclaim that AI will transform every

aspect of work, the hiring process tells a diﬀerent story. Although AI

is discussed in roughly 50% of interviews, candidates are rarely asked

explicitly about their AI skills or experience. In 2024, only 0.4% of

interviews included a direct question about AI usage. That ﬁgure more

than quintupled in 2025 to 2.2%, but it remains notably low given the

technology’s purported importance.

The data become even more striking after multiple interview

rounds have been completed. Even after three separate interviews—

representing hours of evaluation time—93% of candidates have never

been directly asked about their AI capabilities. That represents a

signiﬁcant blind spot in how companies assess readiness for an AI-

# driven future.

Copyright © 2025 Harvard Business School Publishing. All rights reserved.

4

This document is authorized for use only by Matt O'Donnell (matthew.od11@gmail.com). Copying or posting is an infringement of copyright. Please contact customerservice@harvardbusiness.org or 800-988-0886 for additional copies.

## HBR / Digital Article / Job Interviews Aren’t Evaluating the Right Skills

Interestingly, the types of roles most likely to include AI-related

questions have shifted dramatically. In 2024, marketing candidates

were the ones most frequently asked about AI usage. By 2025, recruiting

and HR professionals were the ones most likely to face such questions—

a 13-fold increase that reﬂects the technology’s rapid adoption in talent

# acquisition itself.

When AI questions are asked, they typically fall into six categories:

day-to-day usage, familiarity with speciﬁc tools, workﬂow integration,

## software-development assistance, strategic perspective, and prompt

engineering. But those conversations remain the exception rather than

the rule, representing a signiﬁcant missed opportunity to identify

candidates who could drive AI adoption within organizations.

# Recommendations for Leaders

Our ﬁndings point to several concrete steps that organizations can take

to align their hiring processes with their stated priorities:

Implement structured interview guides. Intentional questioning

matters: Companies should develop comprehensive interview guides

that ensure all critical skills receive explicit attention and include

mechanisms to track interviewers’ compliance during the process.

## Audit job descriptions against actual interviews. Organizations should

regularly review whether their interview processes actually assess the

skills they claim to value. This audit should examine whether skills are not just mentioned but evaluated in suﬃcient depth.

Integrate AI assessment into hiring practices. Given the technology’s

growing importance, companies should develop speciﬁc strategies

for evaluating candidates’ AI capabilities, comfort with technological

change, and potential for developing AI-related skills.

Copyright © 2025 Harvard Business School Publishing. All rights reserved.

5

This document is authorized for use only by Matt O'Donnell (matthew.od11@gmail.com). Copying or posting is an infringement of copyright. Please contact customerservice@harvardbusiness.org or 800-988-0886 for additional copies.

## HBR / Digital Article / Job Interviews Aren’t Evaluating the Right Skills

Reduce redundancy while increasing coverage. Rather than conducting

more interviews, organizations should focus on making each interview

more comprehensive and targeted. This might involve assigning speciﬁc

skill categories to diﬀerent interviewers or interview rounds.

## Train interviewers on comprehensive assessment. The research

suggests that many interviewers may lack the tools or training to

systematically evaluate candidates against job requirements. Investing

in interviewer development could yield signiﬁcant returns in hiring

# quality.

# The Path Forward

While many have long suspected that hiring processes might

be systematically ﬂawed, this research provides concrete data to

substantiate some of those concerns. Companies that fail to accurately

assess candidate capabilities may be missing qualiﬁed candidates

while hiring unsuitable ones—particularly problematic as organizations

struggle with talent shortages and the need to build AI-ready teams.

The good news is that these problems are entirely solvable with a

focus on intentionality, structure, and a commitment to measuring

what matters. And technology can help signiﬁcantly, by making

possible everything from automated interview recording and analysis

to AI-powered assessment platforms that ensure comprehensive skill

evaluation. Organizations that reform their hiring processes accordingly

will gain competitive advantages through better hiring decisions and

teams that are consequently better equipped for future challenges.

For candidates, improved interview processes mean fairer evaluation

based on actual job requirements rather than chance conversations.

When interviews systematically assess the skills that matter most,

qualiﬁed candidates have better opportunities to demonstrate their

Copyright © 2025 Harvard Business School Publishing. All rights reserved.

6

This document is authorized for use only by Matt O'Donnell (matthew.od11@gmail.com). Copying or posting is an infringement of copyright. Please contact customerservice@harvardbusiness.org or 800-988-0886 for additional copies.

## HBR / Digital Article / Job Interviews Aren’t Evaluating the Right Skills

capabilities—and all job seekers can more conﬁdently prepare for

interviews knowing they’ll be evaluated on relevant competencies.

The path forward is clear. It’s time to close the gap between what we say

we’re looking for and what we actually evaluate.

This article was originally published online on August 14, 2025.

Joseph Fuller is a professor of management practice and a faculty cochair of the Project on Managing the Future of Work at Harvard Business School.

# BS

Ben Sesser is the chief executive oﬃcer of BrightHire, an AI hiring platform.

# WL

William Leeds is the lead data scientist at BrightHire, an AI hiring platform.

Copyright © 2025 Harvard Business School Publishing. All rights reserved.

7

This document is authorized for use only by Matt O'Donnell (matthew.od11@gmail.com). Copying or posting is an infringement of copyright. Please contact customerservice@harvardbusiness.org or 800-988-0886 for additional copies.