# DOCUMENT RESUME

# ED 312 009

# JC 890 518

# AUTHOR

# TITLE

# INSTITUTION

# REPORT NO PUB DATE NOTE AVAILABLE FROM

# PUB TYPE

Burkhalter, Bettye B., Ed.; Buford, James A., Jr., Ed. Performance Appraisal: Concepts and Techniques for Postsecondary Education. American Association of Community and Junior Colleges, Washington, D.C. ISBN-0-87117-197-X

89 188p. American Association of Community and Junior Colleges Publications, 80 South Ear:y Street, Alexandria, VA 22304 ($12.50; $9.50, members). Viewpoints (120) -- Reports

# Descriptive (141)

# EDRS PRICE DESCRIPTORS

MF01 Plus Postage. PC Not Available from EDRS. *Administrator Evaluation; *College Faculty; Compliance (Legal); Evaluation Criteria; *Evaluation Methods; *Legal Problems; *Personnel Evaluation; Postsecondary Education; *Teacher Evaluation

# ABSTRACT

Designed primarily as a functional tool and reference

book for administrators, this book provides a collection of essays covering various aspects of the performance appraisal of college faculty, administrators, and support staff. The booklet presents practical information on the key concepts, theories, practices, and legal constraints in performance appraisal. The collection contains: (1) "Performance Appraisal: An Overview," by Bettye B. Burkhalter; (2) "Legal Aspects of Performance Appraisal," by James A. Buford, Jr.; (3) "Considerations in Selectin"; a Performance Appraisal Technique," by James A. Buford; (4) "Development of Performance Appraisal and Accompanying Criteria," by Edith A. Miller; (5) "Communication Factors in Performance Appraisal," by Mark E. Meadows; (6) "Minimizing Rater Errors in Observing and Appraising Performance," by William I. Sauser, Jr.; (7) "A President's Perspective: A Rationale and a Strategy for Building a Performance Appraisal Program," by Richard J. Federinko; and (8) "Characteristics of an Effective and Legally Defensible System for Postsecondary Education," by Burkhalter and Buford. Appendixes contain examples of performance appraisal forms designed for a number of purposes within the Alabama college system and a checklist of legal requirements. (AYC)

**********************************t*************K********************** Reproductj.ons supplied by EDRS are the best that can be made from the original document. *********************/************************************************

# Performance Appraisal

## Concepts and Techniques for Postsecondary Education

# Bettye B. Burkhalter

# James A. Buford, Jr.

V All rights reserved by the American Association of Community and Junior Colleges, One Dupont Circle, N W., Suite 410, Washington, D.C. 20036. No part of this book can be reproduced in any form without written permission from AACJC and us representatives

# Pnnted in the U S A

IBSN 0-87117-197-X

# Performa.ice Appraisal

# Concepts and Techniques for

# Postsecondary Education

Performance appraisal is conducted in all

types of organizations and groups. Postsecondary educational institutions are no exception. Postsecondary administrators appraise the actions of department heads, faculty. and support personnel to measure their contribution to the objectives of the institution. Sonic. adEatnistrators perform this task perfunctonly and fad to see its value, while others see it as a valuable process. Members of the organization must receive feedback from others concerning the appropriateness of their behavior if they are to noproe productivity. Lorrect errors,and grow professionally.

Terms used to describe this process vary among professional groups. Performance appraisal also is known as performance aluation, merit rating, performance review, performance and productivity assessment, and effmency and reporting. Performance appraisal has become the prefened term and is used in the most recent personnel and compensation textbooks and professional literature. The term evaluation should he avoided since it refers to those processes used to establish the internal worth of jobs.

# fitness

The process or performance appraisal aries from a series of informal assessments made by superiors who know their staff well to more structured systems which require superiors to complete various forms and make written Lomments. Many authorities contend that well-designed performanLe appraisal sytems are essential in effectively and legally managing human resources.

In reality, however, few systems are totally successful. One reason is that superiors have great difficulty writing useful and objective performance appraisal reports. They are often reluctant to criticize a subordinates work and put the LritiLism in writing. Another problem is there is no single approach that can fully addiess all the purposes that organizations attempt to achieve with performance appiaisal. As for equal oppor- tunity considerations, many systems used today are not the solution but, rather, are part of the problem. A number of studies have shown Li 'tenon bias to be a serious short- coming, resulting in discrimination against blacks, ethnic minorities, and women. These systems may produce ratings that are subjeLtive, impres,ionistic, non-job-related, and unstandardized. When used to justify important personnel decisions, such ratings increase rather than decrease Equal Employ ment Opportunity (EEO) liability.

Fortunately, the failures of the past have led to increa.,ed emphasis on development of raters, more realistic expectations of what performance appraisal can accomplish, workable appraisal techniques, and effective strategies to deal with EEO regulations. Examples of effective performance appraisal systems can be found in all types of organizations including educational institutions. Turning die potential of performance appraisal into productive reality is a challenge but attainah.e goal facing those who manage the affairs of postsecondary education.

With few exceptions, both faculty and administrators approach the performance appraisal process with some level of anxiety and apprehension. The editors have made a concerted effort in this book to relieve some of this anxiety by presenting the most pertinent information which will increase the understanding of basic knowledge that makes any performance appraisal system workable, fair to all parties, and legally defen- sible. While the editors recognize that many facets were omitted that could have been included, to do so would have made it unnecessarily long.

This book is not intended to be a substitute for primary sources in the field, rather, it is meant to provide a concise framework for understanding the basic concepts of per- formance appraisal and serve as a functional tool for practitioners and scholars. In addition, our hook is not designed to render legal advice or lcgal opinion. Such advice may only be given by ]lensed, practicing attorney, and only when related to actual fact situations. This warning is particularly pertinent because of the nature of the topics covered herein. Specific legal questions concerning personnel performance appraisal should always be checked with the appropriate legal counsel.

# Bettye B. Burkhalter

# James A Buford. Jr.

vi

# Acknowledgments

The editors and contributors wish to thank the many administiators, faLulty, graduate students, and support staff who made this work possible We particularly are indebted to the following people for their Lomments or editorial assistance on one or more of the chapters in this book. William H. Holley, Bettye Campbell, Hayden D. Center, and James Palmer.

Special acknowledgement goes to Anne S. Stewart who pro. ided on-site leadership for the study which led to the development of a perfoiniatke appraisal system at Southern Union State Junior College. Special acknowWgnient also is gLen to Deborah J. Mill,.r-Wood for research assistanct and for development of additional appraisal procedures from the study.

vii

(..)

# Preface

# v

# Acknowledgments

# vii

# List of Figures

# xi

1

# Performance Appraisal: An Overview 1

# Bettye B. Burkhalter

2

# Legal Aspects of Performance Appraisal

9

# James A. Buford. Jr.

3

## Considerations in Selecting a Performance Appraisal Technique

# James A Buford, Jr.

4

## Development of Performance Appraisal and Accompanying ('- .term 43

# Edith A. Miller

5

## Communication Factors in Performance Appraisal

57

# Mark E. Meadows

6

## Minimizing Rater Errors in Obsen mg and Appraising Performance

# William I Sauser. Jr.

7

## A President's Perspective: A Rationale and

## a Strategy for Building a Performance Appraisal Program 103

# Richard .1. Federinko

8

# Characteristics of an Effective and

Legally Defensible System for Postsecondary Education Bettye B. Burkhalter and James A. Buford. Jr.

# 1 l

ix

# Contents

19

73

# Appendices

# Appendix A. Case Examples

119

## Appendix B. Checklist for Legal Requirements

# Name Index

181

# Subject Index

185

# About the Editors and Contributions

187

177

# List of Figures

2.1

## Simplified Overview of EEO Liability Process

/3

3.1

# Graphic Trait Rating Scale

2 /

3.2

# Dimensionalized Rating Scale

22

3.3

# Essay Appraisal Format

24

3.4

## Ranking Scale Using Alternative Ranking Method

26

3.5

# Ranking With Paired Comparison

20

3.6

# Forced Distribution

27

3.7

# Forced Choice Appraisal

28

3.8

## Performance Standards for instructional Position

3()

3.9

# A Behaviorally Anchored Rating Scale for the Dimension "Classroom Teaching Performance"

3/

3.10

## Behavioral Observation Scales for the Job Dimension of "Instruk.tion"

32

3.11

Example of a behavioral scale based on expanding the performance standard for "Method of Instruction"

34

## 3.12 Objectives and Performance Requirements

35

5.1

# Basic Communication Transaction

59

5.2

# Two Basic Needs Affecting Communication

6/

5.3

## Factors Affecting the Flow of Messages Between Persons

02

5.4

# Barriers to Effective Communication

67

xi

1 : -i _,

# P

# 3rmance Appraisal: An Overview

# Bettye B. Burkhalter

Appraisal of performance of faculty tdministrators, and support staff is an activity which has been identified as one of the most pressing issues faung higher education during the next decade. There are a number of reasons for this glowing concern includ- ing financial exigency, public pressure for acwuntability, tnd the continuing need for workable approaches to reinforce the growth and development of individuals. As might be expected, this issue has generated considerable appreheilmon and skepticism, particularly on the part of faculty members It is the purpose of the authors to present in uncomplicated terms the key concepts, theories,. practices. and Lonstramts in this area. The focus is experiential and practical. Emphasis is made on the application of knowl- edge so that administrators ill g,an a useful understanding of the topic and have a frame of reference to make the best possible decisions.

## Problems and Issues in Performance Appraisal

Performance appraisal is wide!, recognized as au essential part of the management job in all types of organizations. It can pros ide a source of motivation to achieve organizational goals, a measurt. of work related contributions, and a v alii,tole tool in the personal and professional development of indiv ideals. Unfortunately, performance appraisal is generally regarded as one of the weakest dements in the management process A recent survey of over 2,400 prat.tit.ing mut .tgers combined with extensive review and analysis of 25 years of literature conclud,.. ,,,at "no industry or academician has comprehensively ,olved the problems in performunw appraisal", in fact, no two people completely agree on how to solve the isY ,;."1 The field has apparently not progressed very far since 1972 when Cohen and Brower pointed out that "... we are still at the most rudimentary empirical stage la performance appraisal)...."2

If one accepts these conclusions, then it would seem that there must be certain inherent characteristics within the structure and processes of organizations which are contributing factors. Thomas F. Gilbert offers the following pessimistic and unflatter- ing assessments:

1

# 2

# Performance Appraisal

Information is frequently inadequate and misleading, managers often do not really know how well people are performing.

Job models seldom ekist to tell people precisely w hat important results they are supposed to accomplish, how these results are measured, a id w hat standards of performance are expected of them.

Behavioral conditions for perfoimanke are rarely well supplied by management to see that people hake the best data, feedback, resources, procedures, incen- tives, and training in order to meet exemplary standards.'

Finally, the topic of performance appraisal is iewed at worst as a necessary evil in private industry and many organizations in the pulls In the field of education, the reser\ ations are much more serious, paruk Lila') in regaid to post tenure appraisal of faculty. Formalized appraisal prokedures are seen by many as unworkable, detnmental to collegial relationships, and a threat to academic freedom.;

# sector.

While the authors rekognize the aforementioned problems and issues, we remain optimistic. The results of the past 25 years of researkh and obserk miens of organiza- tional practice do not support a conk lusion that performance appraisal cannot be accomplished. These results simply suggest that designing and implementing a legal, In fact, accurate, and cost effectike performance appraisal program is not an easy task. every organization must appraise performance bekaik,e dekisions must be made in such vital areas as tenure, promotion, and merit pay adjustments whirl: require the measure- ment of work contributions.

## Evolving Purposes of Performance Appraisal

A comprehensike perfomiance appraisal system should provide the framework to make both administrative and professional decisions Michael Skrik en's "formative- summative" ek ;dilation concept is w idely recognized and accepted.' Theoretically, data from the formative dimension of perfornianLc appraisal can be used for professional development decisions, and data from the summame side Lan be t.sed for personnel management decisions. Many educators, researchers, and prat. tiling professionals, however, continue to koikk the concern that one appraisal sy stem Lannot sere both purposes.',s Wilkinson contends that attempts to konstrukt a single comprehensike system which serk es both fonnank e-summank e functions would be' an impossible task!) Conversely, according to the research team of Darling I lammond, Wise, ind Pease, the approaches are not mutually exk him% e if the performance appraisal yields, on the one hand, objective, standardized information for akkountability and, on the other, descrip- tive information for individual staff development.w

Although there 1, disagreement among some of the authorities in the field regarding the dual use of a formamc sammath e ekalLation approach, as applied to a performance appraisal system, the kontrok ers) surrounding the supposed incompatibility between formative and summanke purposes of appraisal is confined largely' to educational

1

nJ

# An Overview 3

research and writing. The issue does not receive a gieat deal of attention in manage- ment literature, nor is it viewed to be a majoi problem in many organizations. There- fore, the authors hold to the ' iew that a single approav h, v. hen carefully des.gned and properly implemented, can serve a variety of purposes.

# Professional Development

Many authonties consider professional de\ clopment to be' a

# cry important aspect

of performance appraisal. Research has led to the following convlusions.

Individuals are very interested in knowing more about the fay tors affecting their performance and their careers.

Administrators are reluctant to discuss these issues.

Most administrators have not found a direvt approavh to professional develop- ment issues.n

Using the results of performative appraisal ii career dev Llopment can help indi- viduals in identify ing and overcoming blocks to their progress and in developing, strate- gies for improvement as they mote through various stages of their career. This could be diagnostic, for example, statistically analyzing the links between performance ratings and career stages. Ratings can also be used directly to help staff members understand what they must do to become or remain high performers.12

# Placement in the Organization

There are several types of plavement decisions in W,

hiLh performance ratings may be used The first deals with an individual's ad\ anvement ;11 the organizational struc- ture. Examples include faculty member to depaitment chair, library teLhnician to assistant librari 111, and comptroller to business manager. Job behavior and activities are often more revealing than tests and inter\ tews for predivting, future performance. Thus, positive performance ratings often are used as promotion criteria. It is unrealistic to assume that because individuals are performing well on a job that they will succeed at the next higher level, particularly when they are Lonsidered fur promotion from lower to upper level positions. Deliberations over which candidates will be chosen for promo- tions always should begin by matching the requirements of the job \s ith the applicant's qualifications It is possible to identify certain aspects of performance on a present job that can he useful in predicting performative in a different assignment. For example, if a faculty member received good ratings in Lhairing faculty committees, this would be a major consideration in a possible promotion to depaument head. On the other hand, a faculty member ,dio had difficulty with daily administrative details would be a poor prospect for an administrative assignment.

41

A.

# 4

# Performance Appraisal

The second type of placement deals with the professional, 1 athLr than administra- tive hierarchy The most perk asiv e ex,miple is found in the faL tiny . Decisions must be made regarding the awarding of tenure and promotion in iankind in some Lases both at the same time For example, an assistant professor Loald be tenured and pi omoted to associate professor simultaneously. These type deLisions foLus on different dimensions of performance; however, accurate assessment of appiopnate behavior and outcomes such as teaching success and community' service' can still be achieved.

Placement also has a negative aspect. An indiv !dual w 110 is performing poorly may need to be transferred into a new job in which prospects for adequate performance are feasible. Again, performance appraisal results that identify both strengths and weak- nesses can provide information about the type of job that better utilizes an indiv idual's strength. These results reduce or eliminate those areas w here deficiencies exist.

There will be cases where, regardless of the best efforts of the organization, an individual is either unwilling or unable to meet reasonable eveLtations of job perfor- mance. is necessary to use ilk. results of performance appraisal for such adverse actions as demotion, suspension. probation, 01 termination.

# In these eases, it

# Compensation

An organization's reward sy stem includes an thing an employ ec aloes that the employer is willing to offer in e \change foi the employee's contra- mons. One impor- tant reward is compensation. is logical that the amount of an individual's salary increase should be related to job performance during a vecific period. Many organiza- tions base the amount of mtrit raises directly on perforwanLe ratings. There are three reasons to relate salary to performance. First; as a society v e are Lommitted to a sense of equity that suggests that rewards and performance should be related. Second, research in motivation shows that if compensation is to be a motivator, people must see a clear, positive correlation with performance Third, research also shows that out- standing performers prefer to work ill and remain in meritocracies.' 3

# It

There are authorities in the field w ho feel that Compensation decisions should not be linked to performance appraisal. The contention is that during the performance appraisal conference, the individual is most LonLerned with the amount of the raise and not with such important matters as productiv it) improvement and professional devel- opment. Therefore, an employee is likely to conLenti ate Oil how the mating will translate into dollars and to ignore all else.

While this issue cannot be resolved completely, it seems reasonable that if an orga- nization is willing to invest the time and resourLes needL.I to develop a job-related performance appraisal system, the results should be used in the compensation program. The argument that if individuals know their pay fracases are related to performance ratings, the other purposes of performance appraisal somehow \sill be minimized can be stated conversely. The person may feel that if ratings have no influence on salary, then the organization is not serious about performance appraisal.

# An Overview 5

The major concern with Lsing performance appraisal results m compensation pro- gram decisions is s hether or not the s) stein aLtuall) measuies employee contributions. Most of the dissatisfaction w ith merit pa) Lau be na.ed direLti) to s) stems that produce highly subjective and frequent!) meaningless rating~. SuLh ratings has e little to do with how well people fulfill their obligations to the organization.

# Legal Considerations

Performance ratings, when used to justify dc,.isions related a., such areas as promo- tion, merit pay, and terminations, are subject to federal and state laws and regulations which prohibit discrimination based on race, color, sex, religion, national origin, age, and handicapping condition. The centerpiece' of EEO Legislation is Title VII of the Civil Rights Act of 1964. Beginning with the landmark case, Griggs v. Duke Power Company, both the courts and the Equal Employment Opportunity Commission (EEOC) have mandated that appraisals be based on criteria which ale valid or job related. While it is not impossible to prose job relatedness to the satisfaction of a com- pliance agency or court, certain essential steps must be followed. What is required, "... at a minimum, is a degree of logical argument and factual es idence, not just a subjec- tive appeal to intuition and so-called common sense."' I

An institution which loses a Title VII case is subject to back pay awards which can be substantial in a class action suit. In addition, courts usual') allow the prevailing party to recover attorney fees. There 'lase been Lases where courts have found defen- dants to be personally liable for violating the rights of mills iduals. Finally; a court is likely to impose hiring and promotional quotas, as well as requiring the employer to revise its selection practices. Es en if the employer wins, a lawsuit is sery costly. Time and resources insested in research and anal)sisanswering interrogatones, and prepara- tion for trial, unlike attorney fees, cannot be recovered.

## The Selection of a Performance Appraisal Technique

## Many performance appraisal methods and techniques

are used today. As might be expected, no method can be expected to accomplish all of the objectis es of the process and all has e advantages and disadsantages. The selection of a method or combination of methods should be based on accommodating legal requirements. current research; proposed uses of appraisal results, institution t) pc, Llimate,, and mission, and organiza- tional resources.

It is probably safe to suggest that there are a number of techniques w luLh are both effective and legall; defensible and an equally large numbei which should be rejected out of hand for failing on both counts. A soilless hat neglected area is cost sersus bene- fits. As will become e-ident. the des Llopment and administration of a performance appraisal program is expensive; and the value of post appraisal benefits such as increased motivation and better administratise daimons should be at least equal to the costs in time and resources.

# 6

# Performance Appraisal

# Criterion -)evelopmerl

Regardless of the technique used to measure jib performance, the adequacy of the criteria measures is a critical issue. There at.: various types of job performance measures which can emphasize both work outtJut and judgmental data. Work output can be observed and tabulated such as nutaber important committees chaired, number of public service activities conducted and the number of professional presenta- tions and publications. Such measures are seen to be highly objective. In fact, one advocate of such measures in appraising performance of faculty members uses the expression "either you did it or you didn',. "j5 There is little question, however, that judgmental data is unavoidable. Most jc bs require information from superiors who directly and continuously observe the quail y of the work. The distnist of these kinds of measures and the possibilit; of bias make it essential to carefully develop and scale behavioral measures.

In criterion development, job analysis sc-es both a legal and technical purpose. The legal role is well established in both the 'Uniform Guidelines" and in a series of court decisions. A thorough and competent jo) analysis establishes the rational link between the content of the job and the content of the performance measure. According to Donald Schwartz, EEOC personnel research psychologist, "the absence of a job analysis is fatal to a validity study in a court challenge." 16

In regard to the technical or professional requirements for job analysis, there are a number of acceptable methods. In selecting a method or technique, the focus should be on ensuring that the method or combination of methods representatively samples significant job tasks Although it is highly desirable, it is not possible t.) specify one clear, suitable, standard means for meeting all the technical and legal considerations of a job analysis.!' The lack of such a standard, however, should not be viewed as a major problem.

# Measurement Accuracy

The final outcome of a performance appraisal program is, of course, the rating. Unfortunately, the process is not self regulating. Measurement accuracy is a serious concern; in fact, various types of later errors can undermine the validity of the most carefully designed system Performance appraisal programs must have the support of top administration; much more than a speech and a Lover memo. At a minimum, all levels of management must take performance appraisal programs seriously.

It is also necessary to address tendencies and perceptual inaccuracies of raters. There are a nutubL_ of common sources of error in perfot mance appraisal which can be controlled with an adequate rater training program. While these problems cannot be completely eliminated, both accuracy and reliability Lan be brought to manageable levels.

# An Overview

# Instrumentation

Finally, there is a need to set concepts and theories into operation so that perfor- mance appraisa' can be implemented under standardized and controlled conditions. Instrumentation often does not receix e adequate attention. In too many cases, the actual performance appraisal forms are either "off-the-shelf' or poorly designed. Each organi- zation will, of coarse, have different requirements depending on the technique that is selected.

# Concluding Comment

This discussion has raised a number of important issues regarding performance appraisal in postsecondary institutions and there arc obviously many others. It should be apparent that there is no perfect solution to the problem of measuring work-related contributions to objectives. But the point is that performance appraisal is an essential part of the management job. There is real value in the process and the forces pressing for performance appraisal w ill only become stronger. While it is important to seek help from the literature, it is also possible to be overwhelmed with conflicting information. Too often this leads to a feeling of futility and a decision to ax old facing the issue until a unified model has appeared. This will not happen. The task of institutions is to inte- grate proven concepts into their on model, aN old the mistakes of others, and move forward.

# Endnotes

1.

Evelyn Eichel and Henry E. Bender,. Performance Appraisal. A Study of

Current Techniques, (New York. American Management Asso.ations, 1984), p. 9.

2.

## Arthur M. Cohen and Florence B. Brawer, Confropith g Identity: The

Community College Instructor, (Englewood Cliffs, NJ. Prentice Hall, 1972), p. 186.

Thomas F. Gilbert, "Analyzing Productix e Performance," in Handbook of Organizational Behavior Management, ed. Lee W. Frederikson (New York. John Wiley and Sons, 1982), p. 127.

3.

4.

Christine M. Licata, "Post-tenure Faculty Evaluation: Threat or Opportunity," Executive Summary, ASHE ERIC Higher Education Report I, (Washington, DC: Association for the Study of Higher Education, 1986), p. 1.

- 5. Michael Seriven, "Summative Teacher Evaluation," in Handbook of Teacher

Education, ed. Jason Millman (Beverly Hills, CA. Sage, 1981), pp. 244-271.

Hans A. Andrews and William A. Nlarzano, "Faculty Evaluation. Stimulates Expectations of Excellence," Community and Junior College Journal 54 ,December January 1983-1984), pp. 35-37.

6.

7.

## Peter Seldin, "Improving Faculty Evaluation Systems," Peabody Journal of

# Education 59 (January 1982), pp. 93-99.

# 7

# 8

# Performance Appraisal

8.

## Arthur M. Cohen, "Evaluation of Faculty," Commands College Review 2

(Summer 1974), p. 12-21.

9.

L. Wilkerson, "Faculty Development." Paper presented at Conference of

## Professional and Organizational Development Network, Memphis, 1979.

- 10. Linda Darling-Hammond, Arthur E. Wise. and Sara R. Pease, "Teacher Evaluation in the Organizational Context. A Review of the Literature," Review of Educational Research 53 (Fall 1983), pp. 285-328. Paul H. Thompson, Robin Z. Baker, and Norman Smallwood, "Improving Professional Development by Applying the Four Stage Career Model," Organizational Dynamics 15 (Autumn 1986), p. 50.

12.

# Ibid., pp. 54 and 62.

Edward Lawler, "Performance Appraisal and Merit Pay," in Creative Person- nel Practices. New Ideas for Local Goternment, ed. John Matzer, Jr. (A ashington, DC: International City Management Association, 1984), p. 75.

13.

14.

## James Ledvinka, Federal Regulation of Personnel and Human Resource

# Management, (Boston: Kent, 1982) p. 43.

James L. Smith, personal communication, March 1987. Dr. Smith is the Head of Personnel and Staff Development for the Cooperative Extension Service, Auburn University and has designed a faculty appraisal system that has withstood several court challenges.

15.

- 16. Bureau of National Affairs, "Professional Legal Requirements of Job

Analysis Explored at Chicago Conference," Dail) Labor Report,. May 30, 1980, p. A5. 17. Robert D. Gatewood and Hubert S. Fad, Human Resource Selection,

# (Homewood, IL: Dryden, 1987), p. 176.

%.3

# Legal Aspects of Performance Appraisal

# James A. Buford, Jr.

Although most of the attention in the area of equal employment Opportunity has been focused on recruitment and selection, the performance appraisal process is subject to the same laws and guidelines Decisions related to promotion, selection for training programs, wage and salary administration, discipline, and even dismissal come from performance appraisal results. Title VII of the Civil Rights Act of 1964 prohibits employment discrimination based on race: color, ieligion, sex, or national origin. The Age Discrimination in Employment act of 1967 prohibits discrimination against people age 40 and over The Equal Employment Opportunity Commission (EEOC) has been given legislative responsibility for enforcing these acts. In 1966 the EEOC issued its first set of "Guidelines" relating to the employer's obligation to develop nondiscrimi- natory personnel procedures. They were revised in 1970 and again in 1978.1

# Major Court Decisions

In 1971 the U S. Supreme Court in GriggA r. Duke Poucr Company issued a land- mark decision regarding Title VII. Hie effect of the Court' decision \\, as to establish a requirement that if any employment practice or "test" has an adverse impact on members of a protected group, the employer must demonstrate that the practice is valid or job-related 2 The decision also gave the EEOC "Guidelines" essentially the force of law in developing personnel procedures Performance appraisal results, \\, hen used to justify personnel decisions, are clearly covered by Title VII and related laws.

T.1 1973 the court stated in Brito r, Zia Compahl that the organization had violated Title VII when, on the basis of poor performance ratings, it laid off a number of employees The court said the practice was illegal because ; I ) a disproportionate number of Hispanic workers were laid off and (2) the performance appiaisal instrument was not related to important elements of work beim\ an but was based on "the best judgments and opinions of supery isors" and \\, as not administered and scored under controlled and standardized conditions. The decision also clearly established that per- formance ratings were employment "tests."

2

# 10

# Performance Appraisal

There was a similar case invols ing a university in 1974.

In Wade v. M.s.sksippi Cooperative Etten.sion Service, a U.S. District Court noted that what the organization had called an "objectise appraisal of performanLe" actually w as based on supersisory ratings of traits such as leadership, public acceptanLLtttitude, grooming, personal con- duct, outlook on life, resourcefulness, and loyalty .4 The cow t ruled that the results of such appraisals retained black employees in nonsupersisory pustons and that the results could not be used as promotion criteria. The court ordered the Extension Service to develop an appraisal system that would meet the requirements of the EEOC "Guidelines." Both of these cases are classic examples of disLrmmation as defined in the Griggs case.

In 1975 the U.S. Supreme Court ruled in Albemarle v Moody that becaus,e job analysis had not been conducted, the company could not use performance appraisal ratings to validate selection requirements which eliminated a disproportionate number of black applicants.' The importance of adeqoate job analysis continues to be empha- In Greenspan v The Automobile Club of Michigan, a case brought in 1980, the sized. court criticized the method used in analy zing jobs, stating, "The analyst did not verify job description by making an on-site inspection of the employee who actually per- formed the job.. .."6 The major requirement in job analysis for performance appraisal purposes is to ensure that the dud collected pros ides accurate information about work behaviors critical on the job.

# EEO Liability

EEO laws and court decisions attempt to eliminate race sex, or age discrimination, and liability can be triggered in at least three general way s. intent to discriminate, dis- parate treatment, and disparate or adverse impact.

Intent to discriminate was the major Lonsderaton in discrimination cases prior to the passage of Title VII. Persons seeking recourse had to prose that the employer deliberately set out to discriminate against them on the basis of raLL. (there was no pro- hibition against sex or age discrimination). Intent to discriminate is eNideneed by the following examples:

A rater delibe' rely gives lower performance ratings to black employees.

Prejudicial statements are made sail as "blacks Lainnot handle management responsibilities."

## Policy statements endorse illegal practices such as job segregation.

At the present time, intent to discriminate

# not a major factor in EEO litigation;

however, evidence of such actions will discredit any defense raised by an employer.

Disparate treatment °cus when members of protected groups are treated differ-

ently from other employees. Examples of this include:

# Legal Aspects

A black and white employee receive different ratings when there is no observ- able difference in job performance.

Male employees receive day -to -day counseling to improve their performance ratings. Female employees do not.

Disparate treatment is a frequent cause of discrimination complaints. Under present law it is not necessary to provide evidence of "evil intent", all that is required to establish the fact that a procedure or practice is not carried out consistently between individuals or groups.

Disparate impact occurs when barriers which appear to be neutral have an adverse effect on members of protected groups. There may be no intent to discriminate or evidence that one group or individual is treated differently from another. In many cases, statistics alone are sufficient to establish disparate impact. The EEOC and the courts have adopted the 80 percent rule for such cases. The rule states that any selec- tion ratio (e.g., number promoted s. number eligible) for members of protected groups must be at least 80 percent of the majority selection ratio.' Examples include:

A statistical analysis reveals that blacks receive significantly lower performance ratings than whites.

Performance ratings lead to differential promotions, training opportunities, merit raises, or dismissals.

Disparate impact focuses on the effect of practices and procedures rather than the

causes. Another term that is used for disparate impact is systemic discrimination.

Intent to discriminate and disparate treatment can involve individuals or groups of people who are members of a protected class. Disparate impact normally involves groups. The ex:stence of any one can start a chain of ck ents known as the EEO liability process.l

Typically, an organization first lc firms that it has been accused of discrimination when it receives a notice of charge from the EEOC. If there is a state fair employment practices agency, the EEOC must defer to that agency before beginning its on investi- gation, The deferral agency may process and settle the charge. If the charge is not settled, or the agency waives jurisdiction; the EEOC will re-assume jurisdiction. The EEOC will first invite the employer to attend a "no-fault" conference to resolve the If, in the opinion of the EEOC representative, the charge has merit, there If the charge is found to be without merit, the

# nlaint.

will be an attempt to obtain a settlement. EEOC will issue a "no-reasonable-cause" finding.

If the representative is unable to settle a charge which is thought to have merit, the EEOC will then conduct a full-scale investigation. The EEOC has the authority to subpoena and question witnesses under oath. If the investigation results in a finding of

# 11

# 12

# Performance Appraisal

"cause," the EEOC w ill again attempt to conciliate the matter. At this point, concilia- tion remedies might include back pay, promotion, changes in procedures and relief for others similarly affected If the investigation reseals "no-reasonable-cause," the EEOC will issue a right-to-sue letter to the complainant. Faced with a finding of "cause," the organization will often elect to settle the case rather than take a chance on losing in court. If conciliation fails, the EEOC has direct access to the courts, and will consider litigation based on the merits of the case. Actually, most charges do not result In litiga- tion but are resolved through administrative action.

If the case goes to court, the complainant (plaintiff) must, as shown earlier, prose a prima facie case of discrimination by showing intent to discriminate. disparate treat- ment, or disparate impact. This is the first burden of proof in a discrimination case and is always carried by the plaintiff.

Once the plaintiff has established a prima facie case in a disparate treatment claim, the employer must articulate some legitimate, non discriminatory reason for making the decision. When disparate impact is established, the employ er must shcw that the practice or procedure has a "manifest relationship" to the job in question. This holds even when the criteria are, by necessity, "subjective or discretionary" in nature. The employer may show that the practice is necessary to fill a legitimate business requirement. This is known as the defense of "business necessity." Another defense is to demonstrate that the practice is valid or job-related according to the "Guidelines." There are variants and combinations of these defenses, but the important point to remember is that, once a prima facie case has been established, the employer is presumed to have violated Title VII unless the employer can show otherw ise.8 The second burden of proof (some authorities use the term burden of production) in an EEO case is always carried by the employer.

If the employer's defense is successful, the plaintiff must show that the employer's reasons were, in fact. only a pretext, or that alternate selection methods having less adverse impact are available. This third burden is carried by the plaintiff. EEO cases, however, are normally decided on the basis of whether or not employers can demon- strate that their practices are job-related (see Figure 2.1).

The discussion above outlines how a charge would typically be decided in a court case. Most charges, of course, do not result in actual litigation, but are resolved by the EEOC or state agency through administrative action, either by a "no cause" finding, or, if "reasonable cause" is found, through conciliation.`

An employer who loses a Title VII case is subject to back pay awaids (which can be substantial in a class action suit). Also, courts normally allow the pres ailing party to recover attorney fees. There 'lase been cases where courts hive found defendants to be personally liable for violating the rights of individuals. Finally, a court is likely to impose hiring and promotional quotas, as well as requiring the employer to revise its practices. Even if the employer w insi lawsuit is sexy costly. Time and resources

# ,,.5

!.

rJART ) -------

# EMPLOYMENT DECISION IS MADE

## CHARGE OF DSCRIMiNATION IS FILED WITH EEOC

# 1 YES

# CHARGE iS DEFERRED TO STATE AGENCY

# 1 YES

(

# STOP

)

# EMPLOYER WINS

# NO 44

# BURDEN SHIFTS BACK TO PLAINTIFF

I (- STOL _,)

# YES

## EMPLOYER LOSES (COURT WILL IMPOSE APPROPRIATE REMEDYI

C.---77OFT----)

# EEOC ASSUMES JuRISD.CTION

YES4.

## EMPLOYER LOSES (COURT WILL IMPOSE APPROPRIATE REMEOYI

(

1

# STOP

# NO F AULT CLAyFERENCF IS HELD

# IYES

(_ STOP )

# BURDEN Slirr T S TO EMPLOYER

)

(

# I NO

# EMPLOYER WINS

# i

# STOP

r7 i,) .:

)

# FA:71Fr L. CARRIES

# OF PROOF [BURDEN

# EEOC ATTEMPTS

# LONC,A710N

# oHAFIGING PARTY FILES SJ,T

# EEOC FILES SI in

# YES

# EEOC ISSUES

111H11 TO SUE ..

# NOTICE

# NO

(

# STOP

)

# NO

# EFLOC CDNDUCTS LITIGATION REVIEW

# LITIGATION APPROVED

# YES

# 14

# Performance Appraisal

invested in research and analysis, answering interrogatories, and preparation for trial, unlike attorney fees, cannot be recovered.

There are three basic approaches that may be used by an employe' to minimize EEO liability. The first is to hire, promote, and administer salaries without regard to performance. For example, promotions could be based on seniority, and across the hoard raises could be given. The employer could thus ensure that there would be no adverse impact, and a prima facie case could not be established. The second approach would be to continue current invalidated practices and wait for the EEOC or minority applicants or employees to take legal action. Many organizations follow th:s practice. A third anproach would bt to assume that performance appraisal practices \N, ill have adverse impact and validate each practice in accordance with the "Guidelines."

The third approach is recommended. The idea of being prepared to defend the organization's performance appraisal practices after a prima facie case has been estab- lished does not mean that adverse impact is something that should not be avoided whenever possible. One does not purchase automobile liability insurance with the intention of causing a traffic accident. In fact, insured motorists are likely to be safer drivers. It is also true that job-related performance appraisal practices ha\ e less adverse impact.

# A Validation Strategy

a o minimizing EEO liability is realistic and well within the capability of any organization. Although no system can be made "lawsuit proof," there are measures which can reduce the possibility of systemic discrimination. The approach recom- mended here is based on a strategy of validation. By requiring the validation of perfor- mance appraisal systems according to the "Guidelines," this strategy ensures adequate defense if an employer is charged with discrimination.

Not all authorities in personnel nnagement recommend the strategy of validation. One view held by the opposing group of practitioners. writers, and consultants is that validation can be done only by experts and that another strategy, namely reducing or eliminating adverse impact, is preferred. Although it is true that validation is required only where a practice is having an adverse impact, such reasoning is not compelling. In the first place, if one accepts the definition of validity, that a procedure or "test" measures what it purports to measure, then validity itself is a legitimate end. Why would an organization not take steps to ensure that its performance appraisal system was measuring job performance? Another problem with a strategy of reducing adverse impact is that this approach implicitly questions whether members of protected groups can perform adequately even when the system is fair. They can and do. Finally, the 'Uniform Guidelines" provide validation methods. and one of these (content validity) can be accomplished without the need for statistical expertise. A checklist for legal requirements is shown in Appendix B.

# 1 ::gal Aspects

Reducing or eliminating adverse impact and improv ing the utilization of protected group members in all parts of the v ork force is more properly an objective than a strat- egy. Employers whc find themselves accused of Title VII violations because members of protected groups are either rejected for promotion at a disproportionate rate, under- represented in the work force, or receive lower pay are usually unable to successfully defend in court the practices in question. An analysis of these cases strongly sugge,ts that these employers have almost always waited until they got into trouble before they attempted to justify their practices, many of which were not job-related. These employ- ers were, to use a common expression, "a day late and a dollar short." Thus, a strategy of validation would seem to hav two major advantages. First, it addresses the problem of systemic discrimination, which Congress and the courts have identified as the major barrier to fair employment. Second, validation contributes to better administrative decisions.

The best sr ategy for demonstrating that a performance appraisal system is job- related is known as content validity, in w hp:h a procedure is justified by showing that it representatively samples significant parts Df a job. The following excerpts from the "Uniform Guidelines" define content validity in more detail.

A selection procedure* may be supported by a content validity strategy to the extent that it is a representative sample of the content of the job.

.. a content validity strategy is not appropriate for demonstrating the validity of selection procedures which purport to measure traits or constructs such as intelligence, aptitude, personality, common sense, judgment, leadership, and spatial ability. Content validity is also not an appropriate strategy when the selection procedure involves knowledge, skills, or abilities which an employee will be expected to learn on the job.

There should be job analysis which includes an analysis of the important work behaviors required for su :cessful performance and their relative importance. Any job analysis should focus on work behavior(s) and the tasks associated with them.

To demonstrate the content validity of a procedure, user should show that the behaviors demonstrated in the selection procedure provide a representative sample of the work product of the job. . The closer the content and the context of the selection procedure are to work samples or work behaviors, the stronger is the basis for showing content validity.10

.

.

- The term selection procedure refers to any procedure used for any employment deci- sion; thus a performance appraisal procedure is a selectioa procedure within the meaning of the "Uniform Guidelines" (see Section I6Q).

# 15

# /6

# Performance Appraisal

# Related Considerations

While the classic defense against adverse nupaLt is tin the employ er to show job- relatedness, the situation is not so simple w ith performanLe appraisal. StnLe it is diffi- cult or impossible to develop a completely objeLti%e system, there always will be ele- ments of supervisory judgment. Courts ha% c %dried their Lriteira for finding discrimi- nation. Factors which are considered include. the facts in the case, the degree of adverse impact; if the criteria are objective. subjective. or sonic combination, and whether or not the practice operates to perpetuate the effeLts of earlier intentional discrimination.!! Thus, extreme care should b,: taken in the choice of measures, standardization and control of ratings. training of raters. and aridly sis of results to ensure that ratings arc not biased by (age) race, color, sex, national origin, or religion.!'

Two recent studies examined empirically the effeLts of 13 appraisal system characteristics on the verdicts in 66 federal court Lases imol% ing charges of discrimina- tion. Five characteristics were found to Lorrelatc strongly with judgments for the defendants.!:

1.

# Type of Organization

Public seLloi organizations were more likely to

receive a favorable verdict than private businesses.

Provision of Written Instructions Mn a) courts have held the v rew that the provision of written instructions, while no guarntee. is a pi crequisite for systematic, unbiased appraisals.

2.

3.

## Traits vs. Bella% lora I-Onented Appraisals

Courts are far more likely to

## accept behaviorally-based performance appraisal systems.

4.

Use of Job Analysis Defendants ha% c won approximately, 82 percent of the

time when the system was based on job analysis.

5

Review of Appraisal Results Defendants were moiL suLLessful when results

of the appraisal were discussed with the employee.

# "At Will" Liability

Beginning N,.ith the industrial re% olution. the employ cc-employ el relationship in the United Stag'~ has been co% ered b) the common law door me of "employment-at-will." Under this doctrine, either the employer of employ ee can terminate the relationship ,tt any time and without giving reason.

The doctrine clearly favors the employer, since it contains the right to arbitrarily dismiss an employee. Increasingly, howeci, this light has become subject to both statutory and judicial restrictions. As has been pointed out, the effect of federal EEO laws has become a majoi constraint. In recent years, however. both federal and state courts have created new legal rights for employees including those w ho are not members of protected groups (women, In regard to

# , persons 0% er 40, etc.).

t her J

# Legal Aspects

performance appraisal, employers may encounter legal liability when they attempt to discharge employees for poor performance. Two impoitant soinces of at -will liability involving performance appraisal are breach of contract ac ' violation of the implied convenant of "good faith and fair dealing."11

There have been a number of successful lawsuits w here the employer has been charged with breach of contract Representation made in employee handbooks, poli- cies, procedures; and direct or indirect statements are implied contracts. Once a contract has been found to exist, either in fact or by implication; the employee has a iegal claim if its terms are not followed. The common claim of breach of contract is when employers fail to follow their ovum specified procedures when discharging employees for poor performance.15

Courts are also allowing wrongful discharge suits where termination constitutes a violation of the implied convenant of "good faith and fair dealing." Arbitrary and unexplained firings are often overturned, and courts are making it clear that employees are entitled to varying amounts of organizational due process.'' Employees of public institutions have additional due process rights guaranteed by the 14th Amendment to the U S Constitution In other words, an employee who is being dismissed or pressured to resign (constructively discharged) for poor performance should have an opportunity to defend his or her performance and be judged in a fail Vs,l) with explicit know ledge of the criteria on which the dismissal was based.

# Closing Remarks

Disparate impact is a major issue in all personnel procedures.

It is unrealistic- to assume that performance appraisal systems can be designed which will never cause disparate impact or can be made court-proof by establishing business necessity or job relatedness. Moreoer, the area of at-will liability is still evolving. But it has been demonstrated that a performance appraisal system that avoids court problems encoun- tered by other organizations, that meets the v Akin) requirements of the "Uniform Guidelines," and that is administered b) trained raters under standakhzed and controlled conditions will greatly reduce the potential for legal

# liability.

# Endnotes

"Uniform Guidelines on Employee Selection Procedures," Fedet al Register 43 (August 25, 1978), pp. 38290-40223. These were referred to in earlier editions (1966 and 1970) as "EEOC Guidelines

1.

2.

3.

Griggs v. Duke Power Company, 401; U.S. 430 (1971). Brito v. Zia Company, 478 F. 2D, 1200 (1973).

- 4. Wade v Mis.sisAippi Cooperative EttenAion Sat vice, 372F. supp. 126, 7EPD

9186 (1974).

# 17

# 18

# Performance Appraisal

5.

## Albermarle Paper Company' v. Moody, U.S. Supreme Court Nos. 74-389 and

74-428, 10 FEP cases 1181 (1975).

6.

## Greenspan v. Automobile Club of Michigan, 22 FEP, 195 (1980).

"Uniform Guidelines," op. cit., p. 38302. For examples of evidentiary burdens, see McDonnell Douglas Corp. v. Green, 411 U.S. 792 (1973), Texas Dept. of Comtnunity Affairs v. Burdine 450 U.S. 248 (1981), and Watson v. Fort Worth Bank & Trust, U.S. Supreme Court No. 86-6139 (1988).

7.

8.

This discussion of the EEO liability process is taken from Kenneth J. McCulloch, Selecting Employe,: f ..-fely Under the Law, (Englewood Cliffs, NJ: Prentice-Hall, 1981), pp. 165-242.

9.

10.

"Uniform Guidelines," op. cit., p. 38302.

- 11. Watson v. Fort Worth Bank & Trust, U.S. Supreme Court No. 86-6139

(1988).

J. Vernon Odom, "Performance Appraisal: Legal Aspects," in The Perfor- mance Appraisal Sourcebook, eds. Lloyd S. Baird, Richard W. Beatty, and Craig Eric Schneier (Amherst, MA: Human Resoui,-,e Development Press, 1982), p. 112.

12.

- 13. Hubert S. Feild and William H. Holley, "The Rs-lationship of Performance Appraisal Characteristics to Verdicts in Selected Employment Discrimination Cases," Academy of Management Journal 25 (June 1982), pp. 392-406; and H. S. Feild and D. T. Thompson, "Study of Court Decisions in Cases Involving Employee Performance Appraisal Systems," Bureau of National Affairs, Daily Labor Report, December 26, 1984, pp. El-E5.

- 14. A comprehensive analysis of these and other issues including court cases is found in David M. Mackey, Employment at Will and Employer Liability (New York: American Management Association, 1986), see especially pp. 44-47, 55-58, and 61-66. For example, see Weiner r. McGraw-Hill, Inc., N.Y. Ct. App. (1982).

- 16. Board of Regents v. Roth, 408 U.S., 564 (1972). See also Cleveland Board of Education v. Loudernull 470 U.S. 532 (1985), and Yates v Board of Regents of Lamar University System, 654 F. Supp. 979 (E.D. Tex., 1987).

(1),)rJa_r

## Considerations in Selecting a Performance Appraisal Technique

# James A. Buford, Jr.

Performance appraisal systems are built around a number of methods and tech- the institution should

niques. consider the following:

In selecting a technique (or combination of teL

I. Does the technique accurately measure job pet fonnance?

- 2. Does it meet legal requirements?

- 3. Who will perform the appraisal function?

- 4. Can it be administered efficiently?

- 5. Are the post-appraisal befits in the areas of pioduLtiv

# , motivation. and

decision-making likely to exceed the costs?

To provide a basis foransweting these questions. kk C skill explain the characteristics of a number of performance appraisal methods and techniques. the various sources of appraisal data, and conclude with an approach to the question of costs vs. benefits.

## Overview of Performance Appraisal Techniques

Many performance appraisal methods and techniques are used today. No method alone can be expected to accomplish all objectives of the performance appraisal process, and all have advantages and disadvantages. The methods described in this section are those that are most common. They include graphic rating scales, essay appraisals, comparative methods, checklist methods, Lruical modems, performance standards, behavioral scales, and management by objectives.

J

3

# 20

# Performance Appraisal

# Graphic Rating Scales

Introduced in 1922, the graphic rating scale is the oldest and most commonly' used performance appraisal technique.I An example is pros ided in Figure 3.1. In this method, a scale n- used to rate the akin, kiwi on seL end factors. The rater scores each factor on a continuum from low to high.

Graphic rating scales Nary in two important ways. both UN, ing a major impact on

# reliability and validity.

The first way that graphic rating scales Nary inN, oh es the factors to be rated. These may be a list of traits such as leadership ability, Inman re, honesty, and attitude. The problem with these factors is that they are highly subjeLtos e and may not apply to the job. For example, it is difficult to define and measure a trait such as leadership ability. Moreover, this trait will not always be releN ant, as in the Lase of a bookkeeper. In most cases, trait-based scales will not meet alidity requirements of the EEOC and the courts when used to justify decisions regarding pruinotion, merit increases, and dismissa1.2

Figure 3.2 is a rating scale format that has been dimensionalized and weighted. These factors are based on job domains or major responsibilities and the relative importance of each as established by job analysis. When used w ith an accurate job In a more detailed version of the dimen- description, this format is very job-related. sionalized rating scale format; the factors to be rated describe actual job behaviors and are known as performance standards. An example is shown in Appendix A. In general, the more factors there are that are' ob-specific and can be either quantitatively measured or at least observed, the higher the degree of reliability and validity that can be obtained.

The second way that graphic rating scales vary is the manner in which total scores are assigned. In many cases, ratings are simply added together. how eNer, the addithity assumption may not be valid because the factors are not equal in importance.

Ratings are more meaningful when they are weighted in aLcordanLe with their is possible to importance to overall job performance. With quality job analysis, it develop rating scales that are weighted on an appropriate basis such as amount of time spent, frequency of performance, or relative importance For example the factor used to rate instruction probably, would receive a greater weight man community service, even when both are part of the job. About 7' percent of graphic rating scales used today are similar to the one shown in Figure 3.1. They are unwetghted and are focused on traits rather than job-related behaviors.3

In isolation, a trait-oriented scale is of little use in providing feedback to individ- improvement. However, graphic rating scales are relatively simple to develop, u, easy to undet stand, and less time consuming to administer than other techniques. They

# Considerations in Selecting

# Name Department

# EMPLOYEE RATING

# FORM Classification Date

# RATING

# PERFORMANCE FACTORS

# Poor

1

# Fair 2

# Average 3

# Good Excellent

4

5

- 1. Knowledge

- 2. Initiative

- 3. Cooperation

- 4. Dependability

- 5. Adaptability

# In

[11

# Li iL _ El

F__.

# Li]

# El

[I]

# Llij

# El L. H

---1 L L.

r--- 1 L__ ,

L___,

l___i

L_;

# r-

# L

# El

L_J 71

L____J

- 1L_J Ei

'

- 6. Attitude

# Lr_

L._

- 7. Judgement

- 8. Creativity

- 9. Leadership

- 10. Punctuality

# Ei

# E]nL i

E21

[11

r-L._;

_,

:--- -, L_, __.

L___.

# L

n-___

# i_

Ell 7-,

r--- 7'

COMMENTS:

# Employee Signature

# Date

# Supervisor Sig.lature

# Date

# Figure 3.1 Graphic Trait Rating Scale

# 21

# 22

# Performance Appraisal

# PERFORMANCE APPRAISAL FORM

# PART I

# IDENTIFICATION

# Richard W Martin

## Name Position Faculty Member Rating Period From 10 1 86 Rate. Name

## Douglas Brown Department Chair Social Science

# Rate, Title

_

# Department

# To

9 3.1_8_7

# Date Employed

9 1 80

# PART II

# RATING SCALES FOR MAJOR RESPONSIBILITIES

# A

# Instructional Planning and Preparation

# PCT

10%

Developing and maintaining course outlines selecting instrucbo.nal aids, and preparing classroom presentations

# B

# Instruction

PCT 60°,

Teaching classes as scheduled, presenting material information and skills to be learned, and providing for student evaluation of instruction

# C Testing and Evaluation

# PCT

Developing and administering appropriate assessment procedures for determining student achievement, providing feedback to students, add determining final course grades

10%

- } I

# 0 Student Affairs

# PCT

10% r

Assisting students in curriculum planning, sponsoring student clubs and participating in campus activities and proOding assistance with job placement

# E Administration

# PCT

10%

Maintaining office hours, attending meetings arid carrying ist,t committee assignments, following appropriate procedures aid Policies for submitting reports, requesting supplies and equipment and fulfilling other duties or assignments

# F Professional Development

# PCT

5 0°

Pursuing personal profession:I improvement program partici paling in programs, workshops, and classes to maintain credentials and competencies

# G Community Service

# PCT

5 or.,

Serving as a resource person and providing advisory services within assigned subject matter area, and contributing to welfare of community through participation in areas of interest

# Figure 3 2 Dimensionalizod Rating Scale

iJ

# Rating Scale Key

# ii Felts to Meet Job Requirements

Essentially Meets Job Requirements Fully Meets Job Requirements Meets Job Requirements with Distinction

# E Exceeds Job Requirements

# RATING

[3.]

0

# COMMENTS

# RATING

# COMMENTS

# RATING

# COMMENTS

# RATING

# COMMENTS

# RATING

# COMMENTS

# RATING

# COMMENTS

# RATING

# COMMENTS

0

# O

# C

# Considerations in Selecting

can be highly job- related and can be Lombmed with other methods such as behav- iorally-phrased essay s. To make ratings more meaningful. the rater, along with com- pleting the scale, may be asked or required to justify the rating and to discuss suggestions for improvement in space pros ided for w ritten Lommems.

# Essay Appraisals

The narrative essay is a. desLription of the individual's job performance in the rater's own words. Often, guidelines are pros ided. For example, the rater may be asked to describe such things as strengths, weaknesses, and potential and to make sug- gestions for improvement (see Figure 3.3). The essay approach to performance appraisal assumes that a candid statement from a knowledgeable supervisor about an individual's job performance is just as \ alid as more formal and quantitative methods.;

Narrative essays can pros ide detailed feedback regarding job performance, par- ticularly if the rater uses an accurate job desLription to ensure that all areas are covered. Most essay appraisals, however, are unstructured and vary in length and content. Another problem w ith essay appraisals is that the individual's rating may depend more on the writing skills of the superior than on the individual's performance.5 Finally, this method is highly subjective, time-consuming, difficult to administer, and impractical for large groups.6 Most authorities agree that the essay is best used as a supplement to a more structured method such as the graphic rating scale.

# Comparative Methods

Comparative methods comp re indiv iduals against each other rather than against standards. Individuals may be compared on measures relating to overall job perfor- mance or on several traits or work characteristics. All comparative methods assume that job performance is distributed along a continuum from poor to outstanding. This idea is popular in the military and in the corporate world, where one hears such terms as "top five percenter" and "fast track." The results of these methods produce a listing of individuals from first to last in order of performance. Figure 3.4 illustrates how ranking involves placing individuals in order of overall performance, normally by first selecting the best and worst performers, then designating next be:A, and continuing until all indi- viduals have been ranked. Figure 3.5 shows how paired comparison requires that individuals be compared one at a time w ith every other individual, with the final task rank determined by the number of times an individual was rated better than the other individual. In the forced distribution method, the rater assigns a specific proportion of individuals to predetermined performance categories, as shown in Figure 3.6.

The most elaborate of the comparative methods is founded on the principle of the normal distribution and is analogous to grading on the curve, in which there are a few A's and F's, slightly more B's and D's, and a large number of C's. That there is some proportion of outstanding, good, fair, and poor performers in a department or organiza- tion, however, is an unrealistic assumption.?

# 23

# 24

# Performance Appraisal

Make a clear and concise statement describing the employee's performance on each of the factors below.

## Productivity: Volume of work and major accomplishments

# Accuracy: Meeting quality standards

Coordination: Planning and organizing work and supervising employees

# Fib

# 3.3. Essay Appraisal Format

# Considerations in Selecting

## Cooperation: Working relationships with others

## Know-how: Possession of job-related knowledges and skills

Development: Personal strengths and areas needing improvement.

## Figure 3.3. Essay Appraisal Format (Continued)

# 25

# 26

# Performance Appraisal

Consider the employees in your department in terms of overall jcb performance Select the best employee and put his/her name in column A, line 1 Then select the worst employee and put his/her name in column B, line 20 Continue this process until the names of all employees have been place, on the scale

# Column

# A (Best)

# Column B (Worst)

1.

# Warren Clark

11

2

# Sam Burton

12

3.

# James Strawn

13

4

# Deborah Stitison

14

5

# William Buford

15

6

# 16 Wilson Fowler

7

# 17 Sylvia Watt

8

# 18 Harry Larkin

9

# 19 Robert Lee

10

# 20 John McCord

# Figure 3

## Ranking Scale Using Alternative Ranking Method

Source Adapted from Dale Yoder, Personnel Management and Indusmal Relations (Englewood Cliffs Prentice Halt, 1970) p. 237

# Persons Rated

As compared to: SB WB WC WF I HI_ RL JM DS JS SW

# SCORE

# Sam Burton

# X

# X

# X

# X

# X

# X

# X

# X

8

# William Buford

# X

# X

# X

# X

# X

5

# Warren Clark

# X

# X

# X

# X

# X

# X

9

# William Fowlei

# X I X I X

4

# Harry Larkin

# X

# X

2

# Robert Lee

# X

# John McCord

0

# Debc ah Stinson

# X

# X

# X

# X

# X

# X

6

# James Strawn

# X

# X

# X

# X

# X

# X

# X

7

Sylvia Watt X Note X means that the person s performance is better than the person with whom he,'she was paired For example, Clark's performance is better than any of the uthers Lee s is only better than McCord's

# X

# X

3

## Figure 3.5. Ranking With Paired Comparison

# RANK

2

5

6

8

9

10

4

7

# Considerations in Selecting

Instructions. Assign the employees in your department to the appropriate categories using the following distribution as a guide

# Outstanding (10%)

# Above Average (20%)

# Average (40%)

# Below Average (20%)

# Un- Satisfactory (10%)

# W. Clark

# S. Burton

# D Stinson

# H Larkin

# J McCord

# J Strawn

# W Buford

# R Lee

# W Fowler

# S Watt

# Figure 3 6. Forced Distribution

Another problem with all comparative methods is that individuals are usually com- pared in terms of overall job performance. This kind of comparison limits the useful- ness of the appraLal for providing feedback to the individual regarding aspects of job performance which are acceptable and chum. which need improement.s Therefore, the results of comparative methods are likely to be meaningless and may be damaging to morale since someone must be last. To illustrate how ranking methods distort reality, consider that there is a slowest runner on the U.S. Olympic gold medal 4 x 100 relay team and a fastest runner among 45 to 55 year old finishers in a local "fun run." Comparative methods are not job . _laced and thus are difficult to validate.

One point can be made in defense of comparative methods. An organization may need to determine rankings for administrative purposes, such as a validity check on another method. A supervisor who has rated 10 individuals on a graphic rating scale may be asked later to list the individuals flora first to last in order of performance. A strong positive rank correlation would be expected.

# 27

# 28

# Performance Appraisal

# Checklist Methods

A checklist method known as forced choice was developed by the U.S. Army dur- ing World War II to overcome the problem of lenient performance ratings. Although there are a number of variations, the procedure usually requires raters to select from a group of statements those that are related to the individual's behavior. A group of statements is shown in Figure 3.7.

From each group of statements below, mark M beside the statement which is most descriptive of the employee's behavior and mark L beside the statement which is least descriptive.

A.

Inclined to avoid responsibility

# Takes pride in the job

# Shows poor leadership

# Open to suggestions.

B.

# Exercises good judgement

Tends to resist change

Treats subordinates with respect

# Has gaps in job knowledge

# C

Fails to establish priorities

# Complies with policies and procedures.

_ Pays attention to details. Does not meet deadlines

# Figure 3.7. Forced Choice Appraisal

The rater is required to pick one statement that is most descriptive and one that is least descriptive of the individual. The statements are deigned so that only one of the favorable and one of the unfavorable statement~ is associated with job performance. This information is not provided to the rater, thus, the results of the rating are known only to the personnel department, which has the key. This kind of rating tends to be resented by both managers and 'ndividuals, and feedback is obviously impossible. There are also serious questions as to whether it is possible to develop a set of state- ments that distinguish between good and poor performers.

0 J

# Considerations in Selecting

# Critical Incidents

Critica: incidents are reports made by know ledgeable observers of at tion taken ny individuals who were especially effective or neffeetive in accomplishing their jobs. The critical incident technique, or CIT, was developed in 1954 by John C. Flanagan.9 Critical incidents are recorded by superiors as they happen, thus are short and to the point, and they normally consist of a single sentence. The following are examples of critical incidents that illustrate effective performance:

Conducted formal review sessions outside regular class hours, scheduled sessions so that maximum number of students could attend (Instructor).

Developed reading list of matenals contained in library to support course objec- tives; keyed material to textbook (Instructor).

Prepared for and conducted class when instructor was hospitalized unexpect- edly. Covered all scheduled material for 2-week period (Division Chair).

Critical incidents also describe ineffective or poor performince such as the fol-

# lowing:

Was absent from scheduled class without legitimate rear on and with no notice tc, students (Instructor).

Made several errors in computing students' final grades, resulting in complaints to Dean and reissuing of grade reports by registrar (Instructor).

Failed to hold performance appraisal conference with faculty member (Division Chair).

Critical incidents provide useful information, particularly when they are collected and placed in appropriate categories. For example, an instructor whose critical inci- dents reveal a pattern of innovation, such as developing a reading list, might be consid- ered for a promotion to a position where this characteristic could be utilized more fully. The main disadvantage, of the critical incident technique is that it is time-consuming and burdensome and it may be neglected by supervisors.10

# Performance Standards

Performance standards require a list of conditions that will exist when a job is being performed well. Many organizations have implied performance standards, but these are not spelled out in accordance with job duties. In a formal system using performance standards, a job analy sis is conducted that results in a job description setting forth what is to be done. Performance standards descnbe how much is expected or how well the duties arc to be performed. Figure 3.8 provides an example of perfor- mance standards for an instructional position, in the dimension of "Instruction".

# 29

# 30

# Performance Appraisal

1 Schedule and Attendance ".^(vts L 1,-issw, throughout the quarter Records daily attendan Is cooperative regarding teaching assignments

Eri«)UrciLleS attendance tits lasses for lull time period

## 2 Method of Instruction Varies method of pre,entation '

ri( rt,abt, stuotqit interest Uses class lime on subject ;natter Ent ourades student partiipation Demonstrates overall knowlt dge of subject and presents mater al so that it is understood Dv students Encourages students to seek hip after class if needs a

3 Presentation of instruction I-)resents ntormation liunntly and precisely and stimulates stud, nts interest Attempts to make instruction d pit asant experience for students

4 Student Evaluation Admin[slors student evaluations ar ( ordind to established

procedures Reviews results and uses fenclbac k to improive tear hibij

Figure 3 8. Performance Standards ft r Instructional Position

Standards should be established through negotiations between the individual or group of subordinates and the superior. ,advocates of performance standards recom- mend that they be written in quantitative terms shen possible. However, as the exam- ples show, some job aspects are difficult to reduce to quantitate e terms, therefore, behavioral statements must be made.

The advantages and disadvantages of the perfonnanLe standards approach are as

# follows:11

The participative approach gives both the subordinate and the superior a means of sharing thoughts about work priorities and expected results. This approach tends to earn the subordinate's commitment to achieve standards and the supei ior's commitment to provide support and resources, The subordinate is not surprised b) the appraisal results, standards are known all along so the subindinate Lan identif) ,,ny variances its they develop and correct the problem before the formal appraisal. Appraisals and feed- back interviews are more objective and less Lontentious because the) are based on specified outcomes in the principal job segments tathet than on personality traits.

The principal disadvantage of the performanLe standards appioaLh is the amount of time and thought required to discuss job priorities and develop standards fin ail the sig- nificant 1/4,g-ineets of each job It takes effort to agree on performance standards and define them in ch ar and measurable terms. Although time is diffiLult to schedule, it is time well spent ;ills process requires aunistrators to identify, desLribe, and weigh the various job objectives and results.

# Considerations in Selecting

# Behavioral Scales

The behaviorally-based instrumeid most frequently recommended by industrial psychologists is the behaviorally anchored rating scale (BARS). This scale was origi- nally referred to in the literature as the behavior,A expectation scale (BES), and the two terms are used interchangeably.12

The construction of BARS generally follows procedures developed by Smith and Kendall)", The first step is to collect critical inLidents that descnbe a wide range of behavior and place them in broad categories (e.g., planning, testing and evaluation, instruction, etc.). Each category serves as one performance dimension for appraising an individual. A group of people with knowledge of the job are given the set of critical incidents and categories. Members of the group are asked to match each incident to the category they believe the incident illustrates. This procedure i.) known as retranslation. Incidents that are not a, igned to the same category by a high percentage of the group and those that fall frequently into two or more categories are discarded. Another group of people also familiar with the job are given the final categorized list of incidents and are asked to rate each incident on a five to nine point scale, representing a continuum of job performance from outstanding io poor. The only items retained are those on which there is much agreement. These incidents are used as anchors on the rating scale, hence the term behaviorally anchored. The value git..n to each incident is the mean value assigned by the group. An example of BARS for the position of instructor is shown in Figure 3.9.

5 00-- -Professor can be expected to vary syllabus of class to fit students' background. Emphasis would be placed on projects and discussion rather than lectu.d. Grading is based on quality of projects and tests

4 00-- -Professor can be expectad to meet all classes, to add the lecture with current materials, to answer course material throughly, and present a variety of test methods

3 00-- -Professor can be expected to meet all classes, then deliver organized 1:3

with appropriate standardized testing devices.

2 00-- -Professor can be expected to meet almost all classes and to closely repeat

text, paying little attention to outside material or student questions

1 00-- Professoi can be expected to hold ::.lasses irregularly. Also can be expected to present "true life" examples frequently which have little relationship to course material.

Figure 3 9 A Behaviorally Anchored Rating Scale for the Dimension "Classroom Teaching Performance"

Source Robert 0 Gatewood and Hubert S Feld, Human Resour,,e Sele,,tion, New York Dryder Press, 1987), p 505

# es

# 31

# 32

# Performance Appraisal

While BARS is highly job-related, there are several limitations. The most obv ions problem is that the rater may not be able to match observed behaviors with the scale anchors.I4 There are obviously many more cntical incidents which describe perfor- mance under the domain of "Classroom Teaching Performance" than the five items which are provided on the scale. Another problem is that the rater might observe both "good" and "bad" performance on the same dimension. For example, the faculty member might meet all classes, but during the same period present "true life" examples in class which frequently have little relationship to course material.

A procedure which overcomes these and other limitations of BARS is galled behavioral observation scales (BOS) as set forth by Latham and Wexley .1' The pnmary difference is that BOS is dev eloped by attaching a 5-point Liken scale to identify each behavioral item as shown in Figure 3.10 for the job dimension of "Instruction".

# Begins class on time

# Almost Never

1

2

3

4

5

# Almost Always

# Follows lesson plan

# Almost Never

1

2

3

4

5

# Almost Always

# Uses class lime on subject matter

# Almost Never

1

2

3

4

5

# Almost Always

# Encourages student participation

# Almost Never

1

2

3

4

5

# Almost Always

## Provides outlines, handouts, and bibliographies to students

# Almost Never

1

2

3

4

5

# Almost Always

# Emphasizes topics of mator importance

# Almost Never

1

2

3

4

5

# Almost Always

# Summarizes presentation

# Almost Never

1

2

3

4

5

# Almost Always

# Provides time for student questions

# Almost Never

1

2

3

4

5

# Almost Always

# Figure 3.10. Behavioral Observation Scales for the Job Dimension of "Instruction'

I i.

# Considerations in Selecting

The major advantage of BOS is that raters are forced to make a more complete appraisal of the individual's performance, rather than emphasizing only those items which they can recall at the time of the rating and are able to match with one of the scale anchors.

A final type of behavioral scale, which is less rigorous than BARS or BOS, is an expansion of the performance standards approach. This type of scale attempts to answer such questions as "How good is exceptional?" or "How bad is unsatisfactory?" The scale is constructed by considering task statements developed by job analysis and writing statements which describe levels of performance in each job dimension. The number of levels of performance depends on the number of scale points. The underly- ing assumption is that for each job dimension, all tasks in the dimension will be per- formed in the same general way. The rater selects the description which "best fits." An example of this approach for the dimension of instructional preparation is shown in Figure 3.11.

Behaviorally based scales have several general advantages over other methods. Superiors and subordinates usually are involved in their development. The feedback provided is highly job-related, and performance appraisal sessions focus on behavior that contributes to successful performance. There are disadvantages to these methods. BARS in particular is extremely Lon,plex, requires sophisticated statistical analysis, and is time-consuming. The development procedures for these appr. asal instruments must be repeated for each job, which may not be cost-effective for .nose organizations that have a wide variety of jobs and have only a few individuals a each category.

# Management by Objectives

Although the comparison of results achieved against plans has always been used by managers, Management by Objetmv es (NIBO) was fast proposed by Peter Drucker in 1954.16 As a formal pe formance appraisal system, MBO consists of the following steps:I7

- 1. Organizational goals are

established dining the planning process and

commitment to these goals is established at all managerial levels.

- 2. The key results areas of the job are identified. These are highly selective areas in which the subordinate must achieve an ac,:eptable level of performance to be successful.

The superior and subordinate mutaally agree oa several objectives within key results areas that coincide with cm support °Igo:It/Atonal or departmental goals. Perfor- mance requirements and timetables are established and the subordinate is allocated the necessary resources.

3

# 33

# 34

# Performance Appraisal

METHOD OF INSTRUCTION Presenting letters, demonstration, or laboratory supervision, using appropriate method of instruction and resources, providing out-of-class assistance when necessary.

# EXCEPTIONAL

# a

Uses a variety of methods, aids, and/or resource people as part of presentation, encouraging student involvement. Demonstrates comprehensive and in-depth knowledge in subject area. Stimulates and maintains student interest. Exhibits openness to ideas of students. Is enthusiastic about subject, students, and teaching

# VERY GOOD

# a

Uses a variety of methods and aids to increase students' interest. Exhibits substantial knowledge in subject area. Provides outlines, handouts, and bibliographies to aid learning. Involves students in presentation. Wisely uses class time. Directly offers outside help to specific students determined to need it.

# ACCEPTABLE

# a

Varies method of presentation to increase student interest. Uses class time on subject matter. Encourages student participation. Demonstrates overall knowledge of subject and presents material so that is understood by student. it Encourages students to seek help after class if needed.

# MARGINAL

Presents essential information. May use same method of presentation daily. Demonstrates basic knowledge in subject area. Answers student questions, but does not involve them in presentation. Is available for outside help when needed.

# UNACCEPTABLE

# a

Uses class time poorlystrays from subject. Is not available for help outside class. Does not demonstrate adequate knowledge in subject area Does not encourage student participation.

Figure 3 11 Example of a behavioral scale based on expanding the performance standard for Method of Instruction." The scale is not behaviorally anchored.

A

# Considerations in Selecting

- 4. The superior and subordinate hold interim progress reviews. These reviews provide feedback to the subordinate and may involve corrective action needed to stay on target or revisions of objectives in the face of unforeseen problems.

- 5. At the end of the period, actual accomplishments are measured against pei tor-

mance requirements, and objectives for the next period are established.

For MBO to be effective, a distinction must be made between objectives in and performance requirements. Unless this distinction is made there probably will be no basis for determining if the objective was accomplished. Figure 3.12 illustrates this point:

# Position

# Objective

# Requirements

# Instructor

## Improve testing and evaluation procedures

## Submit list of 20 questions for departmental examination by May 1

# Division Chair

Develop writing skills of freshman students

Establish and staff a writing skills laboratory

# Dean

## Project positive image of college to community

## Present program to five civic clubs during year

## Figure 3 12 Objectives and Performance Requirements

MBO has many attractive features and is especially appropriate for management positions. Performance appraisals are job-related because the objectives define the most important aspects of job performance. Where factors are subjective, the personal- ity of a manager or subordinate may influence judgments. In some cases the superior may have difficulty explaining to the subordinate a discrepancy between objectives previously agreed upon and result, attained. Should this happen, discussions must be held by the two parties until a mutual understanding is reached. These discussions can focus on problems, ways to improve, and assistance needed.

Like other appraisal systems, MBO has its disadvantages. Emphasis is placed pri- marily on tangible results that are easily measured. Consequently, there is often a failure to appraise important aspects of the job that cannot be explained or measured in quantitative terms. Even when such measures can be obtained, an individual's perfor- mance usually is affected by factors beyond his/her control. The exclusive use of MBO can hinder cooperation by encouraging a result-at-all-costs mentality that decreases the overall productivity of the organization.lg Finally, performance outcomes alone do not

# 35

# 36

# Performance Appraisal

tell individuals what they need to do to it .in or increase pioductiv ity. For example, telling the Division Chair that the writing skills laboratory is not in operation skill not come as a surprise. He/she needs to know what must be done to achieve the desired result and how the organization can help. Possibly budget cutbacks have resulted in insufficient funds to hire lab instructors, or sufficient space has not been made ail- able. Problems such as these are why many authorities emphasize the need to combine MBO with other measures of job behavior.'`

# Sources of Appraisal Data

The best sources of appraisal data are.

(1) a knowledgeable indiv idual who has directly and continually observed job performance and w ho can late performance with- out error or bias and (2) items that can be counted, qualified, measured, analyzed, or compared. These factors should be considered no matter which approach is selected for conducting the performance appraisal. This section provides a brief description of the various sources which are currently accepted within organizations. Sources of critical information needed to perform the appraisal function may include. the supervisor, the subordinate, peer review, self-appraisal, and outside appraisals (including the assess- ment center concept and student evaluations, where applicable).20

# Supervisor Appraisal

Probably the most important source of judgmental data is the immediate superior. A manager has both a right and a duty to make appraisal and developmental decisions regarding subordinates. In addition, the superior normally assigns the w oil, and is responsible for rewards and sanctions. The liabilities of super\ isory appraisal include the familiar objection to "playing God" as well as the lack of interpersonal skills needed to maintain positive relationships with subordinates. Moreover; there is always the possibility of rater errors, including favoritism and bias.

# Subordinate Appraisal

Appraisal by subordinates is the opposite of super\ isory appraisal and the advan- tages and disadvantages are reversed. The major advantage is that such appraisals are highly democratic and they encourage participative management. This type of appraisal is often seen as illegitimate because it undermines the superior's rightful authority. Also a superior is already being appraised by subordinates, albeit indirectly. The superior's rating is usually influenced by husk well or poorly the subordinates perform their work.

# Peer Appraisal

Peer appraisals are most effective when there is a high level of trust among peers and when job performance information is available to peers such as in a faculty.

# Considerations in Selecting

Research has shown that peer appraisals are strongly Lonelated with objective measures of job success, However, peer appraisals have a Lompentive aspect and can be disnip- tive Conflicts may arise between making objectie appraisals and maintaining colle- gial relationships. Finally, peers may agree in advance to give each other high ratings.

# Self-Appraisal

Self-appraisals may be justified when the indiidual is in the best position to judge his/her own performance, such as in the Lase of physical isolation or when the individ- ual possesses a unique skill or ability. Self appraisals are useful in development because they emphasize personal grow th, intrinsiL mom anon, and goal-setting. They also communicate to the superior how the subordinate perceives his/her performance and provide insights not otherwise available However, self-appraisals are often poorly correlated with supervisory appraisals and are unreliable as a single source of informa- tion for promotions and merit pay.

# Appraisal by Outsiders

Appraisal by outsiders is based on the need for someone with speLialized expertise but without a vested interest in the appraisal results. Examples are retaining a C.P.A. firm to conduct an audit of a financial statement or a visit by an accreditation team. Another application is know n as an assessment center where candidates for managerial positions participate in a variety of situational exercises and are assessed by several trained observers on their performance. Another type of appraisal by outsiders is student evaluation of teaching performance, although the assumptions of specialized expertise and lack of a vested interest do not hold. There is evidence in the literature that suggests that students may sometimes be unable to disLrumnate between effective and ineffective teaching.21 Moreover, many faculty members hold somewhat cynical opinions concerning the value of student judgments. Nevertheless, these ratings, when properly evaluated, are a useful source of appraisal data.

In regard to objective data, the variety of measures is so large that It is impossible to categorize them completely. For faculty members the list might include publications, reading lists, community service projects, student clubs, aLtivity reports, test gains, student performance in subsequent courses or other institutions, and the like. For administrators there are accreditation studies, contraLts and grants, budgetary' Increases, management audits, and similar measures. Analogous examples could be cited for support personnel.

Organizational practiLe and empiriLid evidence suggest that the appraisal process should normally be conducted by the immediate superior who an integrate both judg- mental and quantitative measures. The problems of this approaLli an be solved by developing a job-related system and by properly naming raters. For example, in rating an instructor on the dimension of Llassroom teaLhing, the department chair might con- sider the following:

# 37

# 38

# Performance Appraisal

## Report of a faculty peer review committee

# Analysis of student evaluations

## Recognitions such as testimonials and teaching awards

Syllabi, manuals, reading lists, and other teaching aids

## Personal observation of classroom performance

## Enrollment and subsequent course performance data

# The instructor's self appraisal

Note that this list includes both judgmental and objective data from a variety of sources. In rating a different dimension; for example, scholarly productivity, the department chair would develop sources of data which reveal quality, creativity, and significance of the contributions of the professional field.

# Cost Considerations

Developing, validating, and administenng a performance appraisal sy stem is a major undertaking and requires a substantial investment in time and money. There are a number of factors an organization should consider in making the decso-. regarding resources to be invested. Among these are the nature of the relationship between devel- opmental costs and system effectiveness, allocation of costs among po.it;ons, and potential for improving performance.

In general, the more costs the organization is willing to incur, the better the system that can be developed. It is important to note, however that as more is invested in development beyond what is necessary to establish validity, incremental costs do not necessarily result in proportionate increases in system effectiveness. An example would be useful to show this relationship. Assume the objective is to measure the per- formance of a faculty member. A dimensionalized and weighted rating scale similar to Figure 3.2 could be developed. Based on the author's experience, the job analysis, criterion development, and instrumentation could be accomplished for under $2,000 and would meet the minimum requirements of the "Guidelines." It might be desired, how- ever, to develop behaviorally anchored rating scales similar to Figure 3.7. The devel- opment of BARS requires a much more sophisticated approach and the cost could be as high as $10,000. While the cost may be five times as high, there is no research which suggests that BARS is five times more accurate. In fact, reviews have not found BARS to produce substantially more accurate results than traditional graphic scales.22 The same relationship holds true in the administration of a performance appraisal program. The essential elements of such a program include appraisal interview sind an appeal process. The cost is considerable, and there is always the danger that both subordinates and superiors may spend more time and energy in various aspects of appraisal than in productive work. While certain administrative requirements are necessary, they should

# Considerations in Selecting

be kept in perspective. Beyond the point necessary to ensure that the appraisal program is carried out under standardized and controlled Londitionsidditional meetings, paper- work and procedures do not justify the cost. In other words, the investment in both development and administration of performance appraisal is subject to diminishing returns.

Another important consideration in the investment decision is the number of incumbents in a particular job category. For example, an institution might have 100 instructional positions and two library technicians. Assume that there are three instruc- tional divisions: e.g., Arts and Humanities, Science and Mathematics, and Nursing. Within each division the instructional positions are fundamentally similar. Thus, the developmental cost of a performance appraisal technique could be spread across 20 to 50 positions in the faculty, but only two in the library. This would support a decision to develop a more sophisticated (and expensive) sy stem for the faculty than for the library and other support departments.

Finally, it is very important to consider the value of post-appraisal benefits in such areas as increased productivity, motivation and satisfaction, staff development, and better administrative decisions. This may be intuitively obvious, but the implications are sometimes overlooked. Thomas F. Gilbert has introduced the concept of potential for improving performance (PIP), which is the ratio of exemplary performance to typi- cal performance.21 A PIP of 5.0 suggests that typical performance could be improved fivefold, while a PIP of 1.1 tells us that exemplary performance is only 10 percent better than typical performance. Gilbert suggests that in professional athletics PIP's almost invariably run less than 2 and exceptionally competitive and demanding jobs such as that of an airline pilot have PIP's near 1. On the other hand, PIP's in education and government are typically 5 to 30, showing much more potential benefits from per- formance appraisal.

# Concluding Comment

It should be stressed that there is no one best way to go about selecting a perfor- mance appraisal technique. Performance appraisal programs serve many purposes, and most of the techniques discussed have valid applications. Organizations may want to eliminate options such as tiait rating scales that have serious disadvantages. Several alternatives to the traditional superior-subordinate appraisal review function have been described in this chapter. Organizations may choose to incorporate various sources of information into their overall employee performance appraisal process. They also need to carefully analyze appraisal costs s. benefits. The methodology Finally adopted may be a mixed system with features of several techniques.

,j

# 39

# 40

# Performance Appraisal

# Endnotes

1.

Evelyn Eichel and Henry E. Bender, Performance Appraisal. A ,survo of

Current Techniques, (New York. American Nla..agement Association, 1984), p. 41.

Charles R. Masson, Duane E. Thompson, and Gary C Luben, "How Desir- able is Your Performance Appraisal System' ?" Penonnel Admini,strator 25 (December 1980), pp. 77-83.

2.

3.

Ronald G. Wells. "Guidelines foi Effectike and Defensible Performance

## Appraisal Systems," Perconne/Journa/ 61 (October 1982), p. 777.

4.

# Eichel and Bender, op cit., p. 37.

5.

# Mid.

- 6. William H. Volley and Kenneth NI. Jennings, Personnel Management, (Chicago: Dryden, 1987), p. 255 and Robert L. Lazar and Walter S. Wikstrom. Appraising Managerial Performance, (New York. Conference Board. 1977), p. 95. Holley an Jennings, op. it.. p. 256.

- 6. William H. Volley and Kenneth NI. Jennings, Personnel Management, (Chicago: Dryden, 1987), p. 255 and Robert L. Lazar and Walter S. Wikstrom. Appraising Managerial Performance, (New York. Conference Board. 1977), p. 95. 7.

8.

Eichel and Bender, op. cit., p. 36.

## John C Flanagan, "The Critical Incident Technique'," Ps.sc hologi«il Bulletin

61 (July 1954), pp. 327-358.

- 10. Marion G. Haynes, "Developing an Appraisal Progi am," Pei-mimic/ lourna/

57 (January 1978), pp. 14-19.

11.

# Eichel and Bender, op cit., p. 48.

- 12. Gary P. Latham and Kenneth N. Wexley, Increamng Productivit) Through

## Performance Appraisal, (Reading, MA: Addison Wesley, 1981). p 51.

Patricia C. Smith and L. M. Kendall, "Retranslation of Expectations: An Approach to the Construction of Unambiguous Anchors for Rating Scales," fourna/ of Applied Psychology 47 (April 1963), pp. 149-155.

11

- 14. Walter C. Borman, "Effects of Instructions to Avoid Halo Error on Reliabil- ity of Performance Evaluation Ratings." Journal of Applied P.s.scholog.1 60 (October 1975), pp. 556-560.

- 15. Gary P. Latham and Kenneth N. Vs, exley, "Behar twat Observation Scales for Performance Appraisal Purposes." Pet Amon" Pkscholog) 30 (Sumnici 1977), pp. 255- 268.

## Peter F Drucker, The Prue lice of Management, (Ness Yolk. Harper and

- 16. Row,. 1954).

For a discussion of the steps in the MBO piocess see Dale D. McConkey, Now to Manage h.) Results, (New York. American Management Associations, 1983), pp. 89-160.

17.

18.

# Latham and Wexley, hu taming

# Prodiu tivit) Through Performance

# Appraisal, p. 43.

# Considerations in Selecting

- 19. Craig E. Schneier and Richard W. Beatty, "Combining Bars and MBO. Using an Appr. isal System to Diagnose PerformanLe Problems," Pcnowie/ Adnuni.strator 24 (September 1979), pp. 51-55.

- 20. L. L. Cummings and Donald P. Schwab, "Who Evaluates?" in The Perfor- mance Appraisal Sourcebook, eds. Lloyd S. Paird Richard W. Beatty and Craig E. Schneier (Amherst, MA: Human Resot,i',-e Development Press, 1982), pp. 81-85 and John B. Bennett and Shirley S. Chater, "Evaluating the Performance of Tenured Faculty Members," Educational Record 65 (Spring 1984), pp. 38-41.

- 21. Donald W. Miller, ''Dangers of Using Student Evaluations for Administrative Purposes," Collegiate News and Viett.s 31 (Spring 1978), pp. 2-3 and Irene R. Kiernan, "Student Evaluations Re-Evaluated," Community' and Junior College Journal 45 (April 1975), pp. 25-27. See for example, Frank Lindy and J. L. Farr, "Performance Rating,"

## Psychological Bulletin 87 (January 1980), pp. 88-89.

23

Thomas F. Gilbert, Human Competence. Engineering Worthy Performance,

## (New York: McGraw-Hill, 1978), pp. 30-43.

# 41

4

## Development of Performance Appraisal and Accompanying Criteria

# Edith A. Miller

The development of an appropriate performance appraisal procedure and its accompanying criteria is a complex set of tasks. While there is a vast body of theory and research related to performance appraisal methodology, there is also an equally extensive and widely differing range of opinion, research, and suggestion in the litera- ture regarding not only performance appraisal generally but also criterion development specifically. While there is no concensus regarding the right or best instrument or the roest appropriate criterion, it is clear that whatever form a performance appraisal system takes it must be:

- 1. Conceptually or philosophically congruent with the job, profession, or con- stellation of duties and responsibilities it is designed to appraise.

- 2. Directly related to the actual day-to-day. on-the-job, performance of these duties and responsibilities.

- 3. Usable and legally defensible.

- 4. A source of information for improvement (growth) of the individual being assessed as well as improvement or added benefits for the institution or orga- nization in which the individual is employed.

- 5. Sound from a measurement point-of-view--that is, valid and reliable.

The first four charactenstics herein listed are deafly related to a cogent under- standing of the job or position to be appraised Klasson. Thompson, and Luben outlined four important qualities a performance appraisal system must int.lude to be defensible.

43 t

# 44

# Performance Appraisal

- 1. The performance appraisal system should be formally developed, thoroughly documented, and as objective as possible

2

The standards of performance for all positions being appraised must be based on the results of a thorough, formal lob analysis.

- 3. Relevant job dimensions and desired job performance should be reflected in each performance standard.

- 4. The appraisal process should involve the measurement of performance with the weighting of each dimension or criterion fixed prior to the utilization of the appraisal system.'

Throut,!1,1ut these qualities is found the notion that the performance appraisal pro- cedure is inextrrably linked to the nature of the job or performance being appraised. The preferred metood for assuring that the performance appraisal is not only conceptu- ally and philosophically congruent but also directly related to the actual performance being appraised is some form of job or task analysis. The first section of this chapter will address job analysis as it serves as the basis for the development of the overall per- formance appraisal system and most specifi,:ally for the development of the evaluative criteria with which the system operates. Issues surrounding the choice, adaptation, and/or development of a performance appraisal system will be explored in the second section of the chapter Specific measurement ism. ;s regarding performance appraisal with specific attention to reliability and validity as well as sources of error will con- clude this chapter.

# Job Analysis

The issue of job analysis is as central to the development of tests, performance appraisals, and evaluation procedures as it is to the development of management strate- gies. Ghorpode defined job analysis as "... a managerial activity directed at gathering, analyzing, and synthesizing information about jobs."2 Lopez, Kesselman, and Lopez indicated that from the time it began to assume importance in the test construction ncess, job analysis had also begun to play an important role in personnel selection.3

Both the process and outcome of job analysis are essential to the development of a performance praisal system. Not only does the job analysis info, lawn serve as "te base for the development of the "items" or "behaviors" or "traits" to be appraised but also a well designed and executed job analysis will contribute to -ti,,rion development and content validation. Moreover, it was shown in Chapter 2 that job analysis has com- pelling legal implications.

The job analysis procedure is in itself a complex and demanding aspect of the development of a performance appraisal system. Prien strongly stated that job analysis is not an easy job that just "anybody" can do. I Rather it is a step that requires much thorough planning and careful execution. Ile further indicated that while the research

# Development

on job analysis techniques has indeed grown beyond its infancy, there is still not a strong body of research to answer the question of what is the best job analysis proce- dure to use in specific simations.5 In Principles for the Validation and Use of Personnel Selection Procedures, the following statement is made that, "There is currently no authoritative set of principles for job analysis comparable to the Standards or Principles in the area of selection procedures."6 The document continued by noting some specific things that a job analysis must do. (1) specify the descriptors or units of analysis by which the job will be defined, (2) develop task or activity statements for job-oriented analyses, and (3) develop behavioral statements or descriptors for worker- oriented analyses.

The categorization of job analyses into job-oriented and worker oriented is very useful. There are literally dozens of published job analysis procedures. Bemis, Belensky, and Soder reviewed ten such systems as bases for developing a system which draws on both job-oriented techniques and worker-oriented techniques-- Versatile Job Analysis System (VERJAS).7 The systems discussed by the authors range from the widely-used and generally well respected Department of Labor (DOL) procedure to the Guidelines Oriented Job Analysis (GOJA) which was developed specifically in response to legal and regulatory requirements.

To discuss a wide variety of these job analysis procedures goes well beyond the scope of this document. However, it is impoitant to have an understanding of the ways in which the job-oriented and worker-or- nted models differ. Ghorpode stated that job-oriented models tend to draw on the system framework for their definition.8 The analysis of a specific job is seen as the analysis of a sub-unit of the organization. Sidney Fine's Functional Job Analysis (FJA) is a good example of this particular model. Worker-oriented systems rest on preconceptions about the nature of the inter- relations between the aspects of the job and the individual in that position. The Position Analysis Questionnaire (PAQ) is a good example of the worker-oriented model. To explore the differences between these two approaches to job analyses, the FJA and the PAQ will be examined in more detail. Because of the importance of legal considera- tions, a brief discussion of GOJA will also be presented.

## Sidney Fine's Functional Job Analysis, developed during and after World War II.

## rests on a "systematically articulated theory of jobs and people":9

- 1. A fundamental distinction must be made betweeo what gets done and what workers do to get things done.

- 2. What workers do, insofar as job content is concerned, they do in relation to three primitives: things, data, and people.

3.

In relation to each primitive, workers function in unique ways. Thus, in rela- tion to things, workers draw on physical resources, in relation to data, on mental resources; and in relation to people, on interpersonal resources.

- 4. Al) jobs T.-quire the worker to relate to each of these primitives in some degree. r

# 45

# 46

# Performance Appraisal

- 5. Although the behavior of workers or the tasks performed by them can appar- ently be described in an infinite number of ways, there are only a small number of definitive functions involved. thus, in interacting with machines, workers function to feed, tend, operate, or set up, and in the case of vehicles or related machines, to drive-control them. Although each of these functions occurs over a range of difficulty and content, essentially each draws on a relatively narrow and specific range of similar kinds and degrees of worker characteristics and qualifications for effective performance.

- 6. The functions appropriate to each primitive are hierarchical and ordinal, pro- ceeding from the simple to the complex. Thus, to indicate a particular func- tion, compiling (data), for example, as reflecting the requirements of a job is to say that it induces the requirements of lower functions such as comparing and excludes the requirement of higher functions such as analyzing.

- 7. The three hierarchies provide two measures for a job. Level is a measure of relative complexity in relation to things, to data, and to people. Orientation is a measure of relative (proportional) involvement with things, data, and people.

- 8. The hierarchies of functions reflect a progression from much prescription and little discretion in worker instruction at the least complex level to much dis- cretion and little prescription at the most complex level.

- 9. Human performance is conceived as involving three types of skills. adaptive, functional; and speufic content. Adaptive skills are those competencies that en ible an indiv idual to manage the demands for uniformity and/or change in relation to the physical, interpersonal, and organizational arrangements and conditions in which tilt job exists. Functional skills are those competencies that enable an individual to relate to things, data; and people (orientation) in some combination according to personal preferences and to come degree of complexity appropriate to abilities (level). Specific content skills ace those competencies that enable an individual to perform a specific job accor standards required to satisfy the market.iO

The Position Analysis Questionnaire (PAQ) ryas specifically designed to be a worker-oriented model. Developed by Ernest J. MLCormick and his associates at Purdue University, the PAQ is based on the following undeily mg assumption.

If there is some such underlying behavioral structure, such structure presum- ably would have to be characterized in terms of the ma mei in which more specific "units" of job-related variables tend to be organized au oss jobs. Thus, the "building blocks" or common denominators or any dimensional stricture must consist of relatively unitary, discrete job variables of some class that can be identified and quantified as they relate to individual jobs.11

1 inventory of "job elements" within major divisions and subdivisions is then proposed in the PAQ. Within these divisions the inventory of job elements serve as a basis for determining the behavioral dimensions of jobs. These dimensions include. (1)

# Development

information input, (2) mental processes, (3) work output, (4) relationships with other persons, (5) job context, and (6) other job characteristics. In regard to job context or the physical or social contexts in which the work occurs, examples of job elements would be high temperature and interpersonal conflict situations.

A method which specifically addresses the requirements of the "Uniform Guide- lines" is known as GOJA, an acronym for Guidelines Oriented Job Analysis.'2 This method, developed in 1974 by Richard E. Biddle, has been periodically refined and updated and has been successfully used with numerous public and private employees.

When implemented in its entirety, GOJA is a multistep process which results in a selection plan. For purposes of performance appraisal the earlier steps of the process deal with the identification and characteristics of jobduties as shown below:

- 1. Collection preliminary job data.

2.

# Identify major job duties.

- 3. Rate each duty by frequency and importance.

- 4. Cluster related duties into job domains.

These steps represent about one-half of the GOJA process; however, they provide the foundation on which a performance appraisal system can be built. GOJA is one of the fov methods available that systematically takes a user from the content of a job to the content of a performance appraisal instrument. GOJA't thoroughness in application and documentation makes it an important and useful mcthod.13

These rather disparate examples of job analysis procedures should make the point that one must very carefully design the specific job analysis to meet the purposes to which the resulting data will be applied. The APA Principle' suggested that job analy- sis procedures ". . be chosen or developed as it is appropriate to obtain job information for the purposes or application of that job analysis information."I4 Pearlman suggested an examination of the research and conceptual issues in the area before choosing an approach.is

Ghorpode indicated tnat from the more job-oriented approaches one would get information about job outputs, guidelines, controls, tasks, and other job factors.th With the more worker-oriented systems, information about aptitudes, abilities, and other human characteristics would emerge. The degree to which the appraisal system is designed to focus on these two dimensions of job analysi, will direct the nature of the procedure. Just as the job analysis procedure can be oriented toward the job or the worker, it can also be oriented toward qualitative or quantitative data. The range of data gathered in job analyses extends from truly narrative, anecdotal records to highly quantitative data that can he totally analyzed with a computer. Again, the design of the job analysis will determine the kind of data gathered.

# 47

# 48

# Performance Appraisal

# Development Issues

A variety of development issues arises when one considers either adopting, adapt- ing, nr developing a performance appraisal procedure. The first and most important of these issues is the determination of the purpose of the appraisal procedure--the use of the resulting data. If the purpose of procedure is to make large-scale summatke, insti- tutional judgments, one's focus would be quite different than if the focus were to iden- tify strengths and weaknesses with a view toward employee growth development. Each of these widely differing purposes and many purposes between these two exam- ples will serve to establish the frame-of-reference for the choice, adaptation, or devel- opment of a performance appraisal procedure.

As indicated in regard to job analyses procedures, there is also no clearly superior approach to conducting performance appraisals. There is a vast amount of research and theory around the issue, and depending on one's purpose, some of the research can be helpful in choosing an approach. As an illustration for this discussion of development issues, the use of a rating scale approach to performance appraisal will be used. Rating scales have proved to be generally useful in performance appraisal, and depending on the nature and use of the scale have also proved to be reliable. A study by Dawes indi- cated that while most rating scales are non-representational, with appropriate directions a rating scale could be used reliably to measure a representation variable, height.17 Furthermore, rating scales have both ordinal and interval properties.ls

The retranslation method has provided a useful approach to establishing rating scales with behavioral anchors.'" The accuracy of a rating scale format will, of course, vary with the nature of the job or performance being appraised.20 However, a variety of rating scale formats--Behavioral Expectation Scale (BES), Behaviorally Anchored Rating Scale (BARS), and Behavioral Observation Scale (BOS)--is being used exten- hely and very appropriately in performance appraisal activity.

In 1963, Maurice Lorr, C. James Klett, and Douglas McNair made five specific

uggestions regarding the development of rating scales:

- 1. Only one variable should be rated at a time.

2.

Several items covering an aspect of behavior or a trait should be included in a rating scale.

- 3. Scales should allow the rater to describ: tne strength of a trait or behavior. Bipolar opposites are difficult to depend on for clear information.

4.

Items should use clear, non-jargon language as much as possible.

- 5. The span of the scale should reflect the range expected in th.: population to be appraised.21

c.3

# Development

In discussing the construction of rating instruments for faculty evaluation, Berk maintained that the characteristics of the instrument would evolve from four basic phases of the construction process:

1.

# Specification of the domain

2.

# Scaling of the instrument.

3.

# Item generation.

4.

## Statistical analysis of the in strument.22

Domain specification is, of course, the identification of the "ballpark" of the appraisal development process. What skills, behaviors, performances, traits, abilities, qualities, aspects, etc. will the appraisal address? The development of the criteria (criterion) against which these aspects will be appraised is also of critical importance., Flanagan, in describing the critical incident technique of performance appraisal, suggested that the criteria for performance appraisal must come not only from qualified experts but also from descriptions of skilled professionals. The steps proposed by Flanagan included the following:

- 1. Observation of the activity's purpose of aim.

2.

## Specification of the observation methodology.

- 3. Data collection.

- 4. Analysis of observation data.

5.

Interpretation of resulting data to establish performance ,,riteria.23

In the specification of the domain to be assessed, Berk suggested a procedure called facet analysis: "The task of the domain deemed important and worthy of measure- ment "24 The purpose of an appraisal system and the anticipated use of the resulting information will, of course, determine how general or specific this facet analysis must be. The developmental step which follows the identification of the facets of the domain is to translate them into a set of elements which identify the salient features of the performance to be appraised. Belk suggested a set of guidelines for the development of rating instruments 25 Many of these points are duectl) relevant to the development of a rating scale within a performance appraisal system.

1.

Specify the purposes of the evaluation tapinaisal) and the decisions to be made with the results.

Define the domain of charactei istics to be measined using facet analysis or a similar procedure.

# 49

# 50

# Performance Appraisal

- 3. Develop a summated rating scale continuum consistent w ith the types of characteristics to be rated.

Intensity of scale is in Likert form of agreement/disagreement.

a. b. Numerical format should be used rather than graphic when possible

because of scoring or summing ease.

c. Anchors of scale should be clearly defined.

# d.

Five-point scale is adequate from the point of reliability.

e. Neutral option on the scale can be used or not according to personal pref-

# erence.

f. Non-applicable option should be used only for non-applicable items.

- 4. Generate a pool of items to measure the characteristics.

# a. Two or three items per facet.

b. Available rating instruments and banks serving as resource.

## c. Evaluating items for quality and congruence with domain specifications.

- 5. Field-test the instrument and appraise the psychometric qualities of validity, reliability, item stability, etc.

Using this general format suggested by Berk is a straightforward approach to rating scale development.26 Berk's general steps, however; apply to the development of other appraisal measures as well. Once the rating scale, or checklist or inventory of tasks, has been developed, Berk suggested the following triteria for ealuating items

# Content/Format:

1.

# Clear, direct, specific language.

2.

# One complete thought or concept.

3.

# Concise (no more than 20 words).

4.

# Simple sentence.

5.

## No universal words, e.g., all, always, none, never.

6.

# No words like only, just, and merely.

7.

# No jargon.

# Congruence with Specifications:

8.

Applicable to all being evaluated.

9.

# A desirable characteristic.

10.

# Congruent with facet element.

'6J

# Development

11.

# Consistent with anchors on rating scale.

12.

Factual or can be interpreted as factual.

13.

Open to only one interpretation.

14.

Likely to be responded to by all raters.27

Beyond these simple criteria against which to compare the items on the instrument itself, the items should also be compared against the scale to be used. Berk suggested a summated (Likert) scale.28 Other scales which might be considered include: paired comparisons, equal appearing intervals, successive intervals, scalogram analysis, semantic differential, Q-sort techniques, and multidimensional scaling. Some of these procedures have serious drawbacks regarding the reliability and validity of the resulting data--paired comparisons, for example. Again, the scale should be chosen in light of the intended use of the resulting data. The summated scale (Liken-type) does lend itself to statistical analyses that go beyond simple descriptive statistics.

Once the domain has been specified drawing on-the-job analysis information, an instrument type and scale have been chosen, and items have been developed, the next consideration is the r;t3tistical analyses of the resulting data. There are two major arenas of statistical analyst -. to be considered: (1) analyses of the data in the instrument development process and (2) the analysis of the resulting data for decision or staff development use.

Three major types of analyses should be conducted at the instrument development (1) intercorrelations of items, (2) study of variability, and (3) factor analysis of item develop-

stage: the items and subscales to test for empirical verification of conceptual ment.

The analysis of the resulting data depends on the kinds of decisions to be made with the data. There is much c-mtroversy about whether performance appraisal instru- ments should he one dimensional or should represent several dimensions. Again, the literature provides no clear-cut answer. However, Smith clearly indicated that ". when several dimensions are involved several sets of criteria as composites will be required."29 Given the highly specific nature of performance appraisals, one answer to the question of one overall measure or a series of discrete measures is absolutely impos- sible. The analyses of these data would, ofcourse, help in determining the relatedness or independence of the various dimensions of the instrument.

Whether one adds all of the items into one scale or related items into subscales, Fralicx and Raju found that the weighting of items need not be as difficult as once thought lc' In their study of 112 bankers, they found that Management Weights (MGR), Equal Weights (EQL), Unit Weights (UNIT). and Factor Weights (FACT) produce highl comparable ratings. Equal weights derived by utilizing standard deviation recip- rocals and management weights achieved by having managers weight each item are considerably more time consuming than allow mg each item to contribute equally to the sum. Likewise, factor analysis is more time-consuming and requires much more sophistication A fifth weighting procedure -canonical correlationwas also used in the

# 51

# 52

# Performance Appraisal

study, but those weighted results correlated roughly at the zero le% el with the other weights. Because of the nature of canonical correlation, that particular result was expected by the researchers.

Decisions made on the weighted, summed; or otherwise statistically or conceptu- ally treated data must be made by those who designed the performance appraisal system. Standard setting and cut-scores, numbers of items at paracular levels, and levels of performance required must be determined in terms of local needs. One caution that all using performance appraisal instruments must heed, however, is that many of the traits, behaviors, attributes, aptitudes, etc. that are being appraised are not parallel either in importance or in ease of measurement or obsery anon. These consider- ations must be attended to in any performance appraisal approach.

# Measurement Considerations

The primary measurement considerations which come to mind when focusing on performance appraisal are those of validity and reliability. Does the performance appraisal system indeed tap those dimensions of the performance that are criterial to the effective job performance? Bailey suggested that there are three approaches to deter- mining whether or not the criterion of effective job performance is indeed being measured. performance/factor analytic approaches,1111 and (3) appraiser generated approaches.l1,15 If in the development or adaptation of the performance appraisal procedure at least two of those dimensions could be utilized, the initial notion of content validity would be addressed. Additional content validation can be achieved by ratings of experts, but the primary sources of content validation are the conceptual validation of the job analysis and the empirical validation of the factor analytic approaches.

(1) job analytic procedures,

11,12 "

While content validity lacks the quantitative rigor of other methods, it would be erroneous to conclude that this method of validation is inferior, particularly with performance appraisal. What k central to the conLept is that the performance measures appropriately sample the domain of job content. When these measures are developed through comprehensive job analysis, the "inferential leap" between the content of the performance measure and the content of the job is minnmzed.'6 The "Uniform Guide- lines" accord equal status to content validation alone when behaviors and outcomes are directly observable.1' Finally, in that focus is on the measure itself, rather than on external variables, content validity is often the only practical choice.

Criterion-related validity is, of course,. always considered appropriate. There are some problems with predic II\ e validity in regard to the item and resources necessary to conduct the longitudinal study necessary for predictive studies. If the concurrent study is conducted with on-the-job employees as the criterion respondents to the instrument, there are serious problems as the criterion respondents to the instrument, there are serious problems with the employees not being directly similar to prospective employ- ees, with their having learned on-the-job, and with their experiencing lower levels of

# Development

test anxiety. While this is valuable information, such t_oncurrent studies must be viewed with caution.

Cautions are in order regarding face Validity 18,39 While an instrument appearing to measure what it is designed to measure is indeed a ,trong public relations factor, one must be most careful about the emphasis given to claims of face validity and to the qualifications of those making the face validity judgments. Nonetheless, an instrument which appears to be relevant certainly meets with more acceptance than does one that seems foreign or unrelated to one's job performance.

The final validity issue that might be addressed is that of convergent /discriminant validity.40 With multiple measures of many of the traits, attributes, and behaviors contained in a performance appraisal process, such a N alidity study is most appropnate.

The reliability issue regarding performance appraisals must be addressed from two perspectives: (1) reliability of the instrument and (2) inter-rater reliability. Osgood, Succi, and Tannenbaum used factor analytic studies to test for internal consistency.4t Currently, the coefficient alpha is in wide use to test for internal consistency.42

The issue of inter-rater reliability is ii serious Lonsiderationind the primary vari- able affecting it is training in the use of the procedure. That issue is addressed in Chapter 6, which focuses on minimizing rater errors.

# Endnotes

Charles R. Klasson, Duane E. Thompson, and Gary L. Luben, "How Defen- sible is Your Performance Appraisal Sy stem?" Personnel Administrator 25 (December 1980), pp. 77-83.

1.

2.

## Jai Gharpode, Job Anabsis ,4 Handbook for the Human Resource Director

## (Englewood Cliffs, NJ: Prentice-Hall, 1988), p. 1.

Felix M Lopez, Gerald A. Kesselman, and Felix E. Lopez:" An Empirical Test of a Trait-Oriented Job Analysis Technique," Personnel Ps)cholog) 34 (Autumn 1981), pp. 479-502.

3.

4.

## Erich P. Prien, "The Function of Job Analysis in Content Validation,"

## Personnel Psychology 30 (Summer 1977), pp. 167-174.

5.

# Ibid.

American Psychological Association, DINision of Industrial-Organizational Psychology, Principles for the Validation and L'Ae tdPersonnel Selection Prot edures 2nd ed. (Berkeley, CA. Author, 1980), p. 4.

6.

7.

## Stephen E. Bemis, Ann H. Belensky, and Dee A. Soder, Job Analysis--An

Effective Management Tool (Washington, DC. The Bureau of National Affairs, 1983).

8.

# Gharpode, op. cit., pp. 232-233.

9.

# Ibid.

# 53

# 54

# Performance Appraisal

Sidney A. Fine and W. W. Wile), An Introduction to Functional Job Analy- sis: A Scaling of Selected Tasks from the Social Welfare Field (Kalamazoo, MI: W. E. Upjohn Institute for Employment Research, 1971), pp. 78-80.

10.

- 11. Ernest J. McCormick, Paul R. Jeanneret, and Robert C. Nlecham "A Study of Job Characteristics and Job Dimensions as Based on the Position Anal) sis Question- naire (PAQ)," Journal of Applied Psychology 56 (August 1972), pp. 347-367.

- 12. Richard E. Biddle, Guidelines Oriented Job Anabsis (Sacramento. Biddle

# and Associates, 1982).

- 13. Robert D. Gatewood and Hubert L. Field, Human Resource Selection

# (Chicago: Dryden, 1987), p. 231.

- 14. American Psychological Association, op. cit., p. 5.

- 15. Kenneth Pearlman, "Job Families. A Review and Discussion of Their Impli-

# cations for Personnel Selection," Psychological Bulletin 87 (January 1980), pp. 1-28.

- 16. Gharpode, op. cit.

- 17. Robyn M. Dawes, "Suppose We Measured Height With Rating Scales

# Instead of Rulers," Applied Psychological Measurement 1 (Spring 1977), pp. 267-273.

- 18. Graham K. Kenny, "The Metric Properties of Rating Scales Employed in

## Evaluation Research," Evaluation Review 10 (June 1986), pp. 397-408.

- 19. Michael J. Kavanagh and John F. Duffy, An Extension and Field Test of the Retranslation Method for Developing Rating Scales," Personnel Psychology 31 (Autumn 1978), pp. 461-470.

- 20. Walter C. Borman, "Format and Training Effects of Rater Accuracy and

Rater Errors," Journal of Applied Ps.scholog) 64 (August 1979). pp 410-421. 21. Maurice Lorr, C. James Klett, and Douglas M. McNair,

# utiles of

## Psychosis (New York: Pergamon Press, 1963).

- 22. Ronald A. Berk, "The Construction of Rating Instruments for Faculty Evaluation: A Review of Methodological 7ssues," Journal of Higher Education 50 (September-October 1979), pp. 650-669. John C. Flanagan, "The Critical Incident Technique," Psychological Bulletin

51 (July 1954), pp. 327-358.

74.

# Berk, op. cit., p. 652.

25.

Ibid., p. 664.

- 26. Ronald A. Berk, "Empirical Evaluation of Formulae for Correction of Item- Total Point-Biserial Correlations." Educ ational and P,s, hologit al Alcasurement 38 (Fa1 1978), pp. 647-652. Ibid.

- 26. Ronald A. Berk, "Empirical Evaluation of Formulae for Correction of Item- Total Point-Biserial Correlations." Educ ational and P,s, hologit al Alcasurement 38 (Fa1 1978), pp. 647-652. 27.

# Ibid.

# Development

- 29. Cited from Catherine T. Bailey, The Measurement of Job Performance

## (Aldershot, England: Gower, 1983), p. 748.

- 30. Rodney D. Fralicx and Nambury S. Raju, "A Comparison of FiN e Methods for Combining Multiple Criteria into a Single Composite," Educational and Psycho- logical Measurement 42 (Autumn 1982), pp. 823-827.

- 31. Catherine T. Bailey, The Measurement of Job Performance (Aldershot,

# England: Gower, 1983).

32.

# Flanagan, op. cit., pp. 327-358.

- 33. Bryant F. Nagle, "Criterion Development;" Personnel Psychology 6 (Autumn

1953), pp. 271-289.

- 34. Robert M. Guoin, "Criterion Measurement and Personnel Judgement,"

## Personnel Psychology 14 (Spring 1961), pp. 141-149.

- 35. Patricia Smith and Lorne M. Kendall, "Retranslation of Expeciations. An Approach to the Construction of Unambiguous Anchors for Rating Scales," Journal of Applied Psychology 47 (February 1963), pp. 149-155.

- 36. Gatewood and Field, op. cit., p. 135.

37.

## "Uniform Guidelines on Employee Selection Procedures," Federal Register

43 (August 25, 1978), pp. 38302-38303.

- 38. Baruch Nevo, "Face Validity Revisited," Journal of Educational Measure-

ment 22 (Winter 1985), pp. 287-293.

- 39. Charles Secolsky, On the Direct Measurement of Face Falidity. A Comment

## on Nevo," Journal of Educational Measurement 24 (Spring 1987), pp. 82-83.

- 40. Donald T. Campbell and Donald W. Fiske, "Convergent and Discriminant Validation by the Multitrait Multimethod Matrix," Psychological Bulletin 56 (January 1959), pp. 81-105.

- 41. Charles E. Osgood, George J. Sum, and Percy H. Tannenbaum, The

## Measurement of Meaning (Urbana, IL: University of Illinois Press, 1957).

42.

## Lee J. Cronbach, Essentials of Psychological Testing 4th ed., (New York:

# Harper and Row, 1984).

# 5.5

# Communication Factors in Appraisal

# Mark E. Meadows

Supervisors in many organizations see little practical value in conducting perfor- mance appraisals) This attitude may be exacerbated in postsecondary education settings where administrators are first and foremost scholars within increasingly narrow disciplines and not always skilled or expert in managerial functions. Performance appraisal systems have yielded disappointing results within the community college environment, even so, effecting such a system is significant to the success of community colleges.2

## Saliance of Commtr iication to Performance Appraisal

There is mounting evidence that success or failure of performance appraisal rests on the effectiveness of the terminal appraisal event, that is, the appraisal interview.3 Laird and Clampitt cited research which suggested that performance review interviews make employees more defensive and self-conscious about then job behavior.4 Goodall, Wilson, and Waagen claimed that fear of what performance appraisals might yield keeps the appraisal process from achieving its full potential.' Appraisers experience high levels of anxiety when giving negative feedbackh and futility because they either do not believe they can do what is required of them in performance appraisals or that the environment will not be responsible to their efforts.' For appraisees, "The perfor- mance appraisal interview is a situation that determines ... survival or death."4 Clcarly, performance appraisal interviews are complex, potentially charged situations which call for appraiser communication skids of the highest order.

Maier recommended that perform Le appraisal issues be approached as communi- cation problems. lie contended, "The success or failure of an employee development program largely depends on the skill with which employees are interviewed by their supervisors. "" At its simplest level,. the performance appraisal interview is a communi- cation event in which two persons attempt to exchange meanings through spoken words. Regrettably, simplicity in communication Is quickly lost in complexity. Norman Cousins, a former &inertia) Rolm eduoi, concluded a highly publicized con- flict with exasperation "The most difficult and precarious enterprise in the world is communication. It is the ultimate act. U)

57

5

# 58

# Performance Appraisal

It has long been claimed that communication is the number one problem in management. 11 It should follow that managers and superb isors must assume responsi- bility to see that effective communication takes place in appraisal interviews. As the mere expert or more accountable person, the supervisor needs to establish conditions that are conducive to effective communication and model good communication skills in appraisal interviews. Communication is the only tev:iniqc,-; managers have for exchanging meaning with subordinates. How else can Cie supervisor explore job per- formance with an employee: provide an employee with feedback on how closely work quality approximates expectations, dispense important, though intangible, rewards for jobs well done, or establi.,11 goals? The performance appraisal interview is considered the primary context for supervisors and employers to work together to achieve superior performance.12

Napier and Latham are among researchers in performance appraisal who have detected a shift in research from foci emphasizing psychometric qualities of rating and evaluation instruments to a focus on the appraiser.11 Although they emphasize complex social learning theory in explaining appraiser inters iew behaviors, Napier arta Latham are only two among numerous writers and researchers in pet formance appraisal who place emphasis on the key role of communication N ariables in performance appraisal. Communication between appraiser and appraisee is affected by fears of what performance appraisals might yield. Goodall, Wilson, and Waagen focus on the hierar- chical nature of such communication, that is, communication between a superior and a subordinate.14 Wexley described two primary objectives of the appraisal interview, both accomplished through communication N ariables. He gave special attention to the direction of communication flow in organizations. Because the flow is usually down- y'ard, distortion, inaccuracy, and suspicion re,,ult. Wexley's view of appraiser role is that of a helper whose primary tole is commumeation.15 Stano focused on appraiser communication skills and the importance of appraisee participation in discussion as factors affecting the quality of performance appraisals.i- Laird and Clampitt identified dissemination of results through the inter\ iew as one of four major problems in eon- ducting performance appraisals.17

Review of research related to performance appraisal, and especially that which deals with problems encountered, makes abundantly clear the fact that appraiser- appraisee interaction variables communication if you will- account in large part for the success or failure of performance appraisal systems. Given that fact, and accepting as an assumption that the supervisor/appraiser has the primary responsibility to see that good communication takes place, the remainder of this chapter is devoted to two topics: (1) a brief description of key communication concepts and (2t communication proli-ms inherent in performance appraisal, together with suggestions fen mitigating communi- cation problems.

# Communication Factors

# Communication Concepts

Communication may be defined as the process of exchanging meaning between persons. Person A, the sender or encoder, convey s a message to Person B, the receiver or decoder, who interprets tne message and responds (encodes) in some way to let Person A know that the message has been received. When Person B decodes and inter- prets Ks message ilk: simplest form of interpersonal communication has taken place. For the purpose of reinforcing the fact that the Icader must take responsibility to insure that effective communication occurs in the performance appial;,a1 process, it will be helpful if readers identify themselves as persons encoding, or sending, verbal messages in the content that follow s, that is, as Person A. Figure 5.1 depicts the basic communi- cation transaction which occurs in any form of communication, including performance appraisal.

# Encoder

# Decoder

# Appraiser [Person Ay

# Appraisee

# Interprets Decodes

# Interprets N_,..Encodes

## Fig. 5.1. Basic Communication Transaction

Frequently, appraisers sending nit,tiges find that their purposes are not achieved; the receiver (appraisee) does not respond as expected or possibly does not respond at all. When communication is viewed simply as "sending" a message, we may safely assume that communication will not take plate. As with the Tango, communication is a two-way process. It takes two people to hold an effective performance discussion.18 Further, the two persons must be in contact, have each other's attention, and attach similar meanings to messages. In summary, there must be a sender who transmits a message to a receiver who understands the meaning of the message in the same sense as the sender. The sender ascertains that communication has taken place by securing feedback from the receiver. Only then can the sender knov. whether a message has

# 59

# 60

# Performance Appraisal

been accurately communicated or \\, hethci the message needs to be rex ised and encoded again. Wexley described as one of two primary objectives of appraisal inter\ iews feed- back to appraisees.19

Feedback is especially impor.. when the purpose of communication is instru- mental: that is, to obtain a behavioral response from the receiver of the message. When such messages are sent, feedback is best obtained by asking, "Now, tell me what you are going to do." The supervisor needs to know what is understood by the supervisee. When a subordinate is asked. "Do you understand?" Moe is considerable pressure to answer, "Yes." Otherwise, one's superior might think one is not intelligent.

We communicate best with those who have experiences similar to our own:. how- ever, few persons enjoy the luxury of communicating with a narrow iange of persons altogether similar to themselves. In Figure 5.1, the messages of A and B are shaded differently to commuricate the tact that their experiential backgrounds will "shade" their messages. Employees of higher educational institutions now represent a broader range of cultural, ethnic, and socioeconomic baLkgiound than in the past.:, Communi- cator differences in experiential background can cause senders and receivers to attach quite different meanings to the same words and objects to the extent that messages sent are not identical to messages received. Sensitivity and efforts to increase knowledge of diverse groups are called for. Appraise' who \\, ISh to improve communication must learn to hear messages from the "frame of reference" of others.

The needs of those communicating can cause breakdown in communication. The sender may feel a need to put the recei, er "in his or her place." The iece;ver ma) feel threatened when communicating with the sender. Both sender and receiver can enhance the likelihood of effective communication b) being as aware' as possible of boil' his/her own needs and those of the person with \110111 they communique, however, this is especially a responsibility of the leader/appraiser. Such awareness can reduce defensive behavior and rid the interaction of communication distoitions that defensiveness elicits and sustains. Figure 5 2 represents two basic needs of every person, the need to protect oneself and the need to enhance oneself. When these needs ale threatened or thwarted communication will break down.

It is important to communication effectiveness that senders communicate clearly their expectations In most performance appraisal inter\ iew s appraiseis send messages that attempt to elicit a behavioral response, that is, an mil umental sespouse. Unless senders make expectations explicit, the dcsu ed [espouse 0, ill not be forthcoming. There is appreciable evidence in suppoil of the' so- called Pygmalion effect, that persons generi:ly respond to expectations Ilowe\ er, if expectations aic not cleat and responses are not those sought, inappropriate assuic,;:,ions about the competency of a subordinate may be made when, in fact, that assumption is not justified.

Beliefs of both sender and receiver create difficulties in communication. Napier and Latham draw from social learning theory to identify two Lognitive variables which

# COMMUnication Factors

are sources of fun'ity experienced by appraisers, self-efficacy and outcome expecta- tions.21 Appraisers who believe they cannot do what is iequired of them (low self-effi- cacy) experience feelings of futility because they do not believe the environment will be responsive to their efforts, they have poor outcome expectations In either Lase belief systems of communicators can interfere with communication.

Attitudes are as potent as beliefs in creating LommumLation difficulties. Supervi- sors communicate a certain attitude when they confer with supervisees only on their own turf rather than in the supery isee's workplace or a neutral setting. Communication across the physical barrier of a supervisor's desk does not improve understanding.22 Figure 5.3 is an attempt to depict some of the multiple human factors that are constantly affecting the flow of messages between two persons. Again, the appraiser must assume primary responsibility for recognizing the impact of these factors and in reducing any negative impact they have in communicating with appraisers.

# protect

# (Appraiser (Person Al

# protect

# Enhance

# Appraisee (Person BI

# Enhance

## Fig 5 2 Two Basic Needs Affecting Communication

Finally, poor listeners make poor LomminuLatots. All too often, simple failure to listen is the cau,e of communication breakdown. Two Poor listening habits predomi- nate as communication barriers. One of these is the tendency to attach evaluative judgments to what others say. Rather than listening, the reLeivL is making pdgments, filtering the message, and thereby failing to receive all the meaning intended by the sender One method for breaking thi, habit is for the apprai,ei/supervisor to adopt the non-evaluative feedback rule. l3efoie the appraiser responds to an appraisee statement,

# 61

# 62

# Performance Appraisal

the message must he repeated by the appraiser until the appraiser recognizes that both the content and feelings expressed are understood.21 The tendency to listen ev aluatively contributes to another poor listening habit. Instead of attending fully to what the sender is saying, the receiver may be forming respomzs. When receivers are preoccupied with how they will respond to points being made by senders, the points are usually missed. Stano advocated that managers be taught to listen carefully and accurately, to give reflective feedback, and to ask appropriate, open-ended, non-directive questions. Stano felt that careful listening was especially important in encouraging subordinates to talk.24

# Beliefs

# co

C)

# Appra;:.:r (Person Al

# co

# co.

# Beliefs

# 4/Nudes

# coc

70.-"?

# 5 0)a la

# Appraisee (Person BI

..%

# Attitudes

## Fig. 5.3. Factors Affecting the Flow of Messages Between Persons

## Performance Appraisal Situations With Inherent Communication Problems

The performance appraisal interview is rife with Sallati'MS wfilch have potential for

communication breakdown. These include the hierarchical nature of such events, 25 inherently evaluative aspek is of performance appraisal, multiple purposes of some appraisal interview s,26 influence of the environmental climate, including non-verbal aspects of performance appraisal linen s,2' Each of these special situations is dis- cussed below in terms of the unique communication problem(s) posed, together with suggestions for mitigating communication breakdown.

# Communication Factors

Burke identified the "mystery" that surrounds hierarchical communication, "... the conditions for 'mystery' are set by any pronounced social distinction . .. the social dis- tinction between clerk and office/manager makes them subtly mysterious to each other, not merely two different people, but representing two classes or 'kinds' of people."28 The existence of mystery between classes of beings points out an essential quality of the performance appraisal interview. a superior will be communicating with an inferior in the organization. Goodall,. Wilson, and Waagen pointed out that when mystery inter- cedes in communication between different classes of beings, the common response is to retreat to ritual forms of address; that is, communicative behaviors that are guided by commonly understood cultural and social stereotypes, traditional etiquette, gender- specific, or race-specific rules.29 Both interviewer and interviewee are encouraged to rely on and to respond to prepackaged scripts for the situation that derive rules from commonly understood cultural values and standards.3° In short, the mystery present in the situation is reinforced by ntual forms of cornmunication."1 In the face of pressures to retreat to fixed, conventional forms of communication between appraiser/appraisee, the appraiser must assume responsibility to assure that the barrier is broken and that honest, open communication occurs.

Although some experts in performance appraisal advocate that managers treat employees as equals,'' it does not follow that the employee will adopt this attitude or that such attempts of managers will be credible, especially if the manager's behavior is not consistent with past behavior.'" Review of the literature suggests that the primary way to reduce the "mystery" in supervisor/subordinate communisation is to facilitate participation of the subordinate, the manager needs skills that encourages subordinates to talk.14 Participation is encouraged through active listening,15 manager behaviors that are spontaneous, friendly, sensitive, that show interest in subordinates, and that are nonjudgmental.16 The best place for the appraisal interview is a neutral setting and not in the manager's office, thus reducing the distance over which communication occurs. Finally, Goodall et al. discussed the central purpose of performance appraisal interviews from the frame of reference of both the supervisor and the subordinate.37 They stressed the need for clarity of purpose of the appraisal for each party. When there is a common understanding of what the parameters of the performance interview are, the appraisee is more likely to experience the safety required for self disclosure and risk-taking, thereby making the interview a more authentic, spontaneous experience. Bellman stated, "A performance discussion without objectives is not a performance discussion."38 In summary, the negative effects of status differences on communication within the performance interview are mitigated when the appraiser (1) assumes responsibility to see that effective communication occurs, (2) listens carefully, (3) clarifies interview purposes and goals, and (4) involves the appraisee in all phases of performance appraisal, including the design of the program.'9 When possible, the employer should be allowed to rate his own performance:10

The fact that performance appraisals exist in part to pros ide evaluative feedback to appraisees constitutes in performance appraisal. Bennett and Chater underscored this aspect of appraisal in postsecondary settings They cited several current concerns in higher education that have led faculty and administrators alike to tighten their judgments. Bennett and Chater especially made

# another critical

# communisation variable

# 63

# 64

# Performance Appraisal

a case for evaluating the performance of tenured faculty in order to foster and maintain excellen' performance:I It is noteworthy that virtually no literature on performance appraisal posits a view that does not include the evaluative nature of performance appraisal.

Given that evaluation either takes place or that existing evaluation data are pre- sented in appraisal interviews, what can be done to reduce its negative impact? Three basic communication techniques that have potential to reduce the negative effects of employee evaluation in the performance interview arc offered. feedback clanfication, non evaluative listening, and achieving an appropriate balance of praise and cnticism. It should be noted again that the interviewer/supervisor must assume responsibility to use such techniques, although employees can also be taught these skills.

Non-evaluative listening involves receicing communication from an appraisee without placing any value judgment on the message or the sender, that is, concentrating on tasks, roles, and results rather than the personality of the interviewee.42 Ironically, by temporarily suspending intentions in performance counseling interviews, one may more likely achieve goals because interviewee resistance is decreased by curtailing judgments.41 Feedback clarification refers to the ability to paraphrase content back to the speaker and to reflect the feelings of the speaker.41 When an appraiser provides accurate feedback; the appraisee adds to his/her self-understanding; resulting in improved self-esteem and personal effectiveness. It i not sufficient to simply repeat back, or mimic, the words of the appraisee; it is necessary to feed back accurate under- standings of both content and feelings expressed.

Much has been written about the so-called "sandwich" technique where negative evaluations are sandwiched between praises. Stan° believed that skill in balancing praise and criticit.m in performance interviews can help circumvent the debilitating effects of evaluation, however, he believes that the "sandwich" technique is too obvi- ous. He recommends dispensing supportive feedback almost exclusively at the begin- ning of the interview, thus, establishing an initial positive climate and creating appraisee receptiveness to more thorough analysis in aieas where improvement is needed.45

Use of feedback clarification, non evaluative listening, and balancing praise and criticism in performance interviews nuninuie the negato, e aspects of communicating evaluative messages in one other significant way. by reducing the likelihood of open hostility. Skopec's research findings support that uncertainty in dealing with con- frontations and other hostile interiewee reactions and the need to maintain satisfactory interpersonal relationships following appraisal Intel s constitute primary concerns of performance appraisers When appraisees arc heard accurately and understood, they are less likely to be hostile and confrontive.46

Laird and Ciampitt claimed that the performance appraisal process may be sabo- taged by multiple use of appraisal documents. Stano simmunized !nerd ure on this matter and concluded that it was uno,ersally agreed that to combine discussion of development and salary is deleterious lie believed that performance interviews should

# Communication Factors

have a narrow focus confined to either the objective of development or to perfor- mance/salary review.4i Banks and Murphy suggested that in assessing candidates for promotion, the interview should focus on behavior required for more advanced jobs, whereas in salary administration, the focus should be on behavior required in the appraisee's own job.49

Wexley discussed the appraisal interview in terms of two directions, administrative and employee development. The purpose of the form is to communicate and support administrative decisions such as salary increases, promotions, transfers, etc., the pur- pose of the latter is to enable each employee to get feedback as to how well he/she is doing and to provide an opportunity to discuss improvement of performance. "Both (purposes) cannot usually be accomplished during the same session, inasmuch as the manager is being asked to play the conflicting roles of judge and helper."50 Mount, in a study of employee and r_ anager satisfaction with the appraisal process in a large cor- poration, found that both groups supported the concept of separating salary considera- tions from employee appraisals.51 It is noteworthy that both groups consider the quality of appraisal discussion one of the most important factors is satisfaction with the program.

Combining development goals with administrative tasks such as salary administra- tion within the appraisal interview creates an improbable communication problem in that the appraiser has dual role',. "The superior cannot establish a warm, supportive climate if he or she is ruling on the employee's paycheck. The employee will not be open to a discussion of weakness if he or she feels that such a disclosure will result in economic sanction."52

Every organization has a climate in which communication occurs.53 Climate factors must be considered at both the organizational level (macro) and at the perfor- mance appraisal interview level (micro). Climate factors at the organizational level refer to processes related to such factors as leadership, communication, decision- making, goal setting, and processes.S4 Wexley drew upon the seminal work of Likert to illustrate how organizations differ with respect to climate fattors.55 At one extreme is the System 1 organization where there is no perceived evidence of trust between manager and subordinate, interaction is restricted, decisions are all made at the top, and employee participation is discouraged. In a System I organization communication flows downward, tends to be distorted, inaccurate, and viewed with suspicion. At the other extreme is the System 4 organization which is characterized by supportive rela- tionships, group decision-making, open and extensive interaction, and high participa- In a System 4 organization communication flows freely throughout-upward, tion. downward, and laterally. Information is accurate and undistorted.cn It is apparent that appraisal interviews would take on quite different characteristics within these different environments What seems clear is that communication in organizations onented toward System 4 would be quite superior to that in System I.

Climate exists as a communication variable at the micro level of the performance appraisal interview as well. ''The climate present in an appraisal interview is affected by a complexity of interlocking and intangible variables." s' Vanables include both

# 65

# 66

# Performance Appraisal

physical and personal factors that surround the performance interview. Where the interview is held is an important factor. Experts disagree on this. Wex ley suggested the interview take place in either the appraiser's or appraisee's office.5S Stano believed the best place is a neutral territory that is relatively isolated from routine distractions.59 What seems important is that a place be selected for the interview that is comfortable for both parties, that will provide appropriate privacy, isolation, and no interruptions, and that does not serve to increase mystery, or distance, that already exits. Arrange- ments within the interview room are important climate factors, those that reduce differ- ences in status and distance facilitate effective communications. For example, side-to- side or corner seating is preferred to communicating across the expanse of a desk. Proxemic variables such as these are examples of non-verbal communication that can serve to reduce or expand status or hierarchical differences between appraiser and appraisee.

The impact of climate considerations, whether at the organizational-wide or personal level, may be observed at the appraisal interview level. If appraiser behavior is substantially incongruent with organizationJ characteristics experienced day-to-day by appraisees, distrust and suspicion will be engendered. If appraiser non-verbal behavior, that is, facial expression, gestures, posture, lack of eye contact, etc., contra- dicts what is said verbally, appraisees will get a mixed message. Non-verbal behavior is perceived as more reliable and accurate than the verbal message when they are in conflict.60 Communicators are constantly using two channels of communication, i.e., verbal and non-verbal.

The importance of climate factors at the individual level are illustrated by Stano. "Overall, communication will be more open and honest and problem-solving will be facilitated if the manager can genuinely consider the employee as equal and can appear spontaneous, friendly, supportive, sensitive to and interested in the difficulties of the worker, understanding, and cooperative, nonjudgmental with regard to feelings revealed, nonmanipulative, concerned for the dignity and worth of the individual, trusting, and confident of the employee's abilities." fit Figure 5.4 provides a list of factors which can constitute barriers to effective communication.

# Summary

Review of the performance appraisal interview and the complex processes which occur in the act of communication between appraiser and appraisee leads to a series of statements which might summarize and give direction to ..onimunkative behavior on the part of appraisers.

The appraisal interview is an exceedingly complex communication event that can have negative implications for both appraisee and appraiser The employee may become defensive and view the interview as the deciding factor in his/her ultimate destiny. The appraiser many times expenences high levels of anxiety and feels some sense of futility in evaluating an employee's performance.

1.

# Communication Factors

# i

--1

# Status (Hierarchy)

# Climate

# A

# F Participation

# R

# Proxemics

# R

# Channel [Verbal, Non-verbal]

# E

# R

# Listening

# Criticism

# Multiple Objectives

## Fig. 5.4. Barriers to Effective Communication

To help overcome these feelings, management should attempt to establish an Special attention should be

2

environment conducive to effective communication. addressed to the hierarchical nature of this communication process.

Communication is a two-way process,

3.

ind both parties communicating should he using the same points of reference Validation is accomplished through both parties providing feedback so that a common ground of understanding can be achieved.

4

We communicate best with people who have similar backgrounds to our own

and with people with whom we arc neither threatened by nor do we threaten,

5.

Expectations should he made explicit and clear.

6

## Differences in beliefs cause difficulties in communication, especially in low

# or high self-efficacy beliefs.

# 67

# 68

# Performance Appraisal

7.

Differences in attitudes construct a barrier in LommuniLations between indi-

# viduals.

Poor listeners are not good communicators. The non evaluative feedback rule can help open the lines of Lommum Lawn and assume that all the meaning int,nded by the sender is received by the receiver.

8.

# There

relationship between employ ee and (win ..user/ supervisor, i.e., there are two wfferent L lasses of people, eaLh with his /he! own L us toms and rituals, trying to communicate but possibly not understanding where each is coming from. Thus, both may fall back on societal norms and scripts and may never actually communicate.

9.

# a hierarchical

is

- 10. To overcome this, a manager should facilitate partiLipanon of subordinates. This can be done through (mike listening, faLditatike communication behaviors, and structuring the organizational and personal environment in ways that are conducive to effective communication. The purpose of the inter iew should he stated clearly.

- 11. To reduce the negative impact of the performance inter iew the appraiser should pros ide feedback clarification, non-ekaluam e listening, and attempt to achieve a balance between praise and criticism.

- 12. Multiple use of appraisal documents and interviews can cause problems. The interview should have preLise and clearly defined paiametos and not mingle personal development and administrative objectives.

- 13. All organizations have a climate which consists of two lei els, micro and macro; i.e , personal and organizational. Both physical and personal factors affect the climate that surrounds the performance interview. Communication will be of a higher quality in a climate whuh encourages participation and diminishes status differences. Finally , the sine qua non of effeLme performance appliusal communication is appraiser acceptance of responsibility for the quality of LommuniLation which takes place. When performance interviews are characterized faLditatike communication processes, both personal and organizational development Occurs.

# Enclnotes

Nancy K. Napier and Gary P Latham, "Outcome Expectancies of People Who Conduct Performance Appraisals," Posonne/ Psycho /0,0 39 (Winter 1986), pp. 827-837.

1.

2.

## Robert G Lahti, "Appraising Managerial PerfoimanLe," Junior College

## Resource Review, (January 1981), pp. 3-6.

Eric Wm Skopec, "Rhetorical Dimensions of Performance Appraisal Inter- views," Pape! presented at the Annual Meeting of the Eastern Communication Associa- tion (75th, Philadelphia, PA, March 8-11, 1984), pp. 1 10, Napier and Latham, op. ca.,

3.

# Communication Factors

pp. 827-837; and Kenneth N. We \ le), "Appraisal Inters iew ," in Performance AA.SeAA- meat Methods and Applications, ed. Ronld A. l3erk (Baltimore. Johns Hopkins Press, 1986), pp 167-185.

4.

Angela Laird and Phillip G. Clanspitt, "Effectis e Performance Appraisal: Viewpoints from Managers," The Journal of Bicsino.s Communitation 22.3, pp. 49-57.

5.

H. Lloyd Goodall, Jr., Gerald L. Wilson, and Christopher L Waagen, "The Performance Appraisal Inter% iew . An 'inapt-en\ e Assessment," Quartet!) Journal of Speech 72 (February 1986), pp. 74-87.

6.

# Skopee, op. cit.., pp. 1-10

7.

## Napier and Latham, op. tit., pp. 827-837.

8.

# Goodall. Wilson, and Waagen, op cit

# p.

- 9. N R. F. Meier. Appuns* Performance (La Jolla, CA. University Associates,

Inc., 1976).

- 10. Norman Cousins, "The Hersey Episode," Saturday Revien (January 1977).

11.

## Interpersonal Communit anon, A Guide for Staff Development, Institute of

## Government, Georgia Center for Continuing Education, 1974.

12 Mark E. Meadows. "Personal Commuimation and Organirational Effective-

## ness," Appalachian Business Review 7:2 (1979), pp. 2-6.

13

# Napier and Latham. op

pp. 827-837.

- 14. Goodall, Wilson, and Waagen, op cit , pp. 74-87.

- 15. Wexley; op. cit., pp. 167-185

16 Michael Stano, "Guidelines for Condikung the Performance Appraisal Inter- view: A Literature Synthesis," Jour na/ o/ Apphed Connnumeathm Restart h 9.2 (Fall 1981), pp. 131-142.

17.

# Laird and Clampitt, op. cu., pp. 49-.57

- 18. Geoff Bellman, "Nine Wa) s to l'pgrade Performance DisLussions." Train-

MOND 18 (Febivary 1981), pp. 35-38. 19. Wex ley, op cu., pp 167-185

- 20. Meadows, op cu., pp. 2-6

- 21. Napier and Latham, op cit , pp 827 817.

22.

Stano, op cit.. pp. 13 i -142.

John F Kikorski and Joseph A. Lincrei, "Litedie Communication in the Performance Appraisal Res, Jew," Mau Pei Amine! Managenu nt 12 (1983), pp 33-42, in Goodall, Wilson, and Waagen, op en p. 74

23.

24.

Stano, op. ca., pp. 131-142

- 25. Goodall, Wilson, and Waagen, op, cit , pp. 74-87.

# 69

# 70

# Performance Appraisal

Stanley B. Silverman and Kenneth N. Wex ley, "Reaction of Employees to Performance Appraisal Inter\ iew s as a Funuion of Their PartiLipation in Rating SL,tle Development," Personnel Psychology 37 (Winter 1984), pp. 703-710. Laird :Ind Clampitt, op cit.; pp. 49-57; Stano, op. ca., pp. 131-142; and Wexley, op ed.. pp 167- 185.

26.

- 27. Wexley. op. cit., pp. 167-185. 28. Kenneth Burke, A Rhetoric of Motives (rserkeley, CA. University of

California Press, 1969) in Goodall, Wilson, and Waage,i. op cit , p. 74.

- 29. Goodall, Wilson, and Waagen, op ca., p. 741.

30.

# Ibid, p. 74

3I.

# Ibid.

32.

Stano, op. cit., pp. 131-142.

- 33. Goodali, Wilson, and Waagen, op cu., pp. 74-87, and Laird and Clampitt,

op. cit., pp. 131-142.

34.

Stano, op cit., pp 131-142, and Goodall, Wilson, and Waagen, op. ca.., pp.

74-87.

- 35. Goodall, Wilson, and Waagen, op. cit., pp. 74-87.

36.

Stano, op. cit., pp. 131-142.

- 37. Goodall, Wilson, and Waagen, op. ca., pp. 74-87.

- 38. Bellman, op

pp. 35-38.

39.

Stano, op. cit., pp. 131-142.

40.

# Laird and Clampitt, op. cit., pp. 49-57.

41.

John B. Bennett and Shirley S. Chater. Evaluating the Performance of

## Tenured Faculty Members," Educational Record 65 (Spring 1984), pp. 38-41

42.

Stano, op. ca , pp. 131-142.

# 43 Meadows, op cit., Pp. 2-6.

- 44. Kikorski and Utterer in Goodall, Wilson, and Waanen, op. cit , p. 74.

45.

# Stano, op. cit , pp. 131-142.

46.

# Skopec, op. cit., pp. 1-10.

47.

# Laird and Clampitt, op cit., pp. 49-57

48.

# Stano, Op cit., pp. 131-142.

- 49. Christina G Banks a J Kevin R. Murphy , "Tow aid Narrow

the' Research- Practice Gap in Performance Appraisal." Personnel PAlt holoks 38 (Summer 1985); pp 335-345.

- 50. Wexley, op. cit p. 170.

# Communication Factors

51 Michael K. Mount, "Comparisons of Managerial and Employee Satisfaction with a Performance Appraisal Sy stem," Personnel P.$)c holog 3 4 (Spring 1983), pp. 99-109.

52.

Laird and Clampitt, op. cit , p. 56.

- 53. Meadows, op cit.. pp. 2-6.

- 54. Wexley, op. cit.. pp. 167-185.

55

## R. Liken, "Motivational Approaa to Management Deelopmcnt," Harvard

Business Review 37:4 (1959), pp. 75-82 in Sumo, op. cu., pp. 131-142.

- 56. Wexley, op cu., pp. 167-185.

57.

Stano, op cit.., p. 135.

- 58. Wexley, op. cit., pp 167-185.

59.

Stano, op. cit., pp. 131-142.

60

Rodney Napier and Matti K. Geisherfield, Groups. Theory and Etperience

## (Boston, MA: 1- Loughlin Mifflin Company)

61.

# Stano, op. cit., p. 135.

# 71

## Minimizing Rater Errors in Observing and Appraising Performance

# William I. Sauser, Jr.

Having a well-designed performance' appraisal instrument and process is essential if the resulting evaluations are to be useful. However, even the most carefully con- structed devices and programs will not assure success in gathering valuable; information if the human beings who use the instruments are not willing or able to employ them properly.

The persons who observe and appraise performance are very much a part of the measurement process. No matter how fine an instrument they are using, if the raters are unreliable or invalid in their observations and appraisals, then the resulting information will be unreliable and invalid, and thus, not suitable for any purpose

Unfortunately, human beings tend to be very poor evaluators of behavior, as the

following except from the work of John Bernardin and Richard Beatty attests.

Research in psychology is replete with examples of the potential difficulties confronting performance appraisers People apparently do not attend very well to base-rate information; they express excessive and unjustified confidence in their judgments; they make predictive judgments that are biased in comparison with normative standards; they are subject to hindsight biases, they have self- serving biases in person perception, they underestimate the role of contextual factors affecting behavior, their judgments of emanation are inaccurate, they resort to erroneous judgmental heuristics. and so on .. . and on.. . There can be no question that some raters of performance commit these errors in judgment, as well as many others)

The existence of these and other rater error s hay e been know n for years.2.i.i Some of the more common errors ,klueli ha, 'seen identified and studied in detail are described in Exhibit 6.I.s

73

6

# 74

# Performance Appraisal

Since the existence of these errors is so pervasive, ind their effects are so poten- tially damaging, it is important to take ever) possible precaution to avoid them. The following ten suggestions for minimizing rater errors in obsen mg and appraising performance are discussed in this chapter:

1.

# Select appropriate raters.

2.

Clarify the purpose of the performance appraisal program.

3.

Choose the right format and content.

4.

Involve the raters in creating or interpreting the rating scale.

5.

Train the raters.

6.

Provide opportunities for the raters appraised.

to obsery e the performance being

7.

Help the raters keep records of meaningful observations.

8.

Standardize the rating context.

- 9. Motivate the raters to do a good job.

- 10. Maintain the quality of the program.

Administrators w ho follow these steps when implementing their performance appraisal programs will be rewarded with more meaningful data than will those who ignore these powerful suggestions for minimizing rater errors.

- 1. Select appropriate raters.

There is evidence to support the belief that one persons are better than others at rating performance. For example, after re It:wing numerous res,:arLh studies on this topic,. Ronald Taft in 1955 concluded:

. that the following characteristics are fairly consistently found to be posi- tively correlated with the ability to judge the peisonalit) characteristics of others: (a) age (children), (b) high intelligence kind academic ability (with analytic judgments especially), (e) specialization in the physical sciences, (d) esthetic and dramatic interests, (e) insight into one's status w ith respect to one's peers on specific traits, (f) good emotional adjustment and integration ... and (g) social skill... .6

.

More recently, Walter Borman found that personal qualities related to accuracy of appraisal include verbal reasoning, freedom from self doubt, high self- control, and an orientation toward details.?

In most organizational settings there arc piaLtiLal constraints which make it diffi- cult to apply the findings of Taft and Bornun. Most administrators do not have the luxury to pick and choose aLLurate raters from a pool of potential appraisers. However,

# Minimizing Rater Errors

it would not be wise to ignore these important findings. Ratings turned in by indi- viduals who are poorly adjusted or are undergoing a personal or emotional crisisor who have proven to be grossly mattentive to details- -are suspect and could be very damaging to the integrity of the performance appraisal process.

A more practical approach to the selection of potential raters is offered by Kenneth

## Wexley and Richard Klimoski. They suggest:

The person doing the assessment must. (1) he in a position to observe the behavior and performance cf the individual of interest, (2) be knowledgeable about the dimensions or features of performance, (3) have an understanding of the scale format and the instrument itself, and (4) must be motivated to do a conscientious job of rating.s

Note that in an academic setting this may call for multiple raters, each attending to a specific aspect of a professor's performance. For example, the department head may be in the best position to observe and es aluate adherence to policy and departmental service; students may be the best sources of data regarding the professor's day-to-day classroom performance, peers may be the best judges of the adequacy of syllabi and tests; and outside reviewers may be the best sources of unbiased evaluations of wnting and creative work.

The point is that there are some steps the administrator can take to make certain that persons are fairly evaluated. Individuals NA, ho. ( I) have no opportunity to observe the performance in question, (2) do not understand the rating scale, (3) are obviously biased toward or against the individual being appraised, t4) are poorly adjusted or undergoing a personal or emotional crisis, or (5) have proven to be grossly inattenuve to details should not be selected to Like part in the performance appraisal process.

- 2. Clarify the purpose of the performance appraisal program.

Performance appraisal ratings can be used for a variety of purposes, including providing feedback to the ratee, justify ing personnel actions, identify ing training needs and special talents, placing employees into propel jobs, fostering accountability, and improving organizational effectiveness.'' The specific purpo:,e for which appraisal ratings are collected can affect the molly awl --and thus the behavior -of the raters who are providing the scores, as noted in the l'ailowing passage from the work of Wallace Lonergan:

Appraisal programs are doomed to failure if employees associate them with determination of firing and layoffs Such negative associations not only engender resentment and distrust on the part of the employees, but also put the assessing supervisor on the spot Similarly, if appraisal programs become associated with favorable management action, a supervisor, wishing to show the department in a good light, might understandably upgrade an employ ee's ratings, thus adding leliberate distortion to Iready biased human judgment. in

# 75

# 76

# Performance Appraisal

Bernardin and Beatty are also LonLerned that the late' has e a deal understanding

of the purpose of the appraisal program lest the' rater distiust the process.

One factor that affects rater mon L anon has to do Vali the trust indisidual raters have in the appraisal process. Trust in the appraisal process ma) he defined as the extent to \\ hich both raters and raters perceise that the appraisal data will be for has been) rated accurately and fairly and the extent to which they per- ceive that the appraisal data will he (or has been) used find) and objecti el) for pertinent personnel decisions)]

If the raters are confused about the purpose of the appiaisal program, or if the pro- gram seems to be designed to fulfill two or more LcnraLting purposes, not 0111) might the raters lose trust in the program, they may beLome frustrated and angry as well.

For example, suppose that one objective' of an appiaisal program is to deter- mine salary increases. In this case, assessing supers isors frequent!) emphasize' the strengths of an employee if they feel that the employee deserves an increase Suppose that at the same time the apprai,,a1 program, is being used to improve performance. With this objective in mind, the assessing supervisor may feel obligated to point out an emplo)ee's relam e weaknesses in order to identify areas for improL einem. Ines itabl), the assessing supers isors will find themselves in a frustrating, if not untenable, position al attempting to use the assessments for these differing, purposes i2

It was recognized at least sixt) yea's ago that knowledge of the purpose for which ratings wer: to be used might influenLe the scores pros ided, therefore, the Lon% entional wisdom was as follows. "To as oid this enoi, ratings should he secured w raters in ignorance of their use and if possible at a time in advance of the slaw .on demanding their use." 13

Given Bernardm and Beatt)'s LonLerns about trust in the appraisal process, it is likely that tills cons entional wisdom Lould do with some es ision. Administiatiirs who desire to consn net a performarke appraisal s) stem w bleb V ill be accepted and used should inform the potential rate's of all intended uses of the iesulting data This will at least reduce any distortion and LarianLe in ratings due to SpCl. lad t on regaiding their use.

As a final note, 'while perfoimance apps nsal ratings can indeed be used foi a s ari- ety of purposes, Loncrgan suggests that setting indRidual development as the primary objective of an appraisal program has at least four ads antages.

The program is likely to be more acceptable to employees and to gain their support rather than arouse their iesentment,

There is less obvious reason for the assessing supervisors to introduce deliberate distortion into the assessments to achieve their OW11

# Manna:any Rater Erron

3

Feelings of stress and strain on the part of both the assessing supervisors and the employees are lessened.

- 4. Assessments will probably reflect the facts better.11

- 3. Choose the right format and content.

As noted in Chapter Three of this volume, there is a wide arle.ty of appraisal tech- niques and formats from which to choose', each with partkular strengths and weak- nesses is 16 It does make a difference which format is chosen for use, since some formats are better suited for one use than another.

Bernardin and Beatty have proided the following surnmar), of what they believe to be the most important contingencies regarding the efficacy of the various appraisal methods:

If the purpose of appraisal requires comparisons of people across raters for important decisions, then Management By Objectives (MBO) . . (is) inappro- priate since (it is) typically not ba..ed on a common measurement scheme. If there is low trust among raters, and if ratings are linked to important personnel decisions . then the forced- choice method is recommended since it is more resistant to deliberate rating inflation than other methods. If the Behav- iorally Anchored Raring Scale (BARS) method is to be adopted, then diary- keeping should be incorporated as a formal component of the process. . Such an approach is not only more effective at inhibiting halo than oth,-r methods; it also provides documentation for summary ratings and a data source for validating individual raters If the purpose of appraisal is test validation, then the relatively high levels of reliability and satiability for personnel -com- parison methods certainly support their use, providing a behavioral format is adopted for the comparisons and assumptions can be met for comparisons across raters is to improve performance, then MBO is the best strategy, providing uncontaminated, quantifiable data are available. ...17

.

.

.

.

.

# If the purpose of appraisal

These results of Bernardin and Beauy's wmptehensie review of the research literature point out the importance of clearly defining the purpose of the performance appraisal program before choosing and implementing any par tkular assessment technique.

Richard Klimoski warns practitioners also to consider carefully the content of assessment before selecting a scale for implementation. Ile des vibes three traditional options of assessment content: (1) personal traits or qualities of an individual, (2) per- fomanee results, and (3) behaviors exhibited on the job,18

As it turns out, each of these approaches to defining (refererking) effectiveness has strengths and weaknesses. Each is more or less applicable to particular jobs, to types of industries, and to differing management philosophies. Each

U L.,

# 77

# 78

# Performance Appraisal

one will be more or less appropriate depending on the purpose of the assess- ment. For example, a results approach might be more suitable as a basis for awarding a bonus. A beha% ior emphasis would be better when assessments are to be used to determine a manager's training needs. A person or trait orienta- tion makes sense when the assessment is to be used as input to making a pro- In the last case, we need to predict a person's likely future motion decision. success, and knowing his or her personal traits or qualities helps us to do this.1')

The message of this section is that the format and content of the assessment device to be implemented should certainly not be determined arbmanly if rater errors in obser- vation and appraisal are to be avoided. Administrators should consider carefully the organizational context, the prevailing managerial philosophy, ind the purpose for carrying out the appraisal program before any decisions about format or content are made.

- 4. Involve the raters in creating or interpreting the rating scale.

Douglas McGregor argues that supervisors are very reluctant to "play God" in appraising employees' performance, and implies that they may intentionally distort ratings as a result of this reluctanee.2n Some of the reasons for managers' resistance to performance appraisal cited by McGregor include. ( I ) a normal dislike of criticizing a subordinate (and perhaps having to argue about it), (2) lack of interview= skills, (3) dislike of new procedures v,ith accompanying changes in ways of operating, and (4) mistrust of the validity of the appraisal instrument.21

Carl Kujaw ski and Drew Young suggest, "Too often this resistance is justified. If an appraisal program is developed independently by a staff unit and imposed from above, it has a good chance for failure. Flowever,, it doesn't hive to be this way. "22

Kujaw ski and Young point out Peter Drueker's major suggestion for overcoming resistance to change. "Workers must be pros ided with opportunities for participation that will give them a managenal v iew."21 They then translate Dnicker's des ice into a pragmatic suggestion for administrators who sire trying to implement a workable appraisal progi am:

Ore approach is to have the personnel department work with a cross section of management in developing the appraisal program. Once the outline of the program has been established, it can be circulated to a larger group of managers for review and comment, and the program modified as needed.

Depending on the particular needs of the organization and the results desired, the number of levels of management involved in the design of the program will vary. The critical faetoi is that the users of the program be involved. By being so, they' will come to "own" the program, tnd therefore will be more willing to support it because it is theirs.24

# Minimizing Rater Errors

The motivational effect of participation in the development of performance rating scales has been documented in the research literature.2-c:6 Raters are typically proud of the rating scales they develop through their own efforts and are motivated to use them effectively.

Rater participation in scale construction can also have a second major benefit, particularly when Patricia Smith and Lorne Kendall's "retranslation technique"--the process used to develop Bella\ Anchored Rating Scales (BARS)--is employed. William Sauser notes:

When employees work together to est:.iish a standardized set of performance levels and dimensions to ev aluate, they typically reach a common understand- ing of the meaning of each dimension and anchor point. Thus, the rater participation process serves to greatly reduce the problem of each rater inter- preting the scales differently.28

One problem with Smith and Kendall's retranslation process is that it

is very cumbersome and time-consuming. Fortunately, i shortcut method for constructing BARS has been devised .2`)'° The psychometric quality of the scales which have been produced using this shortcut technique is similar to that of scales developed with the unabridged method.

Participation in scale construction almost always leads to an improvement in rater motivation. However, the examples described above seem to indicate that the addi- tional benefit--creating a common understanding of the meaning of scale dimensions and anchor points accrues only when such participation is in the form of involvement in the "retranslation process." Flow can this additional benefit be obtained when work- ing with scales which are not of the BARS format?

This question has been answered by the dt % elopment of a type of training program, called "frame-of reference training," which involves raters not in the development of the scale, but rather in the interpretation of the scale.'1 An example of the practical application of frame-of-reference training is described below. In this particular exam- ple, the standardized instrument in use was a trait rating scale:

One possible modification with which I hav e been experimenting in my rater training workshops may prove to be % aluable. Workshop participants are asked to develop, in small task groups, meaningful definitions of each dimension of the standardized scale with which they ine working. Each task group also produces beim\ ioral anchors for each level of a pamcular standardized scale. After these definitions and anchors have been dev iced, the workshop convenes in full session, and each task pouf) presents its products. All workshops participants then seek to agree upon a common set of performance dimensions and standards.32

# 79

# 80

# Perfornzance Appraisal

In summary, two major benefits can result from allowing raters to participate in the (1) the Inters will gain a sense of scale construction or interpretation process. "ownership" of the scale, their resistance' to its use will be lessened, and the motivation to intentionally distort scale scores will be reduced, and (2) the raters are more likely to develop a commoli frame of reference, they will share similar interpretations of scale dimensions and anchor point~, and unintentional distortion will be reduced.

Administrators w ishing to minimize rater errors in obsering and appraising performance would thus he well sick ised to allow raters to participate in the creation of the scales themseRc. or at least in the interpretation of standardized scales within the organizational context.

- 5. Train the haters.

In 1954. J. P. Guilford stated, "Various experiences w ith ratings tend to show that the most effective methoc! for impro mg ratings in many ways is to train raters care- fully."'" The documented effectieness of a \ ane t y of types of training programs carried out in a number of different organizational settings in the three decades since In fact, Kujawski and Young claim Guilford made that statement testify to its truth.'" that "A comprehensive training program for superisors w h o w ill sere as appraisers is one of the most valuable aspects of the implementation process.""

What should be the content of a comprehensive rater training program? William Holley and Kenneth Jennings have supplied the following excellent answer to this question:

Training programs for appraisers should focus on impim mg both obser a- uonal and evaluame skills. Appiaisers need to he taught what kinds of beim\ iors distinguish high from low performers, how to avoid perceptual and judgmental errors, and how to understand appraisal formats so as to use them applopriately for their intended purposes. Also, It is important that raters know how to select the relos ant information for making an accurate appraisal. Training programs should actiNely in oh, c the potential appraisers in the training process, and appraisers should be provided an opportunity to partici pate in group discussions and practice performance inter\ iews. While the content of the' training program should airy accoiding to the organization's needs, training should also sum to change the attitudes of the appiaisers, where' necessary Frequently performance appraisal programs fail because' of the lack of rater motivation either due to lack of understanding or pour instructions"'

Duane Schultz suggests that rater !laming ,'could in

# two steps.

I.

Creating an awareness that abilities and skills sire usually distributed in accordance w.th the normal curve, so that is perfectly acceptable to find large differences among a gismp of workers, ind

# it

# Minimizing Rater Errors

Developing the ability to define appropriate criteria for the behav- iors being evaluated, a standard or average performance against which employees may be compared 37

James Buford and Sony a Collins add that the workshop method is an excellent way

to train raters to reduce errors:

Trainees should have the opportunity to observe errors being made in an appraisal conference if possible. Videotapes are effective and can be used repeatedly. Raters should at least review written situational exercises. They should attempt to identify the errors that are being made and then complete their own ratings. Through group discussion, trainees have the opportunity to receive feedback regarding their on rating behavior and practice the correct techniques.3s

Latham and Wex ley have described in detail an excellent workshop employing the kind of videotaped exercises recommended by Buford and Collins.;') Administrators would do well to review the Latham and Wexley program when devising their own training sessions Another useful training device is the Atlantic Richfield Company's guide for individual raters 40

Exhibit 6.2 contains a detailed training outline which was devised to facilitate the implementation of a BARS-type faculty evaluation instrument in a university' setting.'' Research with this training program found it to be very effective in minimizing rater errors.42

The implications of this section should be very , lear. Tram y our raters if you want to minimize errors in observing and appraising performance. Providing a comprehen- sive rate' i:aining program is probably the most important step in implementing an effective appraisal system Time and energy invested in rater training w ill pay huge dividends in terms of the accuracy of the data resulting from the appraisal process.

- 6. Provide opportunities for the raters to observe the performance being appraised.

In an earlier section of this chapter administrators were advised to select raters who are in a position to observe the performance in question However, simply being in position to observe is not enough, as the following passage illustrates.

Supervisors meeting informally over coffee or lunch frequently brag about and share amusing anecdotes regarding their employees' behavior and work per- formance As they do this, the supers isois are actually informally evaluating their employees, often on the basis of a few randomly observed events or remarks. . It is during these infoonal, loosely structured discussions that ei dloyees In the absence of more accu- rate data regarding employee work performance, decisiou, might typically

.

.. begin to acquire reputations. . .

# 81

# 82

# Performance Appraisal

be made on the basis of the reputational factors resultin "roam the informal e" aluation process mentioned aboe. Ilovs e" er, reputations, since they are based mostly on hearsay and random comments and ober"ations, often present inaccurate, distorted, biased pictures of employ e;:s' true abilitie!. and (I ant certain that all of us from time to time wonder ',shy our performance. super" isors are ne"er around to see us when we make a particularly brilliant decision or complete a difficult task, but always seem to appear just in time to catch us in a blunder.)43

How can an administrator make certain that a rater's observations are objeLtive and fair rather than biased and distorted? All of the suggestions in this chapter are directed toward that end, hovse"er, there are three things in partiLular that should be done to address this problem.

First, the administrator should make certain that the raters understand exactly what it is they are looking for. While they are obser" mg, they should be primed to notice specific incidents of effeLti" e or ineffeLtie beha"ior. This is why a comprehensive rater training program must Lontain information on the kinds of [tau" iors which distin- guish among levels of performance. As Christina Banks and Kos in Murphy state, "Training programs should not want appraisers merely to observe; rather they should train them novs to decide N hat to obser" e." 14 (Note that if it is unclear what beha"iors actually distinguish effeLtie from ineffeLtRe performance, a job analysis is clearly in order.45)

Second, the administrator should ascertain that all raters take a sy stematic approach to gathering the information they need to make accurate appraisals. For example, if a department head is to e" aluate the quality of each faulty member's publications on an annual basis, she should certainly hale a process in place to collect copies of all pub- lished work- -not just those papers which the faculty happen to bring to her attention. Similarly, if a committee of peers is to e"aluate a colleague's classroom teaching performance; the committee should de" isL and follov, a plan that alloys s penodiL class- room visits- -not just a single "isit that may fall on a particularly good or bad day for their colleague.

Third, the administrator should see that all raters keep some sort of orderly record of their observations. By recording these observations o'er a period of time, then refer- ring to the complete re,ord when pro" iding an appraisal, the rater can avoid being overly influenced by recent events or isolated incidents of irregular beha"ior. The next section describes some of the techniques "Nitta can be employ ed to assist raters in keeping useful records of their observations.

- 7. Help the raters keep records of meaningful observations.

Many performance appraisal programs call foi ratings to be collected on a periodic basis, such as annually. It is assumed that the rater takes into Lonsideration the ratee's typical performance across the entire span of the rating period LL hen filling out the

# Minimizing Rater Errors

performance appraisal form Unfortunately, is very difficult for supervisors to remember all of the incidents of perfc-mance which the) niay have observed over the year, so this assumption is eery difficult to support. In fact, it is probable that many raters base their scores upon recent observations and a few "unforgettable" instances of behavior they recall from earlier in the year.

# it

Although these recalled instances may be "unforgettable." they niay not be remem- bered accurately, since most human beings are not blessed with total recall. Instead, these remembered samples of behavior may become distorted over time due to the frailties of human memory, they may also be colored and reinterpreted in the mind by incidents which have occurred during the intervening period of time.

Furthermore, the "unforgettable" incidents may not be typical of the ratee's day-to- day performance. While a spectacular success or failure during the year should certainly be considered when rating an employee's behavior, one or two "unforgettable" incidents should not overshadow the hundreds of instances of more typical behavior which have occurred during the rating period Otherwise, the ratings will be distorted; they will not be valid as true measures of typical behavior across the penod covered by the performance appraisal.

Since human memory is not infallible, how can raters be helped to recall accurately typical instances of behavior which occur across a span of time? The best approach is to keep records of observations as they occur, and to refer to these records when filling out the performance appraisal instrument. Three record-keeping approaches which have been devised to help raters are described in this section. These approaches are: (1) keeping a critical incident file, (2) keeping a diary, and (31 using a checklist.

In 1954, John Flanagan introduced a job analysis method which he called "the critical incident technique." 46 This method was quickly adapted for use in a perfor- mance appraisal context.41 The method calls for the observer to provide anecdotal descriptions of effective and ineffective job behaviors which have actually been observed in the work setting. These anecdotal observations, called "critical incidents," have been characterized as follows:

The observer reporting the critical incident is typically asked to describe: (1) what led up to the incident and the context in which it occurred, (2) exactly what the individual did that was effective or ineffective. (3) the apparent consequences of this behavior, and (4) whether or not the consequences were under the individual's contro1.5

Two examples of critical incidents, one positive and one negative, are piovided in

# Exhibit 6.3.

During the year. the rater could jot down notes regarding all critical incidents observed, and could file these notes in a "critical incident file." This file could then be consulted when the performance appraisal form was to be completed. This procedure

# 83

# 84

# Performance Appraisal

will ensure that behavioral observations from throughout the rating period are consid- ered when ratings are provided, thus decreasing c rors of distortion due to faulty memory.

The critical Ilk ident file will also be beneficial during counseling diseussions with the mice, since it will allow the supervisor to illustrate tatintzs with actual observations of behavior. This will provide more objectivity to the performance appraisal interview, and will reduce feelings of "arbitrariness" w hen ratings are diseussed with subordinates.

Note that it is not necessary to "stockpile" the critical incident file until the annual appraisal season rolls around. Instead, each incident could serve as the basis of a con- temporaneous eoaehing interview between the supervisor and subordinate. Positive incidents could serve as reasons for praise' and other reinforcement, negative incidents as cause for correction. The critical incident tile, accompanied by records of resulting commendation or reprimand, would then beeome a cumulative record of each subordi- nate's performance during the year and an objective basis f,,r a valid perfoimance appraisal rating

It should be further noted that anecdotes of behavior written some time after the incidents have occurred are subject to the same errors of distortion as are other memories. It is for this reason that critical ineidents should be written at the time of their occurrence, not several months later. Raters who attempt to produce from memory their critical incident files on the day they are to be used for performance appraisal purposes are negating the value of the procedure.

Flanagan's critical incident technique, combined with Smith and Kendall's appli- cation of the Thurstone sealing tei hniquc to critical modems, has led to the develop- ment of several performance appraisal methods, me luding behaviorally anchored rating scales, mixed standard rattng scales, and \Nei:4111a! ehecklists.4'icil As noted earlier in this chapter, Bernardin and Beatty suggest that keeping a formal, contemporaneous diary of behavioral observations is an important component in the successful imple- mentation of performance appraisal programs u,ing these methods.rI Based on their review of research regarding the usefulness of diary -keeping, they make the following recommendation:

We recommend that a formal system of diary-keeping be implemented after rater training and that it is monitored by the rater's supervisor. We also recommend that the rater be made aware that the observation of the ratee*s behav ior is an important supervisory function and that the most important part of the appraisal process takes place during the observation period, rather than in the ten minute, when summary ratings are actually done.62

Since maintaining a critical ineident file and keeping a diary are simply two differ- ent manifestations of the same concept, Bernarchn and Beatty -s suggestions for writing descriptions of behav Mr, presented n Lxhibit 6 4, apply equally to both methods of record-keeping.61

# Minimizing Rater Errors

The third technique which is av ailable to help raters keep accurate records of their observations is the use of a checklist. Exhibit 6.5 displays a checklist devised by William Ronan for evaluating college classroom teaching effectiveness.'4

Ronan's checklist was devised for students to use when evaluating the classroom teaching performance of their professors. Similar checklists can be devised for use by a variety of observers from different perspectives. The secret to devising these checklists is to perform a thorough job analysis- -using the critical incident technique or a similar method--to determine the key behaviors which distinguish effective from ineffective performance. Brief descriptions of these key behav iors are then arranged in checklist format and provided to observers who are in a position to see the occurrence of these key behaviors.

The checklist thus serves two important purposes.

(I) focuses the observers' attention on important behav iors, and t 2) pros ides a record of those behaviors which were actually observed.

# It.

Note that the checklist could be formatted such that the observer would provide the actual time and place each behavior occurred; or that each incident which occurred would be described in more detail in anecdotal form. The checklist could even be formatted such that the observer could rate the frequency of occurrence of each behav- ior, or that each behavior be weighted in terms of its contnbution to effectiveness. These and other modifications serve as the bases for such modern performance appraisal systems as Behavioral Observation Scales, Behavior Summary Scales, Behavioral Discrimination Scales, and Behavioral Assessment Approaches.55,56

This section has described three tools which are available to help raters keep records of meaningful observations. the critical incident file, diary-keeping, and the use of checklists. Which format is employed in any performance appraisal system is a matter of preference, however, the employment of one or more of these tools--or another such tool which forces raters to keep contemporaneous records of important instances of behavior--is essential if the system is to produce valid measures of perfor- mance during the period of time represented by the appraisal rating.

- 8. Standardize the rating context.

Holley and Jennings have described the importance of standardizing the perfor-

# mance appraisal rating process:

Because appraisals are used to make judgments for personnel decisions, such as promotions and compensation, and appraisal data are used to make com- parisons among employees, appraisal systems must be standardized in form and administration. Lack of standardization in forms, appraisers, procedures, and on raises the question of whether differences in performance appraisals result from the system and its administration rather than from differences in employee's performance.57

# 85

# 86

# Performance Appraisal

Many of the suggestions presented in previous sections of this chapter are focused on providing this necessary standardization. For example, the proper appraisal instru- ment must be chosen so that all raters are using the same dev ice. Rater selection, training, and involvement are intended to ensure that all raters share a common view- point and understanding of the appraisal process. The techniques described in the previous two sections are designed to make certain that there is standardization in the observation and recording of key instances of actual behavior.

However, there are other factors in the appraisal setting which also must be consid- ered. For example, William Sauser, Carlos Arauz, and Randall Chambers found that the level of background noise present when ratings were produced could have a signifi- cant effect on those ratings." Other contextual factors w filch have been found to influ- ence ratings include the presence of higher-level supervisors in the room where ratings are produced, the number of ratees evaluated in one session, the presence of environ- mental stressors, and the time available for making the ratings.59

Administrators who are serious about reducing the possibility of error in perfor- mance appraisals should consider standardizing such contextual factors as the time and place in which ratings are done, the number of ratees to be appraised at one time, and the presence of supervisors, trainers, and other persons when ratings are being produced. It should be obvious that a rater who is trying to evaluate 35 subordinates in an hour while working in a hot, crowded, noisy room late at night will quite likely pro- duce different scores than when evaluating five subordinates in an entire morning while working in quiet, comfortable surroundings.

To maintain fairness for all ratees, the administrator should ascertain that all ratings are produced under the same standardized environmental conditions. This may require, for instance, that a specified time and place be established at which all raters will per- form their work.

- 9. Motivate the raters to do a good job.

No matter how sophisticated a performance appraisal sy stem has been established,

no matter how well the raters have been trained, no matter how many observations of behavior have been recorded, no matter how carefully the context has been standard- ized, there still remains an essential factor which heavily influences the validity of the ratings obtained. "individual raters and their motivation or hick of motivation) to rate accurately. "60

Richard Klimoski makes the following obsery anon concerning this crucial factor.

issue of motivation toward accuracy must be (Ultimately) the critical confronted But, in my opinion, it can only be dealt with by creating a climate or ethic for careful and ':onsidered employee assessment. I also feel that prime responsibility for doing this lies with upper management, and especially with the chief executive officer.6I

# Minimizing Rater Errors

Sonk of the ideas Klimoski provides to create this Llimate include the following:

I. Top management must establish and support specialists within the organization itself who are capable of de\ eloping and implementing appraisal systems.

- 2. Top management must personally use aud demonstrate careful assessment of its own staff. Actions speak louder than words.

- 3. Careful performance assessment should be made an explicit part of each It may even be written into a job manager's job responsibility. descrip'ion.

- 4. Make use of appraisal data in corporate decisions affecting staffing. . Decisions with regard to promotions, to reductions in force, or to salary adjustments should be based, at least in part, on assessed performance.62

Commitment from the top has long been reLognized as the key to successful implementation of any organization-wide program. Klimoski has proxided excellent advice to be followed by administrators who w ant to demonstrate a real Lommitment tc the implementation of a valid performance appraisal system.

- 10. Maintain the quality of the program.

Any administrator who follows the nine suggestions desmbed tiboke when devel- oping and implementing a perfonuanLe appraisal program will most likely Lonstruct an lloweer, just like the outstanding system which will produce valid, useful results. finest automobiles, perform:I-IL,: appraisal systems must be properly maintained if they are to continue to operate at optimal levels.

The administrator who wishes to maintain an expellent systi:m should make certain that appraisal forms and obsen ational aids are kept rele ant and up-to-date, particularly when job content has changed. New superisors must be properly trained, and all raters should be given periodic "refresher Louses' to make certain they are Lontinumg to interpret and use the scales in the presubed manner. Statistk.al analyses should be per- formed to monitor the reliability and k aliduy of performance appraisal ratings.6' Raters should be periodically reminded of the importance of accurate ratings, and reinforced for doing a good job of appraising and de\ elopiniz subordinates. Finally, the entire appraisal prot,ess should be subjected to a peinAlk program eN, Autumn to make certain that it is still meeting the objeLtik es originally esta)lished tw itand re ised if it is not, or if the objectives have changed.

Within this context of progi tni ek A11,16011 lot performance appraisal systems, the

administrator should attend to the :,age words of K ujaw ski and Young

# 87

# 88

# Performance Appraisal

Ensuring that :lie appraisal forms are being completed is only part of the monitoring proceAre Many organizations are proud of the fact that all of their appraisal forms are submitted on time with all of the proper signatures in their proper places and that they have files full of them to prove that this is being done. But how well are the appraisals being used? In an effective pro- gram, the emphasis is on the results produced. These can be checked by asking such questions as: What is the turnover rate? Are people being promoted from within or does the organization have to go outside to get quali- fied people to fill vacancies? How do the people using the program feel about it? Do they feel that it is meeting their needs and tie needs of the organiza- tion? Is it being revised to meet changing organizational goals?6-

After all, the performance appraisal system is a tool designed to enhance organiza- to make certain that it is

tional effectiveness. achieving that purpose.

It should be examine pet

# Conclusion

Due to the frailties of human skills in observation, peiLeption, memory, and evalu- ation. any performance appraisal system whiLli indudes human beings as part of the process will necessarily include some level of error. However, there ale steps which administrators can take to greatly minimize this level oferror.

This chapter has presented ten techniques w Ina are designed to reduce rater errors in observing and appraising performance. These techniques are. (1) select appropriate raters, (2) clarify the purpose of the performance appraisal program, (3) choose the nght format and content, (4) involve raters in creating 0i interpreting the rating scale, (5) train the raters, (6) provide opportunities for the raters to observe the performance being appraised, (7) help the raters keep records of meaningful obsery ations, (8) standardize the rating context, (9) motivate the raters to do a good job, and (10) maintain the quality of the program.

Administrators who use these techniques when devising and implementing their performance appraisal programs will be riddy rewarded. The resn,ung appraisal systems should serve as powerfui Loots fo enhancing organizational eff,..tiveness.

# Endnotes

1

## 11 John Bernardm and Richard W. Beatty, Petlottnan« Appraoal /b.sc.s,sing

Human Behavior at Work, (Boston. Kent, 1984), pp. 238-239.

2.

J P. Gifford, Psychometric Method,s 2nd ed., (New York. McGraw-Hill,

1954), pp. 278-280.

I '3

# Minimizing Rater Errors

- 3. William I. Sauser, tr., A Comparative Evaluation if the Effects of Rater Participation and Rater Training on Chat acteristic.s if Employee Performance Appraisal Ratings and Related Mediating I atiables (Doctoral Dissertation). (Atlanta. Georgia Institute of Technology, 1978). pp. 16-20 Patricia C. Smith, "The Problem of Criteria," in Handbook of Industrial and Organizational Psychology,. ed. Mary in D. Mimetic. (Chicago. Rand McNally, 1976), pp. 757-758.

5.

## Adapted from Sauser, A Comparative Evaluation,. pp. 216-217.

6.

Ronald Taft, "The Ability to Judge People," Ps.',( hological Bulletin 52

(January 1955), p. 20

- 7. Walter C Borman, "Indy, idual Differences Correlates of Accuracy in Evalu- ating Others' Performance Effectiveness," Apphtd Ps.v( ho/ogu a/ Measurement 3 (Winter 1979), pp. 103-115. 8.

Kenneth N. Wexley and Richard Khmoski, "Performance Appraisal: An Update," in Managing Human Resources in Rf.tail Organizations, ed. Arthut F. Brief (Lexington,. MA: Lexington Books, 1984), p 34.

- 9. William I. Sauser, Jr., "Evaluating Employee Performance. Needs, Problems, and Possible Solutions," Public Personnel Management 9 (January February 1980), pp, 1 1 . 1 8 .

- 10. Wallace G. Lonergan, "Appraisal, Performance," in Handbook for Profes- sional Managers, eds. Lester R. Bittell and Jackson E. Ramsey (New York. McGraw- Hill, 1985), p. 33. 11.

- 10. Wallace G. Lonergan, "Appraisal, Performance," in Handbook for Profes- sional Managers, eds. Lester R. Bittell and Jackson E. Ramsey (New York. McGraw- Hill, 1985), p. 33. Bernardin and Beatty, op. cit., p. 268.

# Lonergan, op. cit., p. 33.

- 13. Guilford, op. cu., p. 295.

14.

# Lonergan, op. cit., p. 33.

15.

## Bernardin and Beatty, op cit., pp. 62-127.

- 16. Carl J. Kujawski and Drew M. Young, "Appraisals of 'People' Resources," in ASPA Handbook if Pcoonncl and Industrial Relations, eds. Dale Yoder and Herbert G. Henenian, Jr. (Washington, DC. Bureau of National Affairs, 1979), pp. 4.185-4.199. Bernardin and Beatty, op. cit., pp. 233-234.

- 18. Richard Klimoski, "Performance Assessment and Retail Organizational Effectiveness," in Managing Human Resources in Retail Organizations, ed. Arthur P. Brief (Lexington, MA: Lexington Books, 1984), pp. 68-69. Klimoski, op. cit., p. 69.

## 20, Douglas McGregor, The Human Side of Enterprise, (New York: McGraw-

Hitl, 1960),

# 89

# 90

# Performance Appraisal

- 21. Douglas McGregor; "An Uneasy Look at Performance Appraisal," Harvard

## Business Review 35 (May-June 1957), pp. 89-94.

## Kujawski and Young, op cit., pp. 4.163-4.164.

- 21. 1954), p. 303.

Peter Drucker, The Practice of Management, (Nov York. Harper and Row,

- 24. Kujawski and Young, op. en, p. 4.164

25.

# Sauser, A Comparative Evaluation.

26.

Stanley B. Silverman and Kenneth N. Wexley, "Reaction of Employees to Performance Appraisal Intenievvs as a Function of Their Participation in Rating Scale Development," Personnel Psychology 37 (Winter 1984), pp. 703-710.

Patricia C. Smith and Lorne M. Kendall, "Retranslation of Expectations: An Approach to the Construction of Unambiguous Anchors for Rating Scales," Journal of Applied Psychology 47 (February 1963), pp. 149-155.

27.

28.

## Sauser, "Evaluating Employee Performance," p. 16.

Samuel B. Green, William I. Sauser, Jr., James N. Fagg, and Cecilia H. Champion, "Shortcut Methods for Deriving Behaviorally Anchored Rating Scales," Educational and Psychological Measurement 41 (Fall 1981), pp. 761-775.

29.

- 30. Cecilia H. Champion, Samuel B. Green, and William 1. Sauser, Jr., "Development and Evaluation of Shortcut-Derived Behaviorally Anchored Rating Scales," Educational and Psychological Measurement 48 (Spring 1988), pp. 29-41.

- 31. Bernardin and Beatty, op. cu., pp. 258-262.

32.

# Sauser, op. cit., p. 16.

- 33. Guilford, op. cit., p. 280.

34.

## Sauser, A Comparative Evaluation, pp. 39-43.

- 35. Kujawski and Young, op. cit., p. 4.165.

- 36. William H. Holley and Kenneth M. Jennings, Personnel, Human Resource

Management Contributions and Acui:ittes 2nd ed., (Chicago. Dryden 1987), p. 272.

- 37. Duane P. Schultz, Psychology and Industry Today 3rd ed., (New York:

Macmillan, 1982), p. 181.

James A. Buford, Jr. and Sonya T. Collins,. Performance Appraisal. Concepts and Techniques for Local Government, (Auburn University, AL. Alabama Cooperative Extension Service, 1986), p. 37.

38.

- 39. Gary P. Latham and Kenneth N. Wexley, Increasing Produetivit, 'Through

## Performance Appraisal, (Reading, MA: Addison-Wesley, 1981), pp. 107-111.

- 40. Kujawski and Young, op. cit. pp. 4.182-4.184.

41.

# Sauser, op. cit., pp. 212-218.

42.

# Ibid.

# Minimizing Rater Errors

43.

## Sauser, "Evaluating Employee Performance," p. I!.

- 44. Christina G. Banks and Kevin R. Murphy, "Toward Narrowing the Research- Practice Gap in Performance Appraisal," Pet-auntie' Psychology 38 (Summer 1985), p. 341.

- 45. Ernest J. McCormick, "Job and Task Analysis," in Handbook of Industrial and Organizational Psychology, ed. Marvin D. Dunnette (Chicago. Rand McNally, 1976). John C. Flanagan, "The Critical Incident Technique," Psychological Bulletin

51 (July 1954), pp. 327-358.

John C. Flanagan and Robert K Burns, "The Employee Performance Record: A New Appraisal and Development Tool," Harvard Business Review 33 (September 955), pp. 95-102.

47.

- 48. William I. Sauser, Jr., "Critical Incident Technique," in Concise Encyclo-

pedia of Psychology, ed. Raymond J. Corsini (New York: Wiley, 1987), p. 272.

49.

# Smith and Kendall, op cit.

50.

# Sauser, op. cit.

- 51. Bernardin and Beatty, op. cit., p. 233. P. 53. Ibid., pp. 263-264.

- 54. William W. Ronan, Evaluating College Classroom Teaching Effectiveness (PREP Report No. 34), (Washington, DC. U.S. Gover anent Printing Office, 1972), pp. 23-25.

- 55. Wexley and Klimoski, op. cit., p. 81.

- 56. Latham and Wexley, op. cit.

- 57. Holley and Jennings, op. cit., p. 271. 58. William I. Sauser,

Jr., Caros G. Arauz, and Randall M. Chambers, "Exploring the Relationship Between Level of Office Noise and Salary Recommenda- tions: A Preliminary Reseal _h Note," Journal of Management 4 (Spring 1978), pp. 57- 63.

59.

# Sauser, A Comparative Evaluation, p. 32.

- 60. Bernardin and Beatty, op. cit., pp. 267-268.

- 61. Klimoski, op. cit., p. 72.

62.

# Ibid.

- 63. Guilford, op. cit., pp. 373-413.

- 64. Kujawski and Young, op. cit., p. 4.157.

fl)

# 91

# 92

# Performance Appraisal

## Exhibit 6.1. Common Rater Errors Which Should He Avoided

Leniency This error occurs when the supervisor rates an employee (and probably other employees) higher on every item of the rating scale than the employee's true lc el of performance actually deserves.

Severity This error, the opposite of leniency, occurs when the supervisor rates an employee (and prob- ably other employees) lower on every item of the rating scale than the employee's true level of performance actually deserves.

# Central Tendency

This error occurs when the evaluator uses only the central portion of the scale, ignoring the high and low extremes, even when the employee's true level of performance deserves an unusually high or low rating.

Extremity This error, the opposite of central tendency, occurs when the evaluator uses only the high and low extremes of the scale, ignoring the central portion, even when the employee's true level of performance deserves a more moderate rating.

# Halo

This error occurs when the evaluator forms a general, overall impression of the employee's performance, then fills out the rating form to reflect this impression. This practice should be avoided. Instead, the rater should consider each item on the scale individually and should try not to let his/her rating of the employee on one item influence the rating on another item.

Logical This error, similar to the halo error, occurs when the evaluator, in an attempt to appear consis- tent, bases his/her rating on "logic" rather than on observation, thus allowing his/her response to one scale item to unjustly influence the response to another. As stated above, each item on the scale should be considered individually. An empiv,,PP's level of performance will typically not be perfectly consistent (from item to item), thus there is no requirement that the rating of the employee be somehow logically consistent. What is important is that the ratings reflect only the employee's actual level of performance on each item.

Proximity This error, similar to the two above, occurs when the supervisor allows his/her rating on one item 3f the scale to influence the rating on a second item simply because the two items are located close to one another on the scale. Again, each item should be considered independently.

Contrast and Comparison These errors occur when the supervisor rates his/her employees not accord- ing to the standards specified on the scale, but in contrast or comparison to some other kind of standard, such as the performance of the best or worst employee the supervisor has ever known, the level of performance the supervisor thinks he/she could attain if he/she were doing the job, etc. Each employee should be evaluated independently according to the standards specified on the rating scale, not in comparison with other employees, ideals, etc.

Source William 1 Sauser. Jr, A Comparative Evaluation of the Effects of Rater Partuvatiun and Rater Training on Characteratics of Employee Perfurrnance Appraisal Ratings and Related Afedialing Variables (Doctoral Dissertation) (Atlanta: Georgia Institute of Technology. 1978). pp 216.217.

1 04

# Minimizing Rater Errors

# Exhibit 6.2. A Comprehensive Training Outline for Student Raters of Faculty Classroom

# Teaching Performance

## I. Clarification of the aims and purposes of rating.

# A

The evaluation of professors' teaching performance is a commonly occurring event.

When we think of "faculty evaluation," we usually visualue a formal process involving rating forms, computer printouts, etc. Actually, the evaluauon of professors' teaching performance occurs quite often, usually in an informal manner.

2

Students frequently "compare notes" and "spread the word" about professors. As they do this, the students arc informally evaluating their professors, often on the basis of reputation and randomly observed events.

3

Professors often evaluate themselves and other professors in Informal discussions. These Informal evaluations also may be large!) based on reputation and randomly observed events, as well as comments from two or three students.

4

Deans, department heads, and others are faced with making decisions regarding promotion, tenure, salary, ,ourse assignments, etc., for their professors. These deci- sions require some type of evaluauon of the profcssors in question. When objecuve data are not available. these decisions are frequently based upon some type of informal evaluation, such as reputation, random observauons, or the comments of two or three students or faculty members, even though these are certainly not the fairest ways to evaluate faculty members.

# B

There is a need for systematic, objective information regarding teaching performance.

For lack of more objecux e data, Important decisions are often made on the basis of the "informal evaluation" described above. As noted, much of this informal evaluation is based on hearsay, reputation, random comments and observations, etc. These sources are often inaccurate and even unfair They typically present a distorted, biased picture of the professor's true teaching ability and performance. In order to increase the possi- bilities of appropriate, unbiased, fair decisions being made, It is necessary to gather more objective, systematic,. relevant information about faculty teaching performance. Teacher rating forms are one means of making lanky evaluation more objective and systematic, and less biased.

2

One major problem with man) faculty rating forms is that they can be interpreted dif- ferently by each student neer. Thus, characteristics of the type of form used can influ- ence the outcome of a teacher evaluation project. Students do not always agree on the definition of "good teaching performance," and what one sees as "excellent" perfor- mance may be only "fair" to another. Since the outcome of the rating process can be as easily influenced by how the raters interpret the form as by the faculty member's actual teaching performance, it is important to make sure that all of the raters interpret the form as similarly as possible The teaching behaviors to be evaluated and the meaning of each point on the scale should he clearly specified to ensure nearly uniform inter- pretation Otherwise, the raters may all be rating different aspects of behavior, and the data will not be meaningful.

3

In order to be useful, faculty evaluation data must be reliable. That is, the evaluations by several independent raters of the same professor s teaching perfomiance in the same class should be relatively consistent- -there should be relativ,ly high agreement among the raters. If there is a very low rate of agreement among the raters, the Information will obviously be of little use.

1

# 93

# 94

# Performance Appraisal

C.

## Some uses of objective faculty evaluation data.

1.

FeedbackObjective faculty evaluation data serve as relatively effective feedback from the students to their professors. Teacher evaluation forms enable students to communi- cate ideas to their teachers, to make then teachers aware of particular strengths and weaknesses in their courses and in their teaching methods, and to suggest improvement when necessary. Since learning depends on feedback, this information is essential if professors are to improve their courses and teaching methods in the future. The primary use of faculty rating forms is to provide this important feedback to the indi- vidual faculty members.

2

Personnel actionsObjective faculty evaluation data, when available, can be used to influence decisions regarding such issues as tenure, promotion, and salary adjustment. Decisions based on objective data are typically fairer than those based on hearsay, reputation, and other "informal" data. Student evaluations of teaching performance are rarely the major cnteria considered when personnel action decisions are made, but they can certainly have some influence.

- 3. Development Objective faculty evaluation data Lan help deans and department heads dentify any particular training need' or special tuents in their professors, thus provid- ing them with sug,esttons for faculty develcpment. Individual professors can also identify their own particular weaknesses and seek to improve themselves. PlacementObjective faculty evaluation aata can be used to influence decisions regarding course assignments, class sues, etc.

- 3. Development Objective faculty evaluation data Lan help deans and department heads dentify any particular training need' or special tuents in their professors, thus provid- ing them with sug,esttons for faculty develcpment. Individual professors can also identify their own particular weaknesses and seek to improve themselves. PlacementObjective faculty evaluation aata can be used to influence decisions regarding course assignments, class sues, etc.

4.

5

Responsibility- -The faculty evaluation process often enhances a professor's feelings of responsibility toward his/her students and dunes as a teacher.

EffectivenessT'Autigh the above uses, objxtive faculty evaluation data can help improve departmental, school, and university effectiveness, as well as the effectiveness of the individual faculty member.

D. Additional points regarding faculty evaluation

1.

There arc many different duties involved in the job of college professor. While class- room teaching :s not the professor's only responsibility, it is an important part of his/her job. Auburn University lists teaehing as as faculty members' most important duty.

2.

Students are not the only persons whose evaluations of teat hang performance should be sought, but their evaluations should be considered carefully. Students are one of the major consumer groups of the university's expertise and are certainly affected by the faculty's performance. Furthermore, whereas deans, department heads, and other faculty members rarely observe professors' teaching performance first-hand, and thus 'ire not in a strong position to provide objective data, students are in an excellent posi- tion to observe and report on faculty teaching behavior.

Teachog is multi-dimensional. There are many facets of teaehing performance and it is probably not possible to take all of them into aeeount in ally one performance measure or rating form. The rating form should, however, Lover as many important teaching behaviors as possible and should certainly provide adequate coverage of the facets it is intended to measure.

4.

The purpose of faculty ,valuation is to improve professors' teaelling performance, not to damage faculty members in any way The process should only be used construc- tively, never destructively.

II.

III.

# Minimizing Rater Errors

Introduction of the Behaviorally Anchored Rating Scale,

A Most faculty rating forms are de\ clupc.1 by administrators or faculty committees with limited student input. The scale used in this project, howevcr, was developed through student participation. and is intended to be clear and meaningful to student raters. The scale dimensions and behavioral examples were provided by Auburn students participating in earlier phases of this study

Note kt this point in the training Ne,stun the ,.ale the following points )

shussn to the trainee, A lull lit-Sl,nptIon of the ,sale includes

B.

Instruction on the meaning of the characteristics to be evaluated.

C.

Instruction on the meaning of each anchor point used on the scale.

D.

Instruction on how to use the scale.

## Instruction on the avoidance of common pitfalls in rating

# A

# Lack of objectivity

Some student raters evaluate her professors on the basis of supposition, euesswork,, and reputation thus defeating the entire purpose of using the rating forms. A student's rating of his/her professor should be based only upon first-hand observations of actual behaviors, not comments made by other students, reputational factors, etc. A student who has not observed a teacher first-hand should not cv aluate that teacher Nor should a student let his/her rating of a professor be influenced by what other students think.

2

Some student rater, base their entire rating of a professor on one or two instances of extremely good or extremely poor teaching behav Jur, While these isolated extreme Instances should certainly be considered, it is important also to keep in mind the typi- cal, "day-in, day-out" behavior of the professor.

3

AB students tend to have "first impressions' of their teachers, but some students never change these impressions, even in the face of behaviors to the contrary, and base their ratings exzlusicely on their first impressions. The professor's behavior throughout the quarter should be considered who, his/her performance is being evaluated.

4

The most common problem involv mg lack of objectivity is allow ing some biasing factor to affect a professor's ratirig. As difficult as n is, student raters should strive not to let such factors as the professor's agc, sex, rank, or appearance, the course's level of difficulty, or the student's own performance (i.e grade in the course) or personal liking or disliking of the professor influence the performance ratings given to thei professor. A student's rating of his/her professor should be influenced only by the professor's actual behavior while teaching the course. not by any biasing factor. Non-teaching behaviors, such as consulting and research, should also typically be ignored when the professor's teaching performance is being evaluated.

B. Common rating "errors" to avoid.

Note '[his preNentation is ao-ompanied b, a siNual displa) ul huv, the, t.rrur, ssuuld appear on the Ilehastorally Anchored Rating Scale )

LeniencyThis "error" occurs when the student rates the professor (and probably other professors) higher on -very item of the rating scale than the professor's truc level of performance actually deserves.

-

# 95

# 96

IV.

# Source

# Performance Appraisal

2.

Severity -This "error," the opposite of leniency, occurs when the student rates the professor (and probably other professors) lower on every lizrn of the rating scale than the professor's true level of performance actually deserves.

3

Central tendency -This "error" occurs when the student uses only the central portion of the scale, ignoring the high and low extremes, even when the professor's true level of performance deserves an unusually high or low rating.

4

Extremity -This "error," the opposite of central tendency, occurs when the student uses only the high and low extremes of the scale, ignoring the central portion, even when the professor's true level of performance deserves a more moderate rating.

5

Halo --This "error" occurs when the student forms a general, overall Impression of the professor's performance, then fills out the rating form to reflect this impression. This practice should be avoided. Instead, the student rater should consider each item on the scale individually, and should try not to let his/her rating of the teacher on one item influence the rating on another hem.

6

Logical- -This "error," similar to the "halo error," occurs when the student, in an attempt to appear consistent, bases Ins/her rating on "logic" rather than observation, thus allowing his/her response to one scale item to unjustly Influence the response to another. As stated above, each item on the scale should be considered individually. A professor's level of performance will typically not be perfectly consistent (from item to item), thus there is no requirement that the student's rating of the professor be some- how logically consistent. What is imporunt is that the ratings reflect only the profes- sor's actual level of performance on each item.

7.

Proximity- -This "error," similar to the two above, occurs when the student allows his/her rating on one item of the scale to influence the rating on a second item simply because the two items are located close to one another on the scale. Again, each item should be considered independently.

8

Contrt.st and comparison- -These "errors" occur when the student rates his professor not according to the standards specified on the scale, but in contrast or comparison to sonic other kind of standard, such as the performance of the best or worst professor the stujen. his c 'en known, the level of performance the student thinks he/she could attain if he/she were teaching the course, etc. Each professor should be evaluated indepen- dently according to the standards speared on the rating scale, not in comparison with other teachers, ideals, etc

# Practice in the use of scales.

(Note Dunng the time remaining in the training session, students praetw using the Itehas 'orally AnLhored Rating Scales to csaluate professors of their Loot (housing 1No pl.( lessors are identified I Students are env ouraged to examine then' on ratings for examples of bias and error. and to correct their ratings when apnropnate

V v illiam I Sauscr, J r . 4 Comparative Cv,a/uatiun of the Life, t+ of Haler Pam, ifmiton,rnd Rater I raining on Character- atics of Employee Performan,e Appraisal Ratings anti fit ialot Aft(italing Larables (Doctoral Dissertation) (Atlanta Georgia Institute of.' ethnology, 1978), pp 212-218

# U

# Minimizing Rater Errors

## Exhibit 6.3. Examples of Positive and Negative incidents of College Classroom

# Teaching Behavior

Example A (Positive): On the first day of his class, Professor Jones passed out a detailed syllabus which included his office location, hours, and telephone number; a description of the textbook and daily reading assignments, his objectives for the course; his policies on attendance, testing, calculation of grades, and dishonest behavior; and descriptions of several required class assignments. He discussed the syllabus in class and answered all questions asked about it. The syllabus served as "the rules of the class," and any questions about grading, attendance, or assignments which came up during the semester were answered with reference to the written syllabus. The students reported that they appreciated having the professor's policies set out clearly at the beginning of the semester so that they knew exactly what was expected of them. They reported that the syllabus reated a sense of fairness and allowed them to concentrate their attention on learning course content rather than trying to figure out what was expected of them by Professor Jones.

Example B (Negative) Following a lecture over a very complex theory, Professor Smith asked his students if they had any questions. One student, obviously confused, asked a question which revealed his lac:. of understanding of the theory. Professor Smith "blew up" at the student and called him "a stupid idiot" for failing to understand the theory. Professor Smith did not answer the question, nor were any other questions asked by the students. After class, several of his classmates told the student who had asked the question that they had not understood the theory either, but had been to afraid to ask a question lest they too be humbled in class. Several students failed the subsequent test because their answers indicated a lack of understanding of the theory. By handling the student's question differently, Professor Smith might have been able to better educate these students.

# 97

# 98

# Performance Appraisal

# Exhibit 6.4. Bernardin and Beatty's Suggestions for Writing Descriptions of Beha for

1.

Use specific examples of behaylor, not on, liksionA about the "goodness" or "badness" of beha% 'or.

Use this. Gwen told her secretary when the work was to be completed, whether it was to be a draft or a final copy, the amount of spate in w lila it had to be typed. and the kind of paper necessary.

# Not this.

Liesa gives good instructions to her seta-clay Her instnit lions arc dear and cones:

Avoid using adjecutc qualtfier., in the statements, use descriptions of beliaior.

Use this. Aimee repeated an employee's communication and its intent to the employee. She talked

in private, and I have never head her repeat the conversation to others.

Not this: Kelly does a good job of understanding problems. She is kind and friendly ,

3.

Avoid using statements that make, ,isawnpuolia about an employee's kiwithAige of the job, use descriptions of behavior.

Use this. Sarah performed the disassembly procedure for rebuilding a carburetor by first remot ing the Lap and then proceeding with the internal components When she was m doubt about the procedure, she referred to the appropriate manual.

Not this. Sam knows how to disassemble a carburetor in an cffiuc,it and effeLtRe manner

4.

Avoid using frequencies in statc.aents; use descriptions of behavior.

Use this. Patrol Officer Garcia performed the search proteuae by first informing the arrested of their rights, asking them to assume the search position, and then conducting the search by touching the arrested in the prescribed plates. When the SC,11111 was completed, Garcia informed the arrested. He then proceeded to the next step in the arrest procedure

# Not this.

Patrol Off-ILA r Dinlio always does a good job in performing the search protedure

5.

Avoid using quanutauve wino (numbers). use descriptions of behavior.

Use this. Nancy submitted her reports on tune. They contained no misinformation or mistakes. When discrepancies ottained on reports from the last period, she identified the causes by referring to the changes in accounting protedures and the imp& t they had on this period.

Not this: Mr. Boebel met 90% of deadlines with 95% accuracy.

6.

Proxide sufficient detail so that an assessment can be made of the extent to which LharaL ten .tks of the situation beyond the control of the ratee may have affected the beim

Use this. Mr. Dzaidzo's failure to hit the "target date" for the sky-hook quota was caused by the failure of Mr. Ressler's department to pros ide the ordered supply of linkage gaskets Mr Dzanlio submitted four memos in aunt-pawn of and in ref-creme to the gasket shortage.

# Not this:

It wasn't Diaid/o's fault that he didn't hit the deadline.

Source I torn II John &martial and Richard W Ikatty, Pcrforrn.jatsApppi,i1 NY,comg,llumaii Ilthaviotir at Work (Boston Kent Publishing Company, I98 I pp 263 4.0 by Wadstsurth, Iuc Rtvinted by pernussion of PWS Publishing Company, a division of Wadsworth, Inc

I013

# Minimizing Rater Errors

## Exhibit 6.5. Ronan's Evaluative Questions for Assessing Teaching Performance

Note: Each section would be headed Anil a question suLh as "Did the professor in this t,ourse ...""

1.

# Persaial Relationships with Students

# Yes No

Know or attempt to know students' names'? 1. 2. Talk with students before and/or after class? 3. Hold social events for his students? 4. Give advice or assistance at student request (class cr office)

# with personal problems?

- 5. Discuss (answer questions on) extra class issues? 6. Compliment students on good answers? 7. Encourage (answer) all questions in class? 8. 9. Ridicule, "ride," or otherwise embarrass students (either on questions or their performance)" Encourage or give individual help A ith course material (class or office)? Lose control of himself in class (shout, curse, show anger, etc.)" Bother (harass) students during recitation, quizzes, etc.?

- 10. II. 12. 13. Make threats concerning classwork or personal behax ior? 14. Accept legitimate excuses, explanations (as for missing quiz)? 15. Refuse to listen to or recognize other viewpoints in class? 16. Say or indicate in some way that students are inferior" Provide special "help" sessions for course material (inui \ 'dual and/or dam)? 17.

- 11. Classroom Administration

I. Meet all scheduled (rescheduled) classes? 2. Arrive on time for all classes" 3. 4. Discuss quiz dates or deadlines for student convenience" 5. 6. Distribute a course outline or study plan (course objectives)" 7. 8. Give examples of quiz items? 9. Require and grade homework? 10. Return papers :Ind quizzes promptly? II. 12. Make false statements concerning course requirements i number of

Inform class if he would be absent?

End lectures at end of classtime'?

# Follow course outline or study plan"

Permit classroom disturbances (such as students talking to call other)?

cuts, grading, etc.)"

- 13. Give excessive work"

# 99

# I

# 100

# Performance Appraisal

III.

# Student Participation

- 1. Ask student preference as to topics covered? 2. Ask students to critique his teaching? Schedule quiz/es, deadlines, etc., at the convemcn 3. Encourage (ask for) discussion. questions, or stude.i, pinions'? 4. 5. Ask questions to determine class (individual) understanding of course material"

# IV. Classroom Presence

- 1. Appear well groomed? 2. Speak clearly and distinctly a. Mumbh? b. Talk too softly? c. Talk in a monotone?

- 3. Use dramatic gestures (phrases) to emphasue important points" 4. Use humor in lecture to illustrate points? Read lectures from notes or book? 5. 6. Appear nervous, ill -at -ease during lecture" Talk or present material too rapidly? 7. 8. Give rambling, disorganised lecture? Look at students dunng lecture? 9. 10. Use language students understand? 11. Use profane language excessively?

## V. Organisation and Presentation of Material

I. Begin class with a review of previous work? 2. 3. Use current, pertinent, and/or personal examples to illustrate point" 4. 5. Admit not knowing answer to a question" 6. Use outside references to supplement course'' 7. Distribute handouts/notes to supplement course? 8. Use visual aids to supplement lecture? Provide for field trips? 9. 10. Have guest lecturers? 11. Have full command of the subject matter? 12. Give lectures different from (supplement) text? 13. Cover all course requirements? 14. Avoid trivial detail? 15. Answer questions; work problems if requested? 16. 17. Give erroneous information about course material's 18. Muse to explain material? 19. Make students learn "on-their-own"? 20. 21.

## Stress, in some way, important points in the material"

## Show usefulness of material in "real world"?

# Lecture over students' heads?

Follow course schedule? Prepare for class?

# Yes No

# Minimizing Rater Errors

VI.

# Evaluation of Student Performance

# Yes

Base tests on relevant (covered) material? Base tests on knowledge in principles rather than memoritatioi0 Base tests on emphasiied material?

1.

2.

- 3. 4. Make tests too easy or difficult? 5. Schedule quizies at regular Intervals? 6. 7. Comment on (correct) returned papers, qui//es, etc.') 8. 9. Excuse high average students from final? Permit extra work to improve grade? Disregard lowest test score in grading?

Allow adequate time to complete tests?

10.

- 11. Use same tests every quarter? P. Refuse to explain grading system?* Tell how students are to be graded? 13.

- 14. Curve grades either:

a To compare individual performance with class performance? b. To reduce student grades?

- 15. Return all papers and quines? 16. Grade all quizes and assignments? 17. Give makeup tests at individual convenience? 18. Grade on such things as major, sex, aloe, etc.?* 19. Grade on class attendance?* 20. Give final grades in accord with test scores?* 21. Grade on final exam only? 22. 23. 24. 25. Consider effort, participation, application in assigning final grade' 26. Use student to grade work?

VII.

# Interest in Job of Teaching

- 1. Make derogatory comments about teaching? 2. Make derogatory comments about the course? 3. 4. Criticn'e fellow teachers?

Indicate he would rather consult and/or do research than teach')

- This item would have to be answered after the student recelied his final grade. The major difficulty here would be admistrauce, that is, submitting the question to students after the course is ma and having it returned A suggestion might he to gi students the question, during the final examination and ask them to complete and return the form after they ha% e reLeII,cd their I.nal grade. Returns and their representativeness are problematical.

Soiree Witham W Ronan, Evaluating I. ollege e IdAsrown I ea, Ising OP, live nes. (PRI P Rt,port No 31), 03,,r.hinttlon, IX'

## S Government Pnnting Office, 1972), pp 23 .25

# 101

# No

A President's Perspective: A Rationale and Strategy for Building a Performance Appraisal Program

# Richard J. Federinko

During the past ten years, community college administrators !lace been forced to deal with a comple.c array of problems pnncipally associated with a shifting emphasis from growth to quality. Consequently, the challenges facing college administrators today hate never been greater. Faced with declining or fluctuating enrollment patterns, diminishing financial increasing expenditures associated with rapidly advancing technological changes, and pressing needs to provide a significant leadership role in economic development activit:es, community colleges are being asked to accomplish more with less with greater efficiency and effectiveness. As a result, insti- tutions must implement management systems and parameters which pros ide for greater accountability through effective planning, managing, and evaluating.]

resources,

Accountability is not a fad or "buzz." word that is going to fade away. Elected offi- cials at all levels, as well as their constituents, are demanding increased focus upon what is necessary, valuable, and productive. The focus and growing pressure on public institutions for greater accountability has resulted in an ever- increasing emphasis to examine more closely the quality of institutional programs and serch. es. However, institutions cannot be held accountable, only individuals. Thus,. growing numbers of states are requiring some form ut serious performance appraisal strategy for public education employees.

Since accountability is an issue that is here to stay, the time has arrived for the community college leaders of this country to take a serious appro ich to developing effective, periodic, systematic, and comprehensive appraisal programs. Such programs must be based on clearly articulated criteria and must be legally defensible. Further, the appraisal process should take a positive approach as a professional development aide. No one employee should be excused, and no one should be treated differently.

The major reason for performance appraisal focuses on its use as an important tool in building institutional e \cellence and accountability. This would seem to be reason enough. It is not, considering the ideal of self regulation. Do we want to maintain the prerogative of managing this activity or do we \Amu someone to do it for us or to us?

7

# 104

# Performance Appraisal

As has been well stated by John Kingdon, "If you're not ready to paddle when the big wave comes along, ycl're not going to ride on it. 1 he objective of this chapter is to present a strategy for developing and implementing a performance appraisal program in a postsecondary institution. The following material draws heavily on the experience of Southern Union State Junior College to demonstrate how a rather significant endeavor of this nature can be accomplished.

# Assumptions About People

Writing in the late 1950s, Douglas M. McGregor was one of the first writers to suggest that administrators who hold different assumptions about people in their organi- zations will behave differently toward them as well. This, of course, is the ba'is for McGregor's famous set of assumptions known as Theory X and Theory Y.3

Recall that if administrators feel subordinates are lazy, indifferent, and uncoopera- tive, they will treat them that way. Conversely, if it is assumed that their subordinates are hard working, open-minded, and interested in achieving organizational objectives, they will treat them quite differently. The irony is that consistent with reinforcement theory, people will tend to live up to expectations, in other words, treat people as losers and they will begin to act like losers. McGregor called this result a self-fulfilling prophecy.

While McGregor's work is almost 30 years old and has received some criticism, the real value is that an administrator influences a situation by his/her assumptions about neople. A number of other researchers have demonstrated the effect that expec- tations and environmental pressures have on human behavior. In particular, researchers such as John Roueche and George Baker recommend shifts from rigid, traditional forms of government to models of governance which are more humanistic and create a work environment that is caring and nt.rturing.4 Leadership assumptions and governance styles clearly impact upon employee performance.

In regard to performance appraisal, the administration would do well to provide a positive governance style which assumes that people want to do a good job and will not only accept performance appraisal, but will demonstrate a high degree of cooperation in carrying out a program to w hich they become committed. Therefore, adopt the Theory Y assumptions. There is nothing to lose and a great deal to be gained.

# Coping With the Literature

As would be the base with any major endeavor, it is a good idea to review the pub- lished research on performance appraisal. Several words of caution are in order. First, the amount of literature on the subject is overwhelming. It is simply impossible to read and understand all the valuable articles, books, and monographs that have been published in the past 5 to 10 years alone. If the sheer volume is not problem enough, many of the findings are discouraging. In fact, many studies conclude that little

# A President's Perspective

progress has been made in developing an efficient, Lost effeLin e, and psychometrically sound technique of performance appraisal.5

Consider, however, a different perspective. There are few, if any. other adminis- trative functions and processes in which there are proven methods. In fact the state-of- the-art in management is just as much a "jungle" as when Harold Koontz wrote his classic article.' But that doesn't seem to stop us in other activities. For example, the personnel selection process has the most far reaching consequences of any activity in administration. No researcher has ever devised a "perfect" selection test for any job; the best predictors of job success are only slightly better than chance. Yet we hire people like we know what we are doing. In fact, we also pay, promote and develop people based on imperfect theories.

This is not to disparage the literature. Revit w it but do not be intimidated by it. There are a numt_r of behavioral and outcome concepts and techniques that have been shown to work reasonably well. In fact, such authorities as Redfern and Scriven have developed models for public school systems and much of their work is useful in post- secondary education.' There are other methods such as trait rating scales, unstructured and impressionistic systems. and other non- job related approaches which work poorly, if at all. An examination of the different approaches should lead to a program that best fits the needs of the institution.

# Overcoming Fears and Apprehension

All members of the institutional community need to be sold on the performance appraisal program. Participatory management is itself a long-term performance strat- egy; on the other hand, a "top down" view invites failure.

One essential feature is an administrative mechanism for higher levels of manage- ment to review performance ratings, reinfon by an appeals procedure. A committee or group should be established to adjudicate disputed ratings and the group should include peers. The appeals procedure is particularly important in cases of demotion, suspension, or discharge for poor performance. It is also necessary to hold free and open discussions w ith all segments of an institution. It is at forums such as these that fears can be allayed and apprehensions addressed. These come in the form of the inevitable "what if?" questions and almost always involve a worst case scenario. It is usually possible to turn these negatives around. For example, an instructor might ask, "What if my department chair gives me a low rating because he dislikes me?" It can be pointed out that the rating criteria represent items that can be observed or measured, and that the department chair will be rated on how well he/she observes and measures per- formance. In fact, it can be clearly shown that a good performance, appraisal system makes it difficult to award ratings on likes and dislike s. I t is in the absence of such a system that biased ratings are likely to occur.

Superiors are often concerned that subordinates will resent being given low ratings on those aspects of the job where performance is deficient or will be uncooperative and

1

# 105

# 106

# Performance Appraisal

resist performance appraisal altogether. The answer is that sonic people ale difficult, but they are probably that way long before performance appraisal was instituted. The performance appraisal process itself provides a means to address certain aspects of these problems. Moreover, most administrators will agree that dealing with difficult people is a fact of organizational life and conies with the job. It is also useful to ask superiors to review their on assumptions about people to avoid McGregor's self-ful- filling prophecy.

Finally, it will probably be necessary to address the concerns of professional asso- ciations and possibly unions. These organizations may view with suspicion an admin- istrative activity which might be used to threaten job security or undermine well estab- lished seniority systems. While it may not be possible to gain their wholehearted endorsement of performance appraisal, is best not to adopt a confrontational it approach. At a minimum, be willing to "meet and confer" and establish as much common ground as possible. Keep in mind these organizations also have a stake in the accountability issue and face the same pressures felt by institutional administrators.

For everyone concerned, the best approach is to promote a positive climate of mutual trust. Most superiors want to be fair, and most subordinates will accept honest ratings. The key is a well respected concept of common law known as "good faith and fair dealing."

# Using Consultants

Most two-year colleges will require some outside assistance to develop an effective and legally defensible performance appraisal program There are a number of po.:,.1,1e. sources. These might include the state department or (avision of postsecondary educa- tion, extension units and/or faculty members of major universities, and private amsul- tants. At Southern Union we contracted with a nearby university which assembled a team of faculty members and graduate students representing several disciplinary areas: counseling, industrial psychology, foundations of education, educational administration, and management.

In assembling resources to undertake such a project, the following steps should

# prove useful:

## Identify potential internal resources from the faculty and administration.

# Appoint a project coordinator.

Conduct a needs assessment and determine the expertise required.

In selecting consultants, identify if possible persons with both professional expertise and successful experience in an educational setting.

Even if all or most of the technical assistance is obtained from consultants, it is neither necessary nor desirable to relinquish control of the project. A "lock and key"

# A President's Perspective

job by "outside experts" will have little Lredlbility with the administration and support staff and practically none with the faculty. It is the institution, not the consultants, who have to live with the results.

Before the start of the project, hold a round table discussion with the consultants. Discuss with them the purposes you intend to accomplish, the funds available, services the institution will provide, documentation to be provided, pilot testing. suggested methods and techniques for various job families, follow -up activities such as rater training, validity studies, legal defense (expert witness) evaluation, and similar issues. Moreover, recognize that an undertaking of this magnitude Will not be completed within a short time-frame. Participatory' type involvement requires time and an abundance of patience.

# Who is Covered

The major goal in performance appraisal should be to access individual work related contributions within the total institution--not just the faculty, nor the administra- tion, nor the support staff. A performance appraisal program should be for everyone, beginning with the president. There should be, of course, different procedures for dif- ferent job families. The performance of a dean is measured in terms of outcomes such as goals achieved and expectations net while the performance a library technician is expressed in temis of appropriate job-related behaviors. But in the final analysis, each person's performance is rated against a standard.

While there is disagreement in the literature on rating formats and rating scales, it is necessary to develop appropriate instrumentation. At Southern Union there are three subsystems, however, they each follow the same rules of combination and produce a rating on a 5-point scale. Thusi department chair, instructor, and custodian who receive an overall rating of "3.5" are performing at the same level, albeit in vastly different roles.

# Legality

When used as input to decisions such as retention, promotion, and merit increases, performance appraisal results have important legal implications. Even when used only for developmental purposes, it might be difficult to establish the fact that ratings have no bearing on administrative decisions. People are protected by federal laws and court decisions from discrimination based on race, color, sex, religion, national origin, age, physical handicap, and Veteran status. Moreover, the common law doctrine of employment-at-will has been significantly eroded in state courts. is extremely important that the performance appraisal sy stem be validated in accordance with appropriate regulations.8

# Therefore, it

While no performance appraisal system can be made grievance proof or immune to litigation, a properly designed validity study is an essential document when and if per- formance ratings are called into question by a regulatory agency or a court. The study

1 1,4-

# 107

# 108

# Performance Appraisal

should address such critical issues as job analysis, criterion de\ elopment, instrumenta- tion, procedures, and purposes Without evidence of validity, even systems designed by "experts" are likely to be rejected by the courts.

# Management Support

When beginning the implementation phase of a performance appraisal program, often the president or another administrator makes appropriate comments at a convoca- tion or issues a letter pledging his/her support. All this is tine if preceded by intimate involvement in the developmental phase and followed by a demonstrated personal commitment. If performance appraisal is to be taken seriously, managers and supervi- sors at all levels of the institution must be conscientiously involved. In fact, how well they accomplish this task should be reflected in their performance ratings.

# Shakedown Administration

No matter how competent and professional the seam that developed the program, or how high the level of management support, or how deeply involved were the faculty and staff from its inception, there will be problems in implementation. Behavioral anchors which were clear and concise when written and reviewed by 15 people in three levels of the organization will suddenly become vague and ambiguous. Rater errors and tendencies which were fully covered during rater training sessions will proliferate and several new ones will emerge. Carefully designed weightingsystems and rules of com- bination will come apart when the same people who signed off on the job analysis data point out that the criteria do not match their work assignments. When the dust settles, it will be disco.ered that the problems are not that serious and Lan be corrected without fundamental changes. The time to make these refinements, however, is during a shake- down administration or "dry run." It is not when the ratings are to be used for adminis- trative decisions.

# Concluding Remarks

Designing, developing, and implementing an effective perforniance appraisal system is not an easy task. In fact, the Southern Union process at times could have been described as difficult, confusing, controveisial, and time-consuming. But, "difficulty and confusion" were addressed early from the process by retaining individuals with pro- fessional expertise in implementing a sophisticated, comprehensive appraisal system. "Controversy" was mitigated through total institutional cc mmitment, involvement, negotiation, and communication. As far as the "time-consuming" aspect of the process, this is one factor which simply cannot nor ever will be eliminated. In fact, maintenance of the appraisal process at Southern Union continues to be time-consuming. Effective performance appraisal systems require continuous refinement and modification because position descriptions will be rearranged, errors will be found, new positions will evolve, and humans will change for the sake of change. Change, therefore, is a necessary ingredient in the evolution of an effective system of appraisal.

4

# A President's Perspective

At Southern Union, the "high road" to developing and implementing a performance appraisal system was taken. A genuiuely open and positive environment was created, disagreement was expected, negotiation was required, and individual participation by everyone was necessary. Through total institutioi,a1 commitment, a very positive out- come was achieved. But more important, Southern Union wisely invested in the posi- tive development of its greatest resource. its individual employees. Its employees are consequently highly motivated, achievement-oriented, and committed to accountability.

# Endnotes

## Gerald L. McManis and L. James Harvey, Planning, Management and

1.

## Evaluation Systems in Higher educatio (Littleton: Ireland, 1978), p. 1.

2.

John W. Kingdon, Agendas Alternative and Public Policies, (Boston, Little,

Brown, 1984), p. 173.

- 3. Hill, 1960).

## Douglas McGregor, The Human Side of enterprise, (New York: McGraw-

4.

John E. Roueche and George A. Baker, III, Beacons for Change. An Innova- tive Outcome Model for Community Colleges, (Iowa. American College Testing, 1983), pp. 1-3.

For an excellent discussion of these issues, see Arthur M. Cohen and Florence B. Brawer, Confronting Identity. The Comniunity College Instructor, (Englewood Cliffs, NJ: Prentice-Hall, 1972).

5.

6.

## Harold Koontz, "The Management Theory Jungle," Journal of the Academy

## of Management 4 (December 1961), pp. 174-188.

7.

See, for example, George B. Redfern, Eva'uating Teachers and Administra- tors: A Performance Objectives Approach, (Boulder, CO: Westview, 1982) and Michael Scriven "Summative Teacher Education," in Handbook of Teacher Education, ed. Jason Millman (Beverly Hills, CA: Sage, 1981).

8.

An excellent analysis of the various legal constraints that impact on the personnel function can be found in James Ledvinka, Federal Regulation of Personnel and Human Resource Management, (Boston. Kent, 1982), pp. 1-114 and particularly pp. 19-51 and pp. 91-101,

1 1 1

# 109

# Characteristics of Effective and Legally Defensible Performance Appraisal Systems for Postsecondary Education

## Bettye B. Burkhalter and James A. Buford, Jr.

Performance appraisal continues to beone of the most important responsibilities of administrators in postsecondary institutions. It increasingly is becoming a legal prob- lem; the growth of federal laws and regulations has created specific nghts for faculty and staff in their relationship with their employers. Characteristics of a performance appraisal system that accurately measures job contributions and is completely defensible in today's legal environment continue to be a matter of debate. Such a system may not exist. However, incorporation of the following will minimize many of the most common legal problems and lead to a more effective system.

Needs Assessment and Planning. An institution that is considering perfor- mance appraisal should decide in advance what the program is intended to accomplish. Uses of performance ratings might include input to placement, promotion, compensa- tion, development, and termination decisions. Only after the purpose is clearly estab- lished and the specific requirements are decided upon is the organization in a position to develop a performance appraisal program.

1.

2.

Participation. Research clearly has show n that work is a motivator and that most people want to do a good job.! A well respected philosophy is that the authority in an organization is delegated upward. Thus, it makes intuitive sense that people at every level need to participate in the development of a performance appraisal program. If they do not, it will be very difficult to gain their understanding and support during implementation.

Job Analysis. The cornerstone of the development of a performance appraisal system is job analysis.21 When an employment practice is to be defended on the basis of content validity, the job analysis establishes the rational link between factors used in appraisal and the critical work behaviors of the job.4 Two comprehen- sive reviews of characteristics of performance appraisal systems related to court decisions found that where job analysis was performed, courts ruled in favor of the defendarns in approximately 82 percent of the cases. Without job analysis, defendants

3.

8

# 112

# Performance Appraisal

lost every cases Job analysis should be conduct,-%1 when duties are reasonably stable so that conditions will be comparable to those which will exist when the performance appraisal instrument is used.

Performance Criteria. While traits such as initiative, enthusiasm, attitude, and loyalty are important to job performance, most often they are not suitable as performance criteria.61 It is better to develop criteria which describe observable job behaviors or outcomes. Even when the possession of a trait can be shown as critical for effective job performance, it is usually possible to design an observable measurement based on how job duties actually are performed.

4.

Appraisal Instruments. The various instruments should facilitate the admin- istration of performance appraisal under standardized and controlled conditions.8 Instruments should be designed carefully to accommodate both the criteria and method. If several criteria or scales are to be combined, the instrument should produce a com- posite rating based on the rules of combination!) Appropriate identification, comments, and signatory sections should be included.

5.

Reliability and Validity. To achieve the organization's purpose of accurately measuring performance and to satisfy legal requirements, the appraisal system must be valid; it must measure what it purports to measure. First, however, the system must be reliable. The ratings must yield stable and consistent results from one period to the next and across all items.'°. Reliability and validity studies should be conducted to meet technical standards of the "Uniform Guidelines on Employee Selection Procedures" and documented in a written reporin

6.

Testing the System. Prior to implementation of performance appraisal, a review should be conducted to ensure that the process selected supports overall objec- tives and will provide the needed information flew to such decision areas as compensa- tion, placement, and professional development. In many cases it may be necessary to conduct a pilot or "shakedown" test of the system to identify and address problem areas and work out procedural matters.12

7.

Communication of Policy and Purpose. The purpose and uses of perfor- mance appraisal should be stated clearly in the organizational policy as well as in the employee or faculty handbook. Procedures should be developed to cover which systems will be used for which jobs or job families, how often appraisals are to be con- ducted, documentation required, recourse, and similar matters. Fully informing all individuals of policies will minimize uncertainty and resistance and will increase the probability of positive results.13

8.

Rater Training. In many organizations, the task of observing and measuring job performance is poorly carried out. Research has indicated that rater training is more important than design considerations in improving accuracy of performance appraisal. Training programs should focus on improving rater skills in observing, recording, and appraising behavior with less emphasis given to such issues as rating distributions and

9.

I

CJ

# Characteristics

staistical measures.14 Extremely good results halve been obtained with training pro- grams designed to build observational skills and reduce such common problems as halo effect, first impressions, patterns of leniency and strictness, recency, and similar errors.'5 Raters must fully understand the critical importance of the interpersonal aspects of performance appraisal. They must develop skills in feedback, praise, con- structive criticism, and listening. Raters also must be sensitive to the situations and conditions faced by individuals. Finally, raters must develop skills for identifying, describing, and negotiating performance expectations.

- 10. Administration. The most basic requirement is that

the performance appraisal process should support the system's goals, conflicting multiple uses should be avoided. The system could be cost effective. Expenses should be balanced against the post appraisal impact on motivation and productivity.'6 Performance appraisal admin- istration must ensure that the people who are being rated understand the mechanics, including such issues as performance expectations, how ratings on vanous criteria will be weighted, and who will actually conduct the appraisal. Finally, it is very important that performance appraisal be conducted by raters who have directed and continually observed job performance.17

- 11. Privacy and Due Process. The Federal Privacy Act of 1973 created the Privacy Protection Study Committee (PPSC), which issued a series of recommendations in 1977. Among these was the suggestion that employees should have access to all records relating to their qualifications for employment, promotion, and pay increases and to records relating to discipline and discharge. Many professional groups have recommended voluntary compliance with these recommendations. Moreover, indi- vidual access to records builds confidence in the system's basic fairness, provides an additional means of communicating results, and protects the individual's rights.18. Adverse performance ratings can lead to denial of merit pay and promotions in some cases, dismissal. Due process refers to a systematic, orderly procedure where an indi- vidual has the opportunity to object and be heard.I9 Employee rights in this area are still evolving; however, courts increasingly are requiring employers to jastify their actions.20 Legal questions aside, organizations due process is a good management practice. A formal appeal process should be established to provide an impartial review of ratings that are disputed.

- 12. Audits. Performance ratings should be analyzed periodically for evidence of discrepancies and adverse impact. Statistical tests do not prove that raters are making errors or showing bias. However, properly designed analyses can highlight certain patterns that might not be found merely by reviewing a list of ratings. When such patterns appear, management should determine the cause and, if necessary, correct the problem--particularly when members of protected groups such as blacks and females receive significantly lower ratings. In the final analysis, the effectiveness and legal defensibility of a performance appraisal system will depend on its legitima,y as a tool for making employment deci- sions. The success of any system depends on its effective administration by all levels of management. A common failure of performance appraisal systems is the assumption

# 113

# 114

# Performance Appraisal

that forms, handbooks, and policy statements are just another set of procedures. No appraisal program, regardless of how well it is developed, will be effective or legally defensible unless administrators have a high level of commitment and make a continu- ous effort to carry out the complete process. A poor system can be made to work when the administrators make the effort to compensate for inadequacies in design. On the other hand, if a state-of-the-art system is poorly administered, it will surely fail.

# Endnotes

1.

## Frederick Herzberg, Bernard Mausner, and Barbara B. Snyderman, The

## Motivation of Work, (New York: Wiley, 1959).

2.

## Gary P. Latham and Kenneth N. Wexley, Increasing Productivity Through

## Performance Appraisal, (Reading, MA: Addison-Wesley, 1981), p. 73.

3.

## Kirkland v. New York State Department of Corrections, 374F. Supp. 1361

(S.D.N.Y.), 1974.

4.

Richard E. Biddle, Guidelines Oriented Job Analysis,

# Section

## (Sacramento: Biddle and Associates, 1976), p. i.

Hubert S. Feild and William H. Holley, "The Relationship of Performance Appraisal System Characteristics to Verdicts in Selected Employment Discrimination Cases," Academy of Management Journal 25 (June 1982) pp. 392-406. A follow-up study was conducted for the period 1980-1983 and produced similar results. See Hubert S. Feild and D. T. Thompson, "Study of Court Decisions in Cases Involving Performance Appraisal," Bureau of National Affairs, Daily Labor Report, No. 248, December 26, 1984, pp. El -E5.

5.

6.

## Ronald G. Wells, "Guidelines for Effective and Defensible Performance

## Appraisal Systems," Personnel Journal 61 (October 1982), p. 777.

- 7. Wade v Mississippi Cooperative Extension Service, 372F. Supp. 126, 7 EPD

9186 (1974).

8.

Brito v. Zia Company, 478F. 2D. 1200 (1973).

9.

Latham and Wexley, op. cit., p. 73.

10.

Fred N. Kellinger, Foundations of Behavioral Research 2nd ed. (New York: Holt, Rinehart & Winston, 1964), Chapters 26 and 27 provide an in-depth discussion of reliability and validity.

- 11. Equal Employment Opportunity Commission, Civil Service Commission, Department of Labor and Department of Justice, "Uniform Guidelines on Employee Selection Procedures," Federal Register 43 (August 25, 1978), pp. 38290-38315. Latham and Wexley, op. cit., p. 73.

- 13. Wells, op. cit., p. 777.

12 J

5,

# Characteristics

- 14. Gary P. Latham, Kenneth N. Wexley, and Elliot D. Pursell, "Training Managers to Minimize Rating Errors in the Observation of Behavior," Journal of Applied Psychology 60 (October 1975), pp. 550-555.

- 15. Charles H. Fay and Gary P. Latham, "Effects of Training and Ratings Scales

## on Rating Errors," Personnel Psychology 35 (Spring 1982), pp. 105-1:6.

16.

Seleg M. Danzig. "What We Need to Know About Performance Appraisals,"

## Management Review 69 (February 1980), p. 21.

17.

# Biddle, op. cit., pp. 11-12.

- 18. Wells, op. cit.. p. 781. 19. William H. Holley and Kenneth M. Jennings, Personnel Management 2nd ed.

# (Chicago: Dryden, 1983), p. 612.

20.

See, for example, Board of Regents of Sta:e Colleges et al. v. Roth, 408 U.S. 564 (1972). Over the past 15 years, Roth has been followed by a long series of deci- sions in federal and state courts usually taking the side of the employee. Legal bases to sue include breach of contract, violation of public policy, "bad faith," and discrimina- tion. For a detailed review see Daniel M. Mackey, Employment at Will and Employer Liability, (New York: American Managment Association, 1986).

# 115

# Appendices

117

1 :..,' ,-,'

# Appendix A: Performance Appraisal Forms*

Appendix A contains case examples of performance appraisal forms designed for a variety of jobs within The Alabar: College System. The types of forms vary depend- ing on the different job category--support, administrative, or faculty. However, the basis for all appraisal instruments in detailed job analysis which categorizes job duties into major responsibility areas, or job domains. These domains are weighted based on frequency and importance of duCes. On each performance appraisal form appropriate job domains are listed along with their assigned weights. A five-point rating scale is employed throughout, with space designated for explanatory comments. At this point, the appraisal approach varies, depending on the type of job. Explanations of each exhibit will follow.

`Lxhibits 1-4 in this appendix were developed by Anne Smyth Stewart, M.Ed., Counse',.,, Student Development Services, Auburn University, AL 36849. Exhibit 5 in this appendix was developed by Deborah J. Miller-Wood, M.A., Graduate Research Associate, Department of Educational Foundations, Leadership, and Technology, Auburn University, AL 36849.

li

&..4 t...)

# 120

# Performance Appraisal

# Exhibit 1

The job of Library Technician at Southern Union State Junior College fai into the support category. Jobs in this group are appraised using the weighted responsibility aas as performance criteria. These are identified in Part II of the Performance ;Ipraisal Form and are defined using qualifying words that state "how" a set of duties is performed. The performance discussion and summary in Part III deals with factors that impact on the overall performance and should be self explanatory.

# PERFORMANCE APPRAISAL FORM

# PART I

# IDENTIFICATION

# Name

# Position

# Library Technician

# Rating Period From

# To

# Rater Name

# Rater Title

# Department

# Date Employed

# PART II

# RATING SCALES FOR MAJOR RESPONSIBILITIES

# A. Physicial Processing

PCT 35%

Creating and maintaining records, and correctly performing related tasks needed to facilitate locating and obtaining library :niter's's.

# B. Circulation

PCT 20%

Carrying out prescribed procedures, and accurately maintaining records regarding the borrowing of books and other materials by library users.

# C. Acquisition

PCT 15%

Ordering and receiving books, periodicals, and other materials. and recurately maintaining records

# D. Reference

PCT 10%

Assisting library users by providing information services, answering questions, assisting in locating library materials, and integrating information into cataloging system.

# E. Cataloging and Classification

PCT 10%

Accurately compiling Information and properly entering classifications of library materials, and integrating information into cataloging system.

# F. General and Administrative

PCT 10%

Carrying out administrative support services and activities in accordance with Institution policies and procedures.

# G

# PCT

# Appendix A

# 121

# Southern Union State Junior College

## Rating Scale Key F Fails to Meet Job Requirements

Essentially MeetsJob Requirements Fully Meets Job Requirements Meets Job Requirements with Distinction Exceeds Job Requirements

# RATING

# COMMENTS

# RATING

# COMMENTS

# RATING

# COMMENTS

# RATING

# COMMENTS

# RATING

# COMMENTS

# RATING

# COMMENTS

# RATING

0

2

0

# O

6

# Os

# COMMENTS

# 122

# Performance Appraisal

# PART III

# PERFORMANCE DISCUSSION AND SUMMARY

Does the employee report for and rer,iain at work as required? 0 yes 0 no

If no, please explain

Does the employee follow instructions and observe work rules? 0 yes 0 no

If no, please explain

Does the employee get along and cooperate with co-workers on the lob? 0 yes 0 no

# If no. please explain.

Does the employee hcve the knowledges, skills, abilities, and other qualifications needed rot successful lob performance? 0 yes 0 no

If no, please explain

Describe any specific actions employee needs to take to improve Job performance

Summarize this employee's overall lob performance as determined in your joint discussion

# PART IV

# SIGNATURES

This report :s Josed on my observation and knowledge of both the employee and the lob

My signature indicates that I have reviewed this appraisal It does not mean that I agree with the results

# Supervisor

# Date

# Reviewer

# Date

# Employeo

# Date

1 ' 'F...

../

# Appendix A

# Exhibit 2

The position of Director, Instructional and Student Development, is a state level administrative position. The sample Performance Appraisal Form shown is similar to that used in Exhibit 1, with key expectations included as an added dimension. Weighted job domains are entered on the form and defined in pc.:ormance-related terms. Key expectations for the rating period will have been entered from the previous review session when these were developed. Each of these areas is then rated against the five-point scale. Part III addresses factors which impact on the performance of the job but do not fall under specific duty statements. These are not rated on a scale; rather are discussed in narrative form. The remaining sections of this form are self-explanatory.

/ (1' '

,.

*

# 123

# 124

# Performance Appraisal

# PERFORMANCE APPRAISAL FORM

# Name

# Identification Number

# Title

# Director

## Division Instructional and Student Development

# Date Employed

# Date Assigned Present Job

# Rater Name

# Title

## Appraisal Period From This Appraisal Is - Annual_ Other

# To

# INSTRUCTIONS

## PART I PERFORMANCE RESPONSIBILI ry RATINGS

The position responsibilities are taken from the job description The rater appraises iesults achieved against responsibilities/

expectations by checking one of the five following degrees 5 - EXCEPTIONAL Performance which clearly exceeds work requirements and indicates an exceptional desire and ability to do

more than 13 reasonably expected in terms of professional quality. work output. or both

4 - VERY GOOD Performance which meets work requ rements with distinction and indicates a desire and ability to do a highly

# professional job

3- ACCEPTABLE Performance which lutly meets work requirements and indicates a desire and ability to do a thorough and

# competent lob

2 - MARGINAL Performance which essentially meets work requirements and indicates a desire and ability to be at least adequate

UNACCEPTABLE Performance which clearly fails to meet work requirements and indicates either a lack of ability or unwillingness to do what is reasonably expected

Read the definitions of each performance responsibility including the expectations or objectives which have been established. then appraise the person by one responsibility at a time Omit appraisal en any responsibility for which you believe your observation has been insufficient or which did not apply to the person Disregard your general impression of the person and concentrate on the performance responsibility definitions established Rate the person on his/her typical performance on that responsibility during the entire rating period

Raters can appraise performance on those criteria which the rater has regularly and directly observed or where there is objective evidence Ratings must be based on facts Do not be influenced by previous ratings While it is true that several responsibilities are related when you rate a person on one responsibility, you must disregard the ratingsyou have given him/her on other responsibilities For any factor which your appraisal is either UNACCEPTABLE or EXCEPTIONAL, justify with appropriate comments In addition, comments should be made for any rating if they will clarify your rating

# PART II PERFORMANCE FACTORS

Comment on each of the factors which influencea performance in as,igned responsibilities Use specific examples and, as appropriate, emphasize both strengths and areas needing improvement Comments should not focus on personality traits or personal habits but rather n how they translate into observed behaviors in getting the job done If a factor was not applicable during the rating period. leave it blank The performance factors, while not directly rated, are important in understanding how results were achieved and in identifying ways to improve performance in succeeding periods

# PART III SUMMARY PERFORMANCE STATEMENT

The Summary Performance Statement is a key pan of the performance appraisal

It should summarize the overall results, the

manner in which results were achieved, any special conditions which existed, and tha tread of performance PART IV STAFF MEMBER'S COMMENTS

In this section, the staff member should be encouraged to make specific comments on any aspect of NS/her performance appraisal,

# PART V SIGNATURES

Following the performance appraisal discussion, the rater and staff member will sign the appraisal form It will then be forwarded

## through channels to the Chancellor for review and signatures

1 (.0..1 ..,

# Appendix A

## PART I PERFORMANCE RESPONSIBILITY RATINGS

Enter performance responsibility areas from lob description and include relative importance Enter s andards. objectives. or other expectations for the rating period Make comments on observed job behaviors and results achieved Rate performance based on definitions provided

A Administration (25%) Effectively analyzing the situation to the Division. setting goals, and developing policies. operating

plans, and assignments, submitting accurate, timely reports

# KEY EXPECTATIONS FOR RATING PERIOD

# COMMENTS

2

3

4

# RATING

# B

Instructional Programs (20%) Providing instructional leadership for the system through coordination of Division staff and task forces in curriculum development and design, standa and program evaluation

## dizabon of courses, competency-based instructional approaches

# KEY EXPECTATIONS FOR RATING PERIOD

# COMMENTS

2

3

4

# RATING

C Supervisory Management (20%) Selecting, training, and appraising staff directing the activities of subordinates toward

the accomplishment of objectives, and promoting efficiency

# KEY EXPECTATIONS FOR RATING PERIOD

# COMMENTS

2

3

4

# RATING

# D

Liaison and Special Services (15%) Effectively representing the Chancellor and the department in official matters, performing other related services as assigned

# KEY EXPECTATIONS FOR RATING PERIOD

# COMMENTS

2

3

4

# RATING

# E

Faculty/Staff Policies and Development (10%) Developing and maintaining policies for faculty, staff at all institutions, providing opportunities and a structure though which instructors

can increase or improve ciedenbals, skills and abibties

# KEY EXPECTATIONS FOR RATING PERIOD

# COMMENTS

2

3

4

# RATING

F Student Services (10%) Providing leadership for student services though the professional staff of the Division and

# through student services departments at

# each institution

# KEY EXPECTATIONS FOR RATING PERIOD

# COMMENTS

2

3

4

# RATING

5

5

5

5

5

5

# 125

# 126

# Performance Appraisal

# KEY EXPECTATIONS FOR RATING PERIOD

# COMMENTS

# RATING

2

3

4

# ECODC

1

# KEY EXPECTATIONS FOR RATING PERIOD

# COMMENTS

# RATING

2

1

# CC C

3

4

# PART II PERFORMANCE FACTORS

Comment on each of the factors which influenced per ormance of assigned responsibilities and how they translated into observeo behaviors

# FACTOR

# COMMENTS

Sell Development and Appraisal How effectively this person analyzes own perf °mance, strengths and weaknesses accepts constructive Cr tiCism, particIpateS in relevant education experiences, reads tobrelated literature, keeps up -to -date on new trends and developments and improves capabilitieS to meet changing job requirements

Administrative Skills How effectively this person recognizes priities, formulates Schedules, establisheS work objectives understands or defineS responSibiltieS, projects work needs organizes the work to be performed and in general avoids -Crisis" types of activities

Interpersonal Relations - How effectively this person interacts with superiors subordinates peers and external contacts in both favorable and unfavorable or Conflict situations

Oral Communications - How effectively this person verbally communicates information including using appropriate language, listening, overcoming barriers and obtaining feedback in situations involving either information transfer or persuasion

Written Communications - How effectively this person produces written material which is clear concise, expressed in .i logical and direct manner, correct in grammar and spelling, and presented in tne appropriate format and style

1

L.

..,'

5

# 5 C

# Appendix A

# PART Ill SUMMARY PERFORMANCE STATEMENT

Summarize Overall results manner in which results were achieved spec,ai conditions under which performance occurred developmental needs and trend of performance

# PART IV STAFF MEMBERS COMMENTS

Please use the space below to comment on any aspect of your performance appraisal

# PART V SIGNATURES

# Rater

# Signature

# Title

# Date

# Stan Member

have reviewed and discussed this performance appraisal with my superior i am aware Ihat I have the opportunity to comment on this performance apps aisal in writino and that my .ommenls will be.ome part of the record of this performance appraisal

# Signature

# Title

# Date

# Reviewers

# Signature

# Title

# Date

jn:: 're

# Title

# Date

# 127

# 128

# Performance Appraisal

# Exhibit 3

There are two forms used for the administrative position, Dean of Instruction. In the document entitled Performance Standards, each domain is broken clow n into sub- criteria for which performance standards are developed. These are written at the "meets standards" level as an anchor for the performance rating. The degree to which standards are met, exceeded, or not met will determine the rating assigned on the document entitled Performance Appraisal Form. For administrative positions at this level, setting annual objectives and assessing results are key parts of performance appraisal. Parts III and IV allow for future planning and for assessment of the previous year's objectives. The appraisal summary in Part V encourages a developmental, positive approach in disctbsing employee strengths and possible areas for improvement.

4..) ..,

# PERFORMANCE STANDARDS

# Job Title: Dean of Instruction

# Department.

# Administration

# Job Domain

# A

# Planning (20%)

# B Organizing (10%)

# C

# Staffing (10%)

# D

# Leading and Directing (25%)

# Appendix A

# 129

# UnionState

# 141Southern

# Junior College

# Performance meets standards when

2

Long-Range Plans Analysis is made of situation and needs, measurable objectives are established, and appropriate plans are developed. Policies and Procedures Written policies, directives, handbooks, and procedures are developed and communicated in all academic and areas

3 Academic Calendar and Schedules All day and night programs, including off-campus centers, are scheduled in a cost-effective manner, with consideration for space utilization of students and qualifications and preferences of faculty members Budget Development of academic budget is accomplished based on appropriate guidelines and submitted on or before deadlne, adequate budgetary control procedures are established

4

5 Accreditation Action plans are developed to meet or maintain accreditation standards of the Southern Association of Colleges and Schools (SACS) and other accrediting agencies

1 Organizational Structure Academic organizational structure is developed and implemented Organization facilitates accomplishment of objectives

2 Committees Approp-iate standing and ad hoc committees are established and charged Committees carry out prescribed functions and make scheduled reports

2

3

Planning and Analysis Adequate human resource planning for academic program is accomplished, all jobs are periodically analyzed, and comprehensive job descriptions are maintained Personnel Functions Recruiting, selection, development, appraisal, and compel ,sation functions for academic, administrative, and support positions are carried out in accordance with prescribed procedures Legal Requirements All personnel procedures are validated in accordance with current EEO laws and guidelines

1 Overall Leadership Policies, procedures, rules. directives, and instructions are clearly communicated to subordinates at all levels, administrators. chairpersons, and supervsors at all levels use interpersonal influence, lead by example. and promote teamwork, a climate is established where academic administrative staff and faculty are motivated in work toward objectives, developing problems are identified and expeditiously resolved at lowest possible level in organizational structure, and progressive discipline is used, employee rights to due process are protected, and procedures are followed in all cases

# page 1 of 2

# 130

# Performance Appraisal

# E Controlling and Reporting (20%)

1 Concurrent Control Key indicators of performance are established and activities are monitored in all academic areas, corrections are made where necessary Feedback Control Accomplishments are compared against plans and standards at end of performance/budget cycle Analysis is made of any failure to accompl,sh planned results and appropriate action is taken

2

3 Reports All regular and special reports are accurately prepared and submitted on time Information from reports is analyzed and used in planning process

# F

# External Affairs (10%)

1

Public Relations Good public relations are maintained with community, legislative delegations, and other educational institutions to encourage maximum contribution by external groups to college objectives

2 Representation A positive image of the college is projected

# G Professional

# Development (5%)

2

Credentials Incumbent holds appropriate terminal degree Self-Development Adequate current knowledge of professional matters is maintained through attendance of meetings of professional associations, journals, workshop attendance, and personal study

# Page 2 of 2

# PERFORMANCE APPRAISAL FORM

# PART I

# IDENTIFICATION

## Name Position Rating Period From Rater Name Rater Title Department Date Employed

# Dean of Instruction

# PART II

# RATING SCALES

# Performance Standards For

# A Planning

# Long-Rangc Plant

2

# Policies and Procedures

3

# _Academic

# Calendar and Schedules

4

5

# Budget Accreditation

# Performance Standards For

# B Organizing

2

# Organizational Structure Committees

3 4

5

# Performance Standaids For C Staffi

# Planning and Analysis

2 3

# Personnel Functions

# Legal Requirements

4

5

## Performance Standards For 1::, Leading and Directifig_ pct

# Overall Leadership

2

# Academic Program

3 4

5

# To

# Pct

20%

2

# Pct iii% 1

2

# D

# Pct AO.%

2

_a%

2

0 0

# Rahn.

3

# Rah r

3

0

# Rat

3

# Rahn.

3

4

4

4

4

0

# El

# ifl

# Appendix A

## I SU Soalthern Union State Junior College

# Rating Scale Key

Fails to Meet Standards Essentially Meets Standards Fully Meets Standards Meets Standards with Distinction Enos& Standards

# Comments

# Comments

# Comments

# Comments

# 131

# 132

# Performance Appraisal

# Performance Standards For

# E Controlling and Reporting

# pct

# Concurrent Control

2 3 4

# Feedback Control

# Reports

5.

# Performance Standards For

# F

1 2

## External Affairs Public Relations Representation

# Pct

3

4

5

# Performance Standards For

# G Professional Development

# Pct

# Credentials

2

# SelfDevelopment

3 4

5

# PART III

# OBJECTIVES

# Key End Result

# Performance Assessment

# Key End Result

# Performance Assessment

# Rating

15%

0 0

2

1

3

4

0

0 0

0 0

0 0 0 0

0

# Rating

10%

2

3

4

50

0 0 0 0 0 0

# Rating

5%

0 0

1

2

3

4

5

0 0 0

0 0 0 0 0

1 c.-; J

# Comments

# Comments

# Comments

# Measure

# 4easure

# Key End Result

# Performance Assessment

# Key End Result

# Performance Assessment

# PART IV

# OBJECT:VE3NEXT REVIEW PERIOD

# Key End Result

# Key End Result

# Key End Result

# Key End Result

1.

# tc Id 'i

# Measure

# Measure

# Measure

# Measure

# Measure

# Measure

# Appendix A

# 133

# 134

# Performance Appraisal

# PART V

# DEVELOPMENTAL APPRAISAL SUMMARY

# PART VI

# SIGNATURES

This report is based on my observation and knowledge of both the employee and the Job

My signature indicates that I have reviewed this appraisal It does not mean that I agree with the results

# Supervisor

# Date

# Employee

# Reviewer

# Date

Copyright A 1985 by J A Buford IF 8 8 Burkhalter and Auburn Universdy Auburn AL 36849 All rights reserved

1 1,a

# Date

# Appendix A 135

# Exhibit 4

An expanded approach is used for the Faculty position at Southern Union State Junior College, with Observation Stales to be used in conjunction with the Perfor- mance Appraisal Form. In this case, descriptiN e statements are written to reflect typical behaviors at each level on the five-point scale rather than just at the number 3, "meets standards" level. Therefore, a department head completing this form on a faculty member will need to read through the scales for each criteria to locate the description best suited to the observed performance. Parts IV and V of the Performance Appraisal Form are self-explanatory.

# 136

# Performance Appraisal

# Observation Scales for

# Faculty Appraisal

# and

# Development

# Southern Union State Junior College

# Appendix A

## A. Instructional Planning and Preparation

- 1. Course Development Researches literature in subject area, develops and main- tains course outlines, selects textbooks and other teaching aids.

5 Exceptional Assumes a leadership role in divisional planning meetings and other aspects of curriculum development, suggesting additional course offerings and/or modifications in current offerings. Care- fully researches literature and attends workshops focusing on curriculum/course development, learning resources, and subject area matters. Serves as a resource person in subject area and offers suggestions to colleagues regarding textbooks and other learning resources.

# 4 Very Good

Takes an active role in divisional planning meetings regarding curriculum or course development. Researches current literature. Shares information with colleagues. Updates course outlines and suggests ways to optimize format of course outlines.

# 3 Acceptable

Shares responsibilities in divisional planning meetings regarding course development. Prepares each quarter written course out- lines (syllabi) for courses taught, incorporating recent develop- ments in subject area and current methods of instruction. Submits outline on time to Dean's office. Makes suggestions re- garding textbooks and other teaching aids.

# 2 Marginal

Attends divisional planning meetings and participates without taking direct responsibility. Submits course outline to Dean's office with minimal or no changes from previous years. Provides support for others' suggestions regarding textbooks and other teaching aids.

# 1 Unacceptable Misses or

irregularly attends divisional planning meetings. Assumes minimal or no responsibility for completing course out- lines. Demonstrates limited interest in using textbooks or other resources.

2.

# Instructional Planning Makes necessary preparations for classroom lectures, demonstrations or laboratory presentations.

5 Exceptional Develops, maintains, and previews additional resources, such as films or tapes for reference, timing, and quality. Utilizes a variety of teaching methods and aids. Promotes sophisticated inquiry techniques and provides problem solving experiences emphasizing key concepts. Instructional time is optimally planned for benefit of students.

# 137

# 138

# Performance Appraisal

# 4 Very Good

Develops detailed notes and guides. Presentations are well planned emphasizing key concepts. Comprehensively integrates lecture, etc. with textbook and/or other curricular materials. Instructional time and variety of material is planned for benefit of students.

# 3 Acceptable

Develops outlines and notes to ensure that key concepts are emphasized; that textbooks and other materials are integrated. Instructional time is wisely used. Comes to class prepared with necessary materials for classroom instruction.

# 2 Marginal

Reviews topic(s) to be covered. Outlines presentation or instruc- tional activity so that instructional time is not wasted. Usually is prepared with materials necessary for class instruction.

# 1 Acceptable

Reflects minimal or no preparation in instructional performance. Primarily relies on textbook, outdated notes, and/or student input for class content. Arrives at class unprepared without instruc- tional materials necessary for presentation.

- 3. Clinical Preparation (Nursing) Provides for efficient and effective utilization of the clinical facility and staff.

5 Exceptional Meets regularly with clinical staff or head nurse to promote a productive working relationship. Respects all levels of clinical staff. Exhibits interest and implements strategies to improve and facilitate optimal clinical experiences for students. Carefully assesses how each student's learning needs are being met by clinical experiences and arranges for modifications as necessary. Possesses thorough knowledge of facility's system, routines, procedures, and regulations.

# 4 Very Good

Maintains frequent contact with facility staff to ensure positive working relations. Is sensitive to the reciprocal relationship between the clinical facility and nursing program. Actively follows student progress within program. Respects and follows facility's routine, procedures, and regulations.

3 Acceptable Maintains adequate communication with facility staff. Monitors student ' progress within program. Knows and follows facility's routine, procedures, and regulations.

# 2 Marginal

Communications are limited with facility staff. Follows through with experiences planned by course coordinator. Seeks assis- tance or information from staff on occasion regarding facility's routine, procedures, and regulations.

# Appendix A 139

1 Unacceptable Communications are rare with facility staff. Lacks a working knowledge about facility's routine, procedures, and regulations. Fails to seek or consider feedback from students on effectiveness of clinical experiences.

- 4. Clinical Planning (Emergency Medical Technician-EMT) Plans experiences and assignments within clinical facility.

# 5 Exceptional

Acts as a facilitator to clinical staff to update plans for clinical experiences. Researches to discover innovative ways to improve and further facilitate positive clinical experiences for students. Carefully assesses how each student's needs are met through the experiences and assignments completed in the facility. Modifies experiences or assignments of students as deemed necessary.

# 4 Very Good

Maintains frequent contact with clinical supervisor to ensure productive working relationship. Is sensitive to the reciprocal relationship between the facility and the program. Monitors student progress throughout the quarter by encouraging feedback from supervisor student performance and experiences. Encourages input from students on possible improvements in clinical experiences.

# on

# 3 Acceptable

Holds necessary meetings with supervisor in clinical facility to plan assignments, experiences. and schedules in order to promote students' development and attainment of course objectives. Monitors student progress throughout the quarter.

# 2 Marginal

Maintains minimal communications with supervisors in clinical facilities. Plans for students' clinical experiences, but relies predominantly on the facility staff to dictate experiences. Usually schedules appropriate assignments. Accepts student feedback on occasion.

# I Unacceptable

Communicates rarely with supervisors in clinical facilities. Fails to plan appropriate clinical experiences or relevant assignments. Discourages student feedback in clinical activities.

# B. instruction

- 1. Schedule and encourages and

# Attendance records class attendance.

Teaches classes as scheduled or requested, and

# 5 Exceptional

Rarely fails to meet class. Begins and ends class promptly to ensure for maximum instruction time. Conducts class for entire

# 140

# Performance Appraisal

scheduled time. Adheres strictly to college's policy on atten- dance and records absences daily. Willingly accepts teaching assignments and responsibilities as scheduled.

# 4 very Good

Almost always meets class for full time period. Arrives early to class to ensure that instruction can begin on time. Encourages attendance throughout the quarter and records daily attendance. Willingly accepts teaching assignments as scheduled.

# 3 Acceptable

Usually meets classes. Reminds students of attendance policy. Records daily attendance. Accepts teaching assignments as scheduled.

# 2 Marginal

Occasionally fails to meet class. Dismisses students early from class. Explains attendance requirements at beginning of quarter. Fails to keep daily attendance, but has a general idea of who misses class. Usually accepts teaching assignments.

1 Unacceptable Occasionally fails to meet class without notifying students. Fails to begin and end classes promptly. Does not encourage or record daily attendance. Accepts teaching assignments after a con- frontation.

- 2. Methods of Instruction/Content Knowledge

Presents lectures, demonstrations, or provides laboratory supervision using appropriate methods of instruction and resources. Provides out-of-class assistance when necessary.

5 Exceptional Uses a variety of methods, aids, and resource people as part of presentations. Identifies objectives clearly and teaches to fulfill the objectives. Demonstrates mastery and comprehensive knowledge in subject area. Encourages student involvement. Stimulates and maintains student interest. Solicits students to investigate coursework outside of class.

# 4 Very Good

Uses a variety of methods and aids to increase students' interest. Teaches to specific objectives thereby wisely using class time. Exhibits conceptual knowledge in subject area. Presents mate- rials which enhance instruction and student learning. Involves students in presentations. Assists students outside of class when needed.

# 3 Acceptable

Varies method of presentation to increase interest. Establishes class objectives. Demonstrates knowledge of subject. Encourages student participation. Encourages students to seek additional help outside of class.

# student

# Appendix A 141

# 2 Marginal

Generally uses same method of presentation. Occasionally loses sight of objectives during class time. Demonstrates knowledge in subject area. Presents essential information. Answers student questions, but fails to involve students in presentations. Is avail- able for outside help when needed.

# 1 Unacceptable

Strays from subject matter during classes. Exhibits minimal knowledge of subject matter. Discourages student participation. Unavailable to students seeking help outside of class.

- 3. Presentation of Instruction Provides formalized verbal instruction to students.

# 5 Exceptional

Demonstrates exceptional verbal communications with students. Gains students' attention quickly. Usually presentations are both captivating and highly informative. Instructional style is praised by students and is conducive to student learning.

# 4 Very Good

Demonstrates excellent classroom presence. Communicates using a wide range of verbal skills which greatly enhance the learning environment. Students look forward to his/her classes. Students respond to instructional style gaining conceptual knowl- edge of material.

# 3 Acceptable

Presents information with adequate verbal skills. Maintains students' attention. Students gain essential information.

# 2 Marginal

Communicates information but to regularly maintain students' attention. Students gain essential information. Slow to adjust instructional style to needs of students.

# fails

# 1 Unacceptable

Presentations are less than adequate due to lack of preparation, confusion, poorly modulated voice, monotony, grammatical errors, distracting mannerisms, etc. Learning is an ordeal for students. Fails to monitor and adjust teaching style to encourage student attentiveness.

- 4. Student Evaluation

## Provides opportunity for student evaluation of course and

## instructor, reviews evaluations, and utilizes results.

# 5 Exceptional

Serves as a resource person or exhibits leadership in developing or refining evaluation procedures. Attends workshops and con- ducts research related to student evaluations of instructors. In addition to the administration's quarterly evaluations, administers alternative forms of evaluations for more personal and specific feedback. Thoroughly reviews strengths and weaknesses as viewed by students.

# 142

# Performance Appraisal

# 4 Very Good

Assists administration in developing adequate evaluation proce- dures. Administers evaluations according to established proce- dures. Reviews results and takes steps to incorporate recommen- dations in future instructional endeavors so to minimize any weaknesses and capitalize on the strengths.

# 3 Acceptable

Administers student evaimions according to established proce- dures. Reviews results and uses feedback to improve teaching.

# 2 Marginal

Generally follows established procedures in process of evalu- ation. Fails to utilize the results of students' responses.

1 Unacceptable Fails to follow established procedures for students to evaluate

# course or instructor.

- 5. Pre and Post Clinical Conferences (Nursing)

Conducts pre and post conferences to prepare students for clinical experiences and to evaluate the day's activities.

5 Exceptional Assumes the role of a group leader in conducting pre and post conferences. Uses creative strategies for gaining students' atten- tion. Promotes an understanding of important concepts. Demon- strates exceptional ability to inspire creative thinking among students. Expectations include a sophisticated level of active student participation. Facilitates students to integrate subject matter knowledge and theory into practical application. Students look forward to conferences anti eagerly participate.

# 4 Very Good

Implements objective of the day by encouraging students' suggestions as to how the objective could be achieved. Makes an effort to involve all students. Uses post conference to follow through with the objective in practice. Maintains flexible format to include unforeseen situations that may occur.

# 3 Acceptable

Conducts pre and post conferences in a non-threatening, student- oriented atmosphere. Uses objective of the day to relate theory to practice and suggests possibilities of application to students. Elicits student input. Uses post conference to follow up on con- cepts introduced during the pre conference.

# 2 Marginal

Conducts pre conferences using a lecture format. Gives assign- ments and objective for the day. Elicits minimal student input and offers little discussion of how to meet the objective. Post conferences recount activities rather than tie experiences to objective.

# Appendix A

1 Unacceptable Conducts brief and/or incomplete pre and post conferences. Makes assignments for the day with no discussion of how objec- tive might be met. Atmosphere is teacher-directed with no student input or direction of how to meet the objective.

- 6. Clinical Instruction (Nursing) facility.

## Supervises and instructs students in clinical

5 Exceptional Demonstrates substantial expertise in clinical area. Demonstrates an up-to-date comprehensive knowledge base of clients' medical regimens. Manages own time wisely by organizing the environ- ment and situations for the benefit of both students and clients. Skillfully challenges students' higher order thinking skills and promotes an atmosphere of inquiry. Meticulously monitors students' activities with clients by clarifying, verifying, and amplifying students' assessment of the situation.

# 4 Very Good

Demonstrat s expertise in clinical area. Is up-to-date on clients' conditions at all times and knows clients' medical care plans. Efficiently organizes self and students to meet clients' needs and students' objectives. Maintains careful balance between eliciting responses from students and giving direct answers when neces- sary. Carefully monitors students' activities with clients. Veri- fies students' assessments of clients and assists students in clari- fying and refining their skills.

# 3 Acceptable

Demonstrates overall competence in clinical area. Knows clients' diagnoses and treatment regimens. Organizes self and students to meet the needs of clients within the clinical facility. Encourages students' to discover answers on own, but provides answers if necessary. Supervises students' activities with clients. Observes all invasive procedures and medications.

# 2 Marginal

Exhibits basic knowledge in clinical area. Is aware of clients' diagnoses and treatment regimens. Ineffectively organizes students in meeting clients' needs. Directly instructs students rather than elicitiflb -heir ideas. Casually supervises students' activities with clients.

1 Unacceptable Exhibits deficiencies in clinical knowledge. Is minimally aware of clients' diagnoses and treatment regimens. Is very disorga- nized, finding it difficult to supervise students and meet clients' needs. Inhibits students' thinking for themselves. Provides little supervision of students' activities with clients.

V

# 143

# 144

# Performance Appraisal

# C. Testing/Evaluation

- 1. Evaluation Development and Administration Develops and administers tests or other methods for measuring student achievement, and informs students of evalu- ation procedures and criteria.

5 Exceptional Develops tests or other procedures that utilize different item forms or data collection efforts which not only are congruent with the instructions being evaluated but which also tap students' strengths. Attends workshops aimed at improving evaluation methods. Elicits and considers students' input regarding evalua- tion format. Conducts reliability and validity studies of evalu- ation procedures.

# 4 Very Good

Carefully weighs different measures to ensure that evaluation data gathered is congruent with course objectives. Provides comfortable conditions for evaluations. Allows adequate time for test completion or assignments. Ensures that evaluation proce- dures are reliable and valid.

# 3 Acceptable

Uses a variety of methods besides tests for assessing student achievement/performance. Uses statistical methods of analysis when appropriate. Discusses methods of evaluation with students.

# 2 Marginal

Develops ment/performance. Informs students of procedures to be used.

# and uses

# tests

to measure

# students'

# achieve-

## 1 Unacceptable Utilizes subjective methods insufficient

to assess students' achievement/performance. Fails to inform students about evalu- ation procedures.

- 2. Feedback to Students Provides results and critiques tests and other evaluations, records scores and corrections.

# 5 Exceptional

Provides immediate feedback to students by reviewing tests or performance during class following administration. Grades and returns evaluations the next class day. Provides explanatory comments (on evaluation) to clarify answer. Critiques test in class, adjusts scores when appropriate. Allows students opportu- nities to defend their answers or opinions if appropriate. Provides information from test analysis to students.

# 4 Very Good

Usually returns class session. Explains scoring procedure. Reviews all items, adjust- ing for errors in scoring. Informs students of the range of scores and the appropriate descriptive statistics.

# evaluations/assignments by the next

le*

# Appendix A

# 3 Acceptable

Usually returns tests/assignments within one week. Answers any student questions. Does not review every item. Clarifiesareas of confusion and reteaches if necessary.

# 2 Marginal

Returns evaluation results before next evaluation with little explanation of scores and no critique. Allows students with questions to come by office or stay after class. Records scores.

I Unacceptable Feedback from evaluations is delayed. Fails to provide evalu- ation results before next evaluation. Neglects to regularly inform students of their progress during the course.

- 3. Final Exams an Grades - Files copies of examinations with Dean. Following exam schedule, computes final course grades and submits grades to Registrar.

5 Exceptional Always administers final exams according to schedule. Consis- tently files copy of all exams with Dean of Instruction before designated time. Computes final course grades and files these with the Registrar before designated time. Submits grade sheets and attendance reports for classes.

# 4 Very Good

Administers final exams according to schedule. Files on time copies of all exams with Dean of Instruction. After grading exams, computes final course grades and submits appropriate documents to Registrar before designated time.

# 3 Acceptable

Administers final exams usually adhering to schedule. Files copies of all exams with the Dean of Instruction. Submits course grades to Registrar by designated time.

# 2 Marginal

Administers final exams, other than during exam schedule. Fails to file copies of exams on time with the Dean of Instruction. Usually submits course grades to Registrar on time.

## 1 Unacceptable Administers little, if any, final evaluation procedure. Usually

## submits final course grades to Registrar late.

- 4. Pre and Post Clinical Conferences (Emergency Medical Technician-EMT) - Conducts pre and post clinical conferences to determine value of clinical experi- ences to students and assesses student progress.

# 5 Exceptional

Effectively uses clinical conferences as a way to know each student personally. Provides an atmosphere of professionalism. Is available for discussing clinical issues at times other than regular conference hours. Encourages students' self-appraisal of their clinical performance. Uses clinical evaluations as a medium

# 145

# 146

# Performance Appraisal

to build on students' strengths and concentrate on reducing any deficiencies.

# 4 Very Good Makes an effort

to hold pre and post conferences in an atmosphere of supportive learning rather than evaluation. Main- tains a flexible format in conferences in order to accommodate for any unforeseen situations that may occur. Actively assists students in discovering how to improve their decision-making skills.

# 3 Acceptable

Conducts necessary pre and post conferences. Encourages student input, offers support, gives advice, and redemonstrates skills when necessary. Thoroughly explains and follows through on clinical objectives. Demonstrates an acute interest in ,-,-:;,dents' perceptions of clinical experiences. Accepts sugges- tions for improvement.

# 2 Marginal

Conducts pre and post conferences as necessary to evaluate previous clinical experiences. Uses conferences to make assign- ments. Allows student feedback regarding their experiences.

1 Unacceptable Uses pre and post conferences chiefly for assignment purposes. Meets with students infrequently. Limits student input. Fails to critically evaluate feedback or consider alternate action.

# D. Student Affairs

- 1. Advising Assists students in cours- selection and career planning. Refers students to proper resources for personal counseling.

5 Exceptional Guides students to discover their own career goals and directions. Refers students to knowledgeable persons in area of career interest. Exhibits concern for students with personal problems and refers them for personal counseling. Contacts advisees who fail to attend sessions with faculty advisor.

# 4 Very Go-)d

Maintains communication with counselors reb ,rding possible programs to meet students' career or personal needs exhibits genuine professional interest in individual students and their mental health. Maintains confidentiality in all counseling matters. Keeps advisees informed of all commitments to program.

# ' Acceptable

Uses planned student program of study provided by the counselor to help advisee plan quarterly and/or yearly schedules. Exhibits knowledge of college and community resources for personal counseling and refers students appropriately.

# Appendix A

# 147

# 2 Marginal

Agrees to serve as student adviser when requested. Assists students in course selections. Is difficult for students to locate faculty member.

1 Unacceptable Fails to work with students on course selections. Recommends Is generally unavailable to

that students seek help elsewhere. students for career planning.

- 2. Extracurricular Activities Serves as a club sponsor for student organizations and participates in special campus activities.

# 5 Exceptional

Surveys student population to determine interests or needs not being met. Initiates and/or sponsors new school-wide activities and events. Organizes new student groups, publicizing and encouraging participation. Actively participates in extracurricu- lar activities or events.

# 4 Very Good

Sponsors or takes leadership role in a student club or organiza- tion. Engages in extracurricular activities or events as club spon- sor. Enconrages faculty and student participation in campus- wide events.

# 3 Areeptais".-

Sponsors events that involve student campus-wide extracurricular activities or events.

# faculty. Participates in

# 2 Marginal

Attends special campus-wide events occasionally. Assists with club or organization; if necessary, provides minimal leadership.

I Unacceptable Exhibits little interest in or information about student activities. Rarely attends special events. Fails to assist stuuent organiza- tions.

3.

Job Placement Writes letters of recommendation and otherwise assisting in job placement as requested.

# 5 Exceptional

Promptly writes letters of recommendation matching students' knowledge, skills, and abilities against requirements of particular jobs. Uses a wide variety of possible sources of career informa- tion. Calls and makes periodic visits to prospective employers to locate job opportunities.

4 Very Good Writes letters of re,Tnunendation, taking into account students' abilities. Uses various sources of career information. Continu- ously updates job announcements. Relays pertinent information to appropriate personnel.

# 148

# Performance Appraisal

# 3 Acceptable

Writes letters of recommendation upon request. Posts job announcements and makes oral announcements to groups of students in related fields where applicable.

# 2 Marginal

Writes requested letters of recommendation after some delay. Posts job announcements where applicable.

1 Unacceptable Refuses to write letters of recommendation for students. Lacks

# knowledge about area job opportunities.

# E. Administration

- 1. Personal Office Schedule Maintains office hours and posts and adheres to personal schedule.

# 5 Exceptional

Develops and posts a meticulous schedule. Adheres to time and duties specified on schedule. Posts whereabouts if not able to meet schedule. Always is prompt for classes and appointments. Routinely works on campus more than the 35 hours per week minimum.

# 4 Very Good

Develops and posts a detailed schedule. Usually follows sched- ule as posted. Meets classes and appointments on time. Works 35 hours or more per week on campus.

# 3 Acceptable

Posts schedule as required. Usually follows schedule and can be located when needed. Meets classes on time. Maintains 35 hours on campus per week minimum.

# 2 Marginal

Post schedule which denotes general rather than specific duties in blocks of time. Generally adheres to schedule. Is sometimes late for class. Usually maintains a minimum of 35 hours on campus per week.

# 1 Unacceptable

Fails to post hours and/or schedule. Difficult to locate during office hours. Arrives for class late. Works less than the 35 hours on campus per week minimum.

- ).

Administrative Responsibilities carries out official policies.

Performs administratie support tasks and

5 Exceptional Handles administrative responsibilities in an exemplary manner. Exceeds required or expected administrative performance stan- dards. Analyzes data from reports and makes recommendations. Assists in the development of policies. Contributes to the devel- "mem of reports, forms, records, and other materials.

1

r:

",

# Appendix A

# 4 Very Good

Consistently performs administrative responsibilities in a profes- sional manner. Makes special effort always to comply with offi- cial polices. Carefully checks reports and other requested materials for accuracy and usually submits them early.

# S Acceptable

Performs administrative responsibilities. Complies with official policies. Prepares accurate reports and other requested materials and submits them on time.

# 2 Marginal

Usually responsibilities. Generally complies with official policies. Submits reports and other requested materials occasionally improperly prepared.

# performs

requested

# administrative

# late or

I Unacceptable Neglects to perform required administrative responsibilities. Acts contrary to official policies. Submits late or poorly prepared reports and other requested materials.

- 3. Supply Economy Conserves expendable supplies and accounts for and takes care of equipment.

# 5 E.tceptional

Continuously practices supply economy. Maintains accurate inventory control records of assigned equipment. Reads techni- cal/operator manuals and arranges for preventive maintenance. Immediately attends to requests and follows up on needed repairs. Considers needs of others in using item of equipment. Always follows proper checkout and return procedures for equipment.

# 4 Very Good

Makes special effort to economize on supplies. Maintains inventory control records or assigned equipment. Promptly arranges for repairs and maintenance. Ensures that proper checkout and return procedures are followed.

# 3 Acceptable

Conserves supplies. Accounts for items of equipment. Reports needed repairs and maintenance. Follows proper checkout and return procedures.

# 2 Marginal

Generally conserves supplies. Can usually locate items of equipment. Fails to be knowiedgeable about necessary repairs and maintenance schedules. Normally, follows proper checkout and return procedures.

# I Unacceptable Wastes supplies.

Is unaccountable for loses or damages in equipment. Neglects to follow proper checkout and return pro- cedures.

# 149

# 150

# Performance Appraisal

4.

Interpersonal Communications Communicates and interfaces with colleagues and administration both on a one-on-one basis, in faculty committees, and in other group settings.

5 Exceptional Assumes proactive leadership role in all types of situations by providing innovative solutions and inspiration to others. Carries out and follows up on assignments. Resolves conflicts even in stressful situations. Is highly regarded and influential among colleagues.

# 4 Very Good

Assumes leadership role with individuals and groups. Attempts to resolve problems amicably. Carries out assignments promptly. Establishes relationships with colleagues.

# effective

# and

# productive

3 Acceptable Works effectively with individuals and groups. Attends neces- sary meetings. Offers suggestions to problems. Willingly accepts and carries out special assignments. Assumes collegial role.

# 2 Marginal

Usually works with individuals and attends meetings. Accepts and carries out special assignments when required. Conflicts with colleagues are rare.

1 Unacceptable Refuses to work with individuals. Absent from required meet- Is occasionally indifferent, antago-

ings. Refuses assignments. nistic, or disruptive. Conflict with colleagues occur.

# F. Professional Development

1.

Independent Self-Improvement Keeps informed of new information relating to subject area, including better teaching methods and techniques.

# 5 Exceptional

Maintains professional membership(~) and may hold a leadership position within Reads and researches information from professional Initiates research projects in area of specialty. Holds appropriate terminal degree. Pursues academic work beyond the terminal degree.

# professional

# a

# organization.

# journals.

# 4 Very Good

Maintains membership(s) in a pi ofessional organization. Seeks new sources of information and uses resources of organization to enrich knowledge of subject matter or techniques of instruction. Confers with faculty members in other schools, universities, or research institutions. Progresses toward attaining appropriate terminal degree.

# Appendix A

# 3 Acceptable

Seeks information in subject areas and keeps updated on latest developments in subject area or in related field. Holds appropri- ate master's degree in current subject area. Makes progress toward one year of advanced study in subject area.

# 2 Marginal

Reads material available through college in subject areas and in field of education. Holds appropriate master's degree in subject area of instruction.

1 Unacceptable Does little or no independent rea6,ng in subject area or teaching methods. Makes little or no progress toward eliminating noted deficiencies in subject area or in teaching methods and tech- niques.

- 2. Classes and Workshops

## Participates in programs, workshops, and classes to

## maintain credentials and competencies in subject area.

# 5 Exceptional

Organizes and/or leads special in-service programs or workshops in subject area. Stimulates interest in new area for possible study which addresses an identified need.

# 4 Very Good

F,epares and/or presents a segment of a workshop or program in subject area. Maintains professional credentials.

# 3 Acceptable

Attends and actively participates in programs, workshops, and classes designed for maintaining credentials and competencies.

# 2 Marginal

Participates in only those classes or programs mandatory for maintaining credentials.

I Unacceptable Refrains from participating in in-service programs, workshops, or advanced study to maintain credentials and competencies in subject area.

# G. Community Service

- 1. Extension Serves as a resource person in area of expertise for community organi- zations, businesses, or special events.

# 5 Exceptional

Provides major leadership for public service activities, commu- nity businesses, and organization upon request. Advises area businesses of possible services. Actively serves on organiza- tional boards for special events or programs. Takes responsibil- ity for special events in area of expertise. Analyzes area needs for possible new programs or events. Submits informative and

1 r L L:

# 151

# 152

# Performance Appraisal

timely news releases regarding relevant educational information and opportunities.

# 4 Very Good

Promotes and carries out public service activities. Serves on oi.ganizational boards for special events or programs. Submits informative and timely new releases regarding relevant educa- tional information and opportunities. Provides education to the public by writing newspaper articles on subjects of general interest and submitting them for approval.

# 3 A«.cptable

Carries out public service activities. Makes formal presentation in area of expertise to local clubs and organizations when requested. Provides information to media when appropriate to publicize programs or special events.

# 2 Marginal

Will usually attend community programs and share information in area of expertise. Submits necessary information to media when requested.

# 1 Unacceptable

Avoids participation in punt_ service or extension programs. Neglects to provide information to media when appropriate.

- 2. Commit) Rd of the community

ations Represents the institution and contributes to the welfare through participation in civic affairs.

# 5 Exceptional

Projects an extren,-ly positive image of the institution. Serves in a leadership capacity in several different areas of community life. May serve as chairperson for special events. Acts as stimulus for new ideas for improving quality of community life.

# 4 Ver.) Good

Is an asset to the institution. Maintains interest in several aspects of community life, taking a leadership role in at least one.

# 3 Acceptable

Positively represents the institution. Attends some community events, providing a supportive role in special area of interest. Carries out responsibilities when asked.

# 2 ,Marginal

Is not particularly identified with the institution. Attends some community events.

# I Una( ( eptable

Projects a negative image of the institution. Exhibits little or no interest or involvement in community activities.

# Appendix A

- 3. Continuing Education Instruction Teaches continuing education classes, keeps special groups updated on Emergency' Medical Technician (EMT) standards, and teaches skills and competencies to health professionals.

# 5 Exceptional

Works with area health professionals to develop new courses or revise old ones. Works on regional, state, or national committees to evaluate current teaching requirements and maintenance of credentials. Develops and teaches innovative and state-of-the-art material in classes. Communicates latest EMT standards.

# 4 Very Good

Writes letters, sends out brochures, or otherwise communicates with former students, clinical units, and college administration to keep them apprised of current EMT standards. Develops and teaches up-to-date information in classes.

# 3 Acceptable

Plans and teaches classes for health professionals to keep them proficient in EMT skills and competencies, in addition to teach- ing the required classes.

# 2 Marginal

Teaches the required minimum hours of continuing education classes in order to maintain EMT credentials.

# I Unacceptable

Teaches less than the minimum number of hours of continuing education classes to maintain EMT credentials.

# 153

# 154

# Performance Appraisal

# PERFORMANCE APPRAISAL FORM

# PART I

# IDENTIFICATION

# Name

# Posi.

# n

# Library Technician

# Rating Period From

# To

# Rater Name

# Rater Tdle Department

# Date Employed

# PART II

# RATING SCALES FOR MAJOR RESPONSIBILITIES

# A

# Physicial Processing

PCT 35%

Creating and maintaining revords, and correctly performing related tasks needed to facilitate locating and obtaining library materials.

# B Ciiculation

PCT 20%

Carry ng out prescribed procedures, and accurately maintaining reccrds regarding the borrowing of books and other materials by library users.

# C

# Acquisition

PCT 15%

Ordering and receiving books, periodicals, and other materials, and accurately maintaining records

# D

# Reference

PCT 10%

Assisting library users by providing information services, answering questions, assisting in locating library materials, and integrating information into cataloging system.

# E. Cataloging and Classification

PCT 10%

Accurately compiling information and properly entering classifications of library materials, and integrating information into cataloging system.

# F. General and Administrative

PCT 10%

Carrying out administrative support services and activities in accordance with institution policies and procedures

# G

# PCT

%

t...) L.)

# SU Southern Union State Junior College

# Rating Scale Key

# 5 Fails to Meet Job Requirements

# Essentially MeetsJob Requirements

## E Fully Meets Job Requirements Cl 1 Moots Job Requirements with

# Distinction Exceeds Job Requirements

# RATING

# COMMENTS

# RATING

# COMMENTS

# RATING

# COMMENTS

# RATING

# COMMENTS

# RATING

4

# COMMENTS

# RATING

# COMMENTS

# RATING

1-1

# ( OMMENTS

# II

..

# Appendix A 155

# PART III

# RATING SCALES FOR MAJOR RESPONSIBILITIES

# A INSTRUCTIONAL PLANNING AND PREPARATION

(10%)

# Rating 2 3 4

- 1. Course Development 2. Instructional Preparation 3. Clinical Preparation (Nursing) 4. Clinical Planning (EMT) Comments

# III

# III

# B INSTRUCTION

(50%)

# Rating 2 3 4

5

1 Schedule and Attendance 2 Method of Instruction 3 Presentation of Instruction 4 Student Evaluation 5 Pre and Post Clinical Conferences (Nursing) 6. Clinical Instruction (Nursing)

# Comments

# I I I il

# lil Eil

# bil

11

# H

# El

# C TESTING/EVALUATION

(10%)

# Rating 3 2

4

5

- 1. Evaluation Development and Administration 2. Feedback to Students 3. Final Exams and Grades 4 Pre and Post Chnecal Conferences (EMT) Comments

# fl

# D. STUDENT AFFAIRS

(10%)

# Rating 2 3 4

- 1. Advising 2 Extracurricular Activities 3 Job Placement Comments

c.... _,

# 156

# Performance Appraisal

# E ADMINISTRATION

(10%)

1 Personal Office Schedule 2. Administrative Responsibilities 3 Supply Economy 4 Interpersonal Communications

11:

# Comments

# F PROFESSIONAL DEVELOPMENT

(5%)

# Independent SelfImprovement

# 2 Classes and Workshops

# CI

# Comments

# G COMMUNITY SERVICE

(5%)

## 1 Extension 2 Community Relations 3 Continuing Education Instruction (EMT)

# Comments

# PART IV

# OBJECTIVES

## ACHIEVEMENT OF PERSONAL AND PROFESSIONAL (INCLUDING DIVISIONAL) OBJECTIVES

# OBJECTIVES NEXT REVIEW PERIOD

1C; J

# Rating 3 2

# Rating 3 2

# Rating 3 2

4

4

# lai

11111

4

5

5

5

# Appendix A 157

# PART V

# PERFORMANCE DISCUSSION AND SUMMARY

## DESCRIBE THE FACULTY MEMBER'S STRONG POINTS

# DESCRIBE ANY AREAS OF WEAKNESS

## DESCRIBE ANY SPECIFIC ACTIONS NEEDED TO IMPROVE PERFORMANCE

## SUMMARIZE OVERALL PERFORMANCE AS DETERMINED IN YOUR JOINT DISCUSSION

# PART VI

# SIGNATURES

This report is based on my observation and knowledge of both the faculty member and the job.

# Division Chair

# Date

My signature inetcates that I have reviewed this appraisal. It dof s not mean that I agree with the results

# Dean of Instruction

# Date

# Faculty Member

# Date

1 C,

# 158

# Performance Appraisal

# Exhibit 5

Exhibit 5 is a set of behavioral observation scales for the same faculty position. In this case the individual is observed and rated on a five-point Liken-type scale as to the frequency of the observed behavior. In completing the appraisal, the department head circles 1 if the individual has engaged in the behavior 0-64 percent of the time, 2 if 65- 74 percent, 3 if 75-84 percent. 4 if 85-94 percent, and 5 if 95-100 percent. A total score is determined by summing the responses to all behavioral items.

1 C

# Appendix A

## Behavioral Observation Scale (BOS) for Appraising Faculty

## A. Performance Dimension of 1 nstractio ial Planning and Preparation

Assumes a leadership role in divisional planning meetings and other aspects of curriculum development.

# Almost Never

1

2

3

4

5

# Almost Always

Shares responsibilities in divisional planning meetings regarding course develop- ment.

# Almost Never

1

2

3

4

5

# Almost Always

Makes valid suggestions regarding Lourse offerings and/o, modifications of current offerings.

# Almost Never

2

3

4

5

# Almost Always

## Serve.; as a resource person in specialty area to colleagues.

# Almost Never

1

2

3

4

5

# Almost Always

## Updates and submits course outlines (syllabi) on time to Dean's office.

# Almost Never

2

3

4

5

# Almost Always

Suggests way to improve current course/program offerings.

# Almost Never

1

2

3

4

5

# Almost Always

Selects and uses textbooks that currently reflect the latest technology and practices in the field.

# Almost Never

1

2

3

4

5

# Almost Always

Develops, maintains, and pro, um s additional resources, such as films or tapes for reference, timing, and quality.

# Almost Never

1

2

3

4

5

# Almost Always

Utilizes a variety of teaching methods and aids.

# Almost Never

2

3

4

5

# Almost Always

# 159

# 160

# Performance Appraisal

Develops outlines and notes which cover the key concepts of the course objectives.

# Almost Never

1

2

3

4

5

# Almost Always

Presentations are implemented emphasizing key concepts.

# Almost Never

1

2

3

4

5

# Almost Always

Comprehensively integrates lecture, etc. with textbook and/or other relevant curricular materials.

# Almost Never

1

2

3

4

5

# Almost Always

Lectures are planned to promote inquiry ana decision-making skills among students in order to solve problems.

# Almost Never

1

2

3

4

5

# Almost Always

Instructional times is optimally planned for benefit of students.

# Almost Never

2

3

4

5

# Almost Always

Arrives for class prepared with necessary materials for classroom instruction.

# Almost Never

1

2

3

4

5

# Almost Always

## Meets regularly with clinical staff or head nurse.

# Almost Never

1

2

3

4

5

# Almost Always

Interactions with facility staff reflects a mutual respect and appreciation of the clinical facility and nursing program.

# Almost Never

2

3

4

5

# Almost Always

;mplements strategies to improve and facilitate optimal clinical experiences for students.

# Almost Never

2

3

4

5

# Almost Always

Critically assesses students' progress with the clinical program.

# Almost Never

2

3

4

5

# Almost Always

Arranges and modifies clinical experiences in order to ensure that students' needs are being met.

# Almost Never

1

2

3

4

5

# Almost Always

1 C 1

# Appendix A

Possesses indepth knowledge of the facility's system.

# Almost Never

1

2

3

4

5

# Almost Always

Follows facility's routine, procedures, and regt.:' ons in clinical programs.

# Almost Never

1

2

3

4

5

# Almost Always

Acts as a facilitator to clinical staff in updating plans for clinical experiences.

# Almost Never

2

3

4

5

# Almost Always

Cor ducts meetings with supervisors in clinical facility to plan assignments, exp riences, and schedules in order to promote students' overall development and atlainment of course objectives.

# Almost Never

2

3

4

5

# Almost Always

Monitors student progress throughout the quarter by encouraging feedback from supervisors on students' performances and experiences.

# Almost Never

1

2

3

4

5

# Almost Always

## Modifies experiences or assignments of students as deemed necessary.

# Almost Never

2

3

4

5

# Almost Always

Promotes and actively works toward maintaining a program that ensures students of positive clinical experiences.

# Almost Never

2

3

4

5

# Almost Always

Assesses how clinical experiences and assignments are meeting students' needs.

# Almost Never

1

2

3

4

5

# Almost Always

Acknowledges input from students experil lice&

# as

a possible way to improve clinical

# Almost Never

2

3

4

5

# Almost Always

# Total

16,

# 161

# 162

# Performance Appraisal

# B. Performance Dimension of 1nso action

Meets class as scheduled.

# Almost Never

2

3

4

5

# Almost Always

Conducts class for full time period a scheduled.

# Almost Never

2

3

4

5

# Almost Always

## Encourages attendance throughout the quarter.

# Almost Never

2

3

4

5

# Almost Always

# Records daily attendance.

# Almost Never

1

2

3

4

5

# Almost Always

Accepts teaching assignments willingly as scheduled.

# Almost Never

2

3

4

5

# Almost Always

Notifies students in advance if class will be cancelled.

# Almost Never

2

3

4

5

# Almost Always

Makes alternate arrangements if class is not to meet.

# Almost Never

2

3

4

5

# Almost Always

Uses a variety of methods, aids, and resource peopleas part of presentations.

# Almost Never

2

3

4

5

# Almost Always

Establishes and teaches to clearly identified objectives.

# Almost Never

2

3

4

5

# Almost Always

Demonstrates mastery and comprehensive knowledge in subject area.

# Almost Never

2

3

4

5

# Almost Always

## Encourages student involvement and participation.

# Almost Never

2

3

4

5

# Almost Always

Stimulates and maintains student interest.

# Almost Never

2

3

4

5

# Almost Always

1 () u

# Appendix A

Involves students in presentations.

# Almost Never

')

4

5

# Almost Always

# Assists students outside of class

# Almost Never

2

3

4

5

# Almost Always

Lectures are presented at an appropriate volume, tone, and rate of speech.

# Almost Never

2

3

4

5

# Almost Always

Demonstrates excep:onal verbal Lommuncatons/rapport with students.

# Almost Never

1

2

3

4

5

# Almost Always

## Gains students' attention within the first five minutes of class.

# Almost Never

2

3

4

5

# Almost Always

Instructional style is praised by students.

# Almost Never

2

3

4

5

# Almost Always

When needed, modifies instructional style in order to maintain students' attention.

# Almost Never

2

3

4

5

# Almost Always

Students gain essential information.

# Almost Never

2

3

4

5

# Almost Always

Assists administration in developing adequate student evaluation procedures.

# Almost Never

2

3

4

5

# Almost Always

Serves ., a resource person or exhibits leadership in developing or refining student evaluation procedures.

# Almost Never

2

3

4

5

# Almost Always

Attends workshops and conducts researa in the area of student evaluations of faculty.

# Almost Never

2

3

4

5

# Almost Always

i G

# 163

# 164

# Performance Appraisal

Administers student evaluations according to established procedures.

# Almost Never

2

3

4

5

# Almost Always

Reviews results and uses student feedback to improve teaching.

# Almost Never

2

3

4

5

# Almost Always

Administers alternative forms of student evaluations, in addition to the administra- tion's quarterly evaluations in order to achieve more personal and specific feedback from students regarding course and faculty performance.

# Almost Never

2

3

4

5

# Almost Always

# Conducts pre and post atmosphere.

# conferences

# in

# a non-threatening student-oriented

# Almost Never

1

2

3

4

5

# Almost Always

Uses objective of the day to relate theory to practice.

# Almost Never

2

3

4

5

# Almost Always

Facilitates students' learning by integrating subject matter knowledge and theo y in practical application.

# Almost Never

2

3

4

5

# Almost Always

Elicits student input regarding clinical experiences and analysis of the day's activities.

# Almost Never

2

3

4

5

# Almost Always

When necessary, suggests possible clinical applications to students.

# Almost Never

2

3

4

5

# Almost Always

Uses post conferences to follow up on concepts introduced during the pre conference.

# Almost Never

2

3

4

5

# Almost Always

Assumes the role of a group leader in conducting pre and post conferences.

# Almost Never

2

3

4

5

# Almost Always

# Appendix A

Maintains a flexible format in conferences in order to address unforeseen situations that may occur.

# Almost Never

1

2

3

4

5

# Almost Always

Expectations include a sophisticated level of active student participation.

# Almost Never

1

2

3

4

5

# Almost Always

Demonstrates expertise in clinical aim

# Almost Never

1

2

3

4

5

# Almost Always

## Uses constructive time management techniques.

# Almost Never

1

2

3

4

5

# Almost Always

Demonstrates an up-to-date comprehensne knowledge base of clients' medical regimens.

# Almost Never

1

2

3

4

5

# Almost Always

Organizes the clinical environment to maximize efficientieffecthe service delivery.

# Almost Never

1

2

3

4

5

# Almost Always

## Establishes an atmosphere of higher-order inquiry among students.

# Almost Never

1

2

3

4 .-,

5

# Almost Always

Monitors /supervises students' activities With clients by clarifying, verifying, and amplifying students' assessments of the clinical situation.

# Almost Never

1

2

3

4

5

# Almost Always

# Encourages students' necessary.

to discover answers on (hut, but provides answers if

# Almost Never

1

2

3

4

5

# Almost Always

## Observes all invasive procedures and medications.

# Almost Never

2

3

4

5

# Almost Always

# Total

1 C6

# 165

# 166

# Performance Appraisal

## C. Performance Dimension of TestinglEvaluation

Uses a variety of methods besides tests for assessing student achievement/ performance.

# Almost Never

2

3

4

5

# Almost Always

Attends workshops to learn state-of-the-art in test and measurement techniques.

# Almost Never

2

3

4

5

# Almost Always

Elicits and considers students' input regarding evaluation format.

# Almost Never

2

3

4

5

# Almost Always

Assigns weights to assessment measures congruent with course objectives.

# Almost Never

2

3

4

5

# Almost Always

## Allows adequate time for test completion or assignments.

# Almost Never

2

3

4

5

# Almost Always

## Provides appropriate physical environment/conditions for evaluations.

# Almost Never

2

3

4

5

# Almost Always

## Conducts reliability and validity studies of evaluation procedures.

# Almost Never

2

3

4

5

# Almost Always

## Uses statistical methods of analysis in evaluations.

# Almost Never

2

3

4

5

# Almost Always

## Discusses methods of evaluation with students.

# Almost Never

2

3

4

5

# Almost Always

## Returns students' tests/assignments within one week.

# Almost Never

2

3

4

5

# Almost Always

Provides explanatory comment (on o aluation) to clarify appropriate response.

# Almost Never

2

3

4

5

# Almost Always

it:J J

# Appendix A

# Critiques tests in class.

# Almost Never

1

2

3

4

# ;i

# Almost Always

Answers student questions regarding evaluations.

# Almost Never

1

2

3

4

5

# Almost Always

Adjusts test scores to reflect actual credit earned V, hen appropriate .

# Almost Never

1

2

3

4

5

# Almost Always

Allows students opportunities to defend their ansm,ers or opinions.

# Almost Never

1

2

3

4

5

# Almost Always

Explains scoring procedures for evaluations.

# Almost Never

1

2

3

4

5

# Almost Always

# Informs students of the range of scores and the appropriate descriptive analysis.

# Almost Never

1

2

3

4

5

# Almost Always

## Provides clarification of test items which students question.

# Almost Never

1

2

3

4

5

# Almost Always

Administers final exams according to schedule.

# Almost Never

1

2

3

4

5

# Almost Always

## Files copies of all exams with the Dean of Instruction

# Almost Never

1

2

3

4

5

# Almost Always

Submits course grades to Registrar by designated time

# Almost Never

1

4

5

# Almost Always

## Conducts pre and post conferences in a professional atmosphere.

# Almost Never

2

3

4

5

# Almost Always

Is available to discuss clinical issues at times other than at regular conference hours.

# Almost Never

1

2

3

4

5

# Almost Always

'/

# 167

# 168

# Performance Appraisal

## Encourages students' self-appraisal of their clinical performance.

# Almost Never

1

2

3

4

5

# Almost Always

Uses clinical evaluations as a medium to build on students' strengths while concentrating on reducing any deficiencies.

# Almost Never

1

2

3

4

5

# Almost Always

Assists students in learning techniques to improve their clinical decision-making skills.

# Almost Never

1

2

3

4

5

# Almost Always

Encourages student input, offers support, gives advice, and redemonstrates skills when necessary to promote students' progress.

# Almost Never

1

2

3

4

5

# Almost Always

Explains and follows through on clinical experiences.

# Almost Never

1

2

3

4

5

# Almost Always

Accepts suggestions for improving clinical experiences.

# Almost Never

1

2

3

4

5

# Almost Always

Provides an atmosphere of supportive learning rather than evaluation.

# Almost Never

1

2

3

4

5

# Almost Always

Accommodates for any unforeseen situations by Lc:Wu Lung conferences within a flexible format.

# Almost Never

1

2

3

4

5

# Almost Always

Conducts clinical conferences to promote personal student-faculty relationships.

# Almost Never

1

2

3

4

5

# Almost Always

# Total

.11.

fr./ .

# Appendix A

## D. Performance Dimension of Student Affairs

Guides/counsels students to discover their on career goals and directions.

# Almost Never

1

2

3

4

5

# Almost Always

Maintains communications with counselors regarding possible programs to meet students' career or personal needs.

# Almost Never

1

2

3

4

5

# Almost Always

Uses planned student program of study pros ided by the counselor to help advise plan quarterly or yearly schedules.

# Almost Never

2

3

4

5

# Almost Always

Agrees to serve as student advisor as requested.

# Almost Never

2

3

4

5

# Almost Always

Refers students to knowledgeable persons in area of career interest.

# Almost Never

2

3

4

5

# Almost Always

Demonstrates a professional interest in students' mental health.

# Almost Never

1

2

3

4

5

# Almost Always

Refers students for personal counseling when counseling is warranted.

# Almost Never

2

3

4

5

# Almost Always

## Maintains confidentiality in all counseling matters.

# Almost Never

2

3

4

5

# Almost Always

## Exhibits knowledge of college and Lommunity resourLes for personal counseling.

# Almost Never

2

3

4

5

# Almost Always

## Continuously informs adkiees of responsibilities and Lormnitments to program.

# Almost Never

2

3

4

5

# Almost Always

Assumes a leadership role in a student club or organization.

# Almost Never

2

3

4

5

# Almost Always

# 169

# 170

# Performance Appraisal

Sponsors extracurricular events that involve students and faculty.

# Almost Never

1

2

3

4

5

# Almost Always

## Participates in campus-wide extracurricular activities or events.

# Almost Never

1

2

3

4

5

# Almost Always

Actively encourages faculty and student participation in campus-wide events.

# Almost Never

1

2

3

4

5

# Almost Always

Identifies student interests and needs not currently addressed in extracurricular activities.

# Almost Never

2

3

4

5

# Almost Always

Initiates new school-wide programs or organizes new student groups that further meet the interests and needs of the student population.

# Almost Never

1

2

3

4

5

# Almost Always

Writes letter of recommendation matching students' knowledge, skills, and abilities against requirements of a particular job.

# Almost Never

1

2

3

4

5

# Almost Always

Uses various sources of career information to locate job opportunities.

# Almost Never

1

2

3

4

5

# Almost Always

Calls and visits prospectie employers to identify potential new job opportunities.

# Almost Never

1

2

3

4

5

# Almost Always

## Routinely updates and immediately posts job announcements.

# Almost Never

1

2

3

4

5

# Almost Always

## Informs students of job opportunities in their field of endeavor.

# Almost Never

2

3

4

5

# Almost Always

# Total

0

41

i t:

# Appendix A

## E. Performance Dimension of Administration

Develops and posts detailed schedule.

# Almost Never

2

3

4

5

# Almost Always

Adheres to schedules as posted.

# Almost Never

2

3

4

5

# Almost Always

Posts whereabouts if not in office during scheduled office hours.

# Almost Never

2

3

4

5

# Almost Always

## Meets classes and schedules at designated time.

# Almost Never

2

3

4

5

# Almost Always

Routinely works on campus more than the 35 hours per week minimum.

# Almost Never

2

3

4

5

# Almost Always

Con,istently performs administrative responsibilities in a professional manner.

# Almost Never

2

3

4

5

# Almost Always

Exceeds required or expected administrative performance standards.

# Almost Never

2

3

4

5

# Almost Always

Prepares accurate reports ai.d other requested materials as requested.

# Almost Never

2

3

4

5

# Almost Always

Submits reports on time and completes other adnanistrativ c support tasks as scheduled.

# Almost Never

2

3

4

5

# Almost Always

# Complies with official policies.

# Almost Never

2

3

4

5

# Almost Always

Analyzes data from reports and makes recommendations.

# Almost Never

2

3

4

5

# Almost Always

1 '"-e

c..)

# 171

# 172

# Performance Appraisal

## Assists in the development of official policies, reports, forms, etc'.

# Almost Never

2

3

4

5

# Almost Always

Continually practices supply economy.

# Almost Never

1

2

3

4

5

# Almost Always

Notifies appropriate authority when certain expendable supplies are low.

# Almost Never

1

2

3

4

5

# Almost Always

## Maintains accurate inventory control records of assigned equipment.

# Almost Never

1

2

3

4

5

# Almost Always

## Follows proper checkout and return procedures for equipment.

# Almost Never

2

3

4

5

# Almost Always

## Follows preventative maintenance schedules for equipment.

# Almost Never

2

3

4

5

# Almost Always

## Reports and immediately arranges for repairs and maintenance.

# Almost Never

2

3

4

5

# Almost Always

Assumes a proactive leadership role in situations by prodding innovative solutions to problems.

# Almost Never

2

3

4

5

# Almost Always

Is viewed as a facilitator by colleagues and other administrators.

# Almost Never

2

3

4

5

# Almost Always

Maintains a professional and productive relationship with colleagues.

# Almost Never

2

3

4

5

# Almost Always

Attempts to resolve conflicts amicably among individuals and groups.

# Almost Never

2

3

4

5

# Almost Always

Promptly performs and follows up on assignments and commitments.

# Almost Never

1

2

3

4

5

# Almost Always

# Appendix A

# Attends necessary meetings.

# Almost Never

1

2

3

4

5

# Almost Always

# Total

0

## F. Performance Dimension of Professional Development

# Maintains membership(s) in a professional organization in area of specialization.

# Almost Never

1

2

3

4

5

# Almost Always

# Holds a leadership position within a professional organization in area of specialization.

# Almost Never

1

2

3

4

5

# Almost Always

## Reads and incorporates research from professional journals in academic work.

# Almost Never

1

2

3

4

5

# Almost Always

## Initiates research projects in specialty area.

# Almost Never

1

2

3

4

5

# Almost Always

Use resources of organization to enrich personal knowledge of subject matter or related techniques.

# Almost Never

1

2

3

4

5

# Almost Always

Pursues advanced academic coursework beyond current academic degree.

# Almost Never

1

2

3

4

5

# Almost Always

Maintains notarity in their field among colleagues on campus, at other institutions, and within the state.

# Almost Never

1

2

3

4

5

# Almost Always

Organizes and leads special in-service programs or workshops in subject area.

# Almost Never

1

2

3

4

5

# Almost Always

# 173

# 174

# Performance Appraisal

Assumes a leadership role in preparing/presenting a segment of a workshop or in- service program.

# Almost Never

2

3

4

5

# Almost Always

# Maintains professional credentials.

# Almost Never

2

3

4

5

# Almost Always

Attends and actually participates in programs, workshops, and glasses designed for maintaining credentials and competencies.

# Almost Never

2

3

4

5

# Almost Always

# Total

## G. Performance Dimension of Community Service

Provides major leadership for public service awl, ities, Lommunity businesses, and organizations upon request.

# Almost Never

2

3

4

5

# Almost Always

Performs public service activities through formal presentations to local clubs and organizations in area of expertise.

# Almost Never

2

3

4

5

# Almost Always

Actively serves on organizational boards for special events or programs.

# Almost Never

2

3

4

5

# Almost Always

## Analyzes community needs for possible new programs or eNents.

# Almost Never

2

3

4

5

# Almost Alwais

Submits inforrnatiNe and timely news releases publiLizing eduLational information, activities, and opportunities.

# Almost Never

2

3

4

5

# Almost Always

## Projects an extremely positive image of the Institution within the community.

# Almost Never

2

3

4

5

# Almost Always

t'''1 . La

'I

# Appendix A

# 175

Contributes to the xelfare of the community by partici;ating in en lc affairs.

# Almost Never

2

3

4

5

# Almost Always

Takes a leadership role in at least one civic organization.

# Almost Never

2

3

4

5

# Almost Always

Acts as a stimulus for new ideas to promote the welfare of the community.

# Almost Never

2

3

4

5

# Almost Always

Works with area health professionals to develop new Louses or revise old ones in the area of continuing education.

# Almost Never

2

3

4

5

# Almost Always

Works on regional, state, or national committees to evaluate current teaching requirements and maintenance of credentials.

# Almost Never

2

3

4

5

# Almost Always

Teaches innovative, state-of-the-art information in continuing education classes

# Almost Never

1

2

3

4

5

# Almost Always

Communicates the latest Emergency Medical Technician (EMT) standards to various health professional groups, former students, clinical units, and college administrators.

# Almost Never

2

3

4

5

# Almost Always

# Total

## Performance Dimensions for Appraising Faculty

# Totals

A.

# Instructional Planning and Preparation

B.

# Instruction

# C. Testing/Evaluation

# D. Student Affairs

# E. Administration

# F. Professional Development

# G. Community Service

# Overall Faculty Performance Total

## Appendix B: Checklist for Legal Requirements*

This appendix addresses the major considerations Involved in validating a perfor- It is in the form of a checklist It is not a comprehensive guide to conduct-

mance appraisal system using a content validity strategy for meeting minimum legal requirements. ing in-depth or quantitative studies.

- The Checklist for Legal Requirements was developed by James A. Buford, Jr. and Bettye B. Burkhalter, Auburn University, AL 36849.

177

1 (--) U

# Requirements

Determine if content validity strategy is appropriated

Avoid procedures based on traits or contstructs such as "intelligence, aptitude, personality, common sense, Judgement, leadership and spatial ability,"

"There should be a Job analysis which includes an analysis of important work behavior(s) required for successful Job performance and their relative importance and if the behavior results in a work product analysis of the work product(s)"

"A (performance appraisal) procedure designed to measure work behavior may be developed specifically from the loo or lop analysis in question "

# Checklist for Legal Requirements

# Authority

# 'Uniform Guidelines," Sec 14 (C) (1)

Uniform Guidelines, Sec 14 (C) (1) Wade v Mississippi Cooperative Extension Service, 372 F Supp, 126 (1974), 7EPD 9186

"Uniform Guidelines," Sec 14 (C)(2)Greenspan v Automobile Club of Michigan, 22 FEP 195 (1980) Albermarle Paper Co v Moody, U S Supreme Court Nos 74-389 and 74-128, 10 FEP Cases 1181, 1975

# 'Uniform Guidelines Sec 14 (C) (3)

# How Addressed

A content validity strategy is appropriate for procedures designed to measure observable work behavior(s) or work product(s)

No direct measurement of traits or constructs should be built into the system A trait may, however, be inherent in a job related behavior or outcome

Job analysis should be conducted for each lob Relative importance of lob domains, or task areas, should be established during Job analysis Frequency and criticality of tasks should be established during Job analysis

Domains indentified :n Job analysis can be defined in terms of acceptable level of lob performance

# or

Tasks or duties which are similar can be grouped together to form criterion areas

## Checklist for Legal Requirements (continued)

# Requirements

# Authority

# How Addressed

"To demonstrate content validity, a user should show that the behaviors demonstrated in the (performance appraisal) procedures are repre- sentative of behavior(s) work product(s) of the lob"

# "Uniform Guidelines," Sec 14 (C) (4)

Performance criteria should developed for critical and important duties in each domain and weighted in accordance with the overall importance of the domain

"The manner and setting of the (performance appraisal) procedure should closely approxi- mated the work situation."

# "Uniform Guidelines," Sec 14 (C) (4)

Performance criteria should be described in terms of actual lob conditions

The performance appraisal process should be administered under controlled and standardized conditions

Brito v Zia Company, 478 F 2d 1200 (1973) A performance appraisal instrument should be developed The instrument should facilitate the rating process and be keyed to both the criteria and method Provisions should be made for weighting the ratings according to the rules of combination Indentification, comments, and signatory sections should be included

A report or memorandum of how the system was developed should be prepared

Vulcan Pioneers, Inc v New Jersey Department of Caw, Service, 588 F Supp 732 (D C N J 1984) "Uniform Guidelines," Sec 15 (C)(1-9)

A content validity report should be prepared This report should include as a minimum user(s), locahon(s), and date(s), job analysis - content of the job, performance appraisal procedure and its content, relationship between performance appraisal procedure and the job, alternative procedures investigated, uses and applications, contact person, accuracy and completeness

Developed by James A Buford, Jr and Bettye B. Burkhalter (1988), Auburn, University, Alabama 36849

184;

# Andrews, Hans A., 7

Bailey, Catherine T., 52, 53 Baker, George, A., III, 104, 109 Baker, Robin Z., 8 Banks, Christina G., 65, 70, 82, 91 Beatty, Richard W., 41, 73, 76, 77, 84,

88, 89, 90, 91, 98

Belensky, Ann H., 45, 53 Bellman, Geoff, 63, 69, 70 Bemis, Stephen E., 45, 53 Bender, Henry E., 7, 40 Bennett, John B., 41, 63, 64, 70 Berk, Ronald A., 49, 50, 51, 53 Bernardin, H. John, 73, 76, 77, 84, 88,

89, 90, 91, 98

Biddle, Richard E., 47, 53, 114, 115 Borman, Walter C., 40, 53, 74, 89 Brawer, Florence B., 1, 7, 109 Buford, James A., Jr., 81, 90 Bureau of National Affairs, 8 Burke, Kenneth, 63, 70 Burns, Robert K., 91

Campbell, Donald T., 53 Champion, Cecilia H., 90 Chater, Shirley S., 41, 63, 64, 70 Clampitt, Phillip G., 57, 58, 64, 69, 70,

71

Cohen, Arthur M., 1, 7, 8, 109 Collins, Sonya T., 81, 90 Cousins, Norman, 57, 69 Cronbach, Lee J., 53 Cummings, L. L., 41

# Danzig, Seleg M., 115

# Name Index

Darling-Hammond, Linda, 2, 8 Dawes, Robyn M., 48, 53 Drucker, Peter F., 33, 40, 78, 90 Duffy, John F., 53

# Eichel, Evelyn, 7, 40

Fagg, James N., 90 Fan, J. L., 41 Fay, Charles H., 115 Feild, Hubert S., 8, 18, 53, 114 Fine, Sidney A., 45, 53 Fiske, Donald W., 53 Flanagan, John C., 29, 40, 49, 53, 83,

84, 91

# Fralicx, Rodney D., 51, 53

Gatewood, Robert D., 8, 53 Gersherfield, Matti K., 71 Gharpode, Jai, 53 Gilbert, Thomas F., 1, 7, 39, 41 Gilford, J. P., 88 Goodall, H. Lloyd, Jr., 57, 58, 63, 69,

70

## Green, Samuel B., 90 Guoin, Robert M., 53

Harvey, L. James, 109 Haynes, Marion G., 40 Herzberg, Frederick, 114 Holley, William H., 18, 40, 80, 85. 90,

91, 114, 115

Jeanneret, Paul R., 53 Jennings, Kenneth M., 40, 80, 85, 90,

91, 115

-1 Lk, 181

# 182

# Performance Appraisal

Kavanagh, Michael J., 53 Kellinger, Fred N., 114 Kendall, Lorne M., 31, 40, 53, 79, 84,

90, 91

Kenn' Graham K., 53 Kesselman, Gerald A., 44, 53 Kiernan, Irene R., 41 Kikorski, John F., 69, 70 Kingdon, John W., 104, 109 Klasson, Charles R., 40, 43,53 Klett, C. James, 48, 53 Klimoski, Richard, 75, 77, 86, 87, 89,

91

Koontz, Harold, 105, 109 Kujawski, Carl J., 78, 80, 87, 89, 90, 91

Lahti, Robert G., 68 Laird, Angela, 57, 58, 64, 69, 70, 71 Landy, Frank, 41 Latham, Gary P., 32, 40, 58, 60, 68, 69,

78, 80, 87, 81, 90, 91, 114, 115

Lawler, Edward, 8 Lazar, Robert L., 40 Ledvinka, James, 8, 109 Licata, Christine M., 7 Liken, R., 65, 71 Litterer, Joseph A., 69, 70 Lonergan, Wallace G., 75, 76, 89 Lopez, Felix E., 44, 53 Lopez, Felix M., 44, 53 Lorr, Maurice, 48, 53 Luben, Gary L., 40, 43, 53

Mackey, David M., 18, 115 Marzano, William A., 7 Mausner, Bernard, 114 McCormick, Ernest J., 46, 53, 91 McCulloch, Kenneth J., 18 McConkey, Dale D., 40 McGregor, Douglas, 78, 89, 90, 104,

106, 109

McManis, Gerald L., 109 McNair, Douglas M., 48, 53 Meadows, Mark E., 69, -1, 71

/82

Mecham, Robert C., 53 Meier, N. R. F. 69 Miller, Donald W., 41 Mount, Michael K. 65, 71 Murphy, Kevin R., 65, 70, 82. 91

Nagle, Bryant F., 53 Napier, Nancy K., 58, 60, 68, 69 Napier, Rodney, 71 Nevo, Baruch, 53

## Odom, J. Vernon, 18 Osgood, Charles E., 53

Pearlman, Kenneth, 47, 53 i-t,ase, Sara R 2, 8 Preen, Erich P., 44, 53 Pursell, Elliot D., 115

Rapt, Nambury S., 51, 53 Redfern, George B., 105, 109 Ronan, William W., 85, 91, 99, 101 Roucche, John E., 104, 109

Sauser, William I., Jr., 79, 86, 89, 90,

91, 92, 96 Schneier, Craig E., 41 Schultz, Duane P., 80, 90 Schwab, Donald P., 41 Semen, Michael, 2, 7, 105, 109 Secolsky, Charles, 53 Seldin, Peter, 7 Silverman, Stanley B. 70, 90 Skopec, Eric Wm., 64, 68, 69, 70 Smallwood, Norman., 8 Smith, James L. 8 Smith, Patricia C., 31, 40, 51, 53, 79,

84, 89, 90, 91

Soder, Dee A., 45, 53 Stano, Michael, 58, 62, 63, 64, 66, 69,

70, 71

## Succi, George J., 53 Snyderman, Barbara B., 114

Taft, Ronald. 74, 89 Tannenbaum, Percy H., 53 Thompson, D. T., 18, 114 Thompson, Duane E., 40, 43, 53 Thompson, Paul 1-1., 8

Waagen, Christopher L., 57, 58, 63, 69,

70

Wells, Ronald G., 40, 114, 115 Wexley, Kenneth N., 32, 40, 58, 60, 65, 66, 69, 70, 71, 75, 8 i, 89, 90, 91, 114, 115

Wikstrom, Walter S., 40 Wiley, W. W., 53 Wilkerson, L., 8 Wilson, Gerald L., 57, 58, 63, 69, 70 Wise, Arthur E., 2, 8

Young, Drew M., 78, 80, 87, 89, 90, 91

183

1.b,,

# Name Index

# 183

Accountability, 1-2, 73, 101, 104, 107 Adverse impact (see disparate impact) The Age Discrimination in Employment

# Act, 9

Albermarle v. Moody, 10 American Psychological Association,

# 47 Appraisal

communication factors in, 59-66 cost considerations, 38-39 development of criteria, 43-53, 112 effective and legally defensible, 111-

114

formative vs. summative, 2-3, 48 implementation, 103-109 legal aspects, 9-18 minimizing errors in, 73 purposes of, 2-5, 75-77 techniques, 19-36

# At-will Lability, 16-17, 105

Behaviorally anchored rating scales (BARS), 31-33, 38, 48, 75, 77, 79, 82, 93-94

# Behavioral expectation scales (BES)

(see BARS)

Behavioral observation scales (BOS),

32-33, 48 Bias (see Rating errors) Board of Regents v. Roth, 18, 115 Brito v. Zia Company, 9 Burden of proof, 12 Business necessity, 12

## Central tendency error Checklist methods, 28

185

# Subject Index

# Civil Rights Act, 1964 (also see Title

VII), 5, 9

# Cleveland Board of Education v.

# Loudermill, 18

# Communication

breakdown, 60 climate, 65-66 concepts, 59-62 feedback, 63-65 hierarchical, 63 human factors, 61 listening, 61-62 needs, 60-61 problems in, 62 transaction, 59-60

# Comparative methods of appraisals, 23-

27

Criterion (see Appraisal) Critical incident technique, 29, 49, 81-

83

Discrimination (see legal aspects) Disparate treatment, 10-12 Disparate impact, 10-15 Due process, 17, 113

Economic measures (see Appraisal, cost

# considerations)

# Equal Employment Opportunity

Commission (EEOC), 5, 9, 11, 12, 14, 20

complaints, "Guidelines," 6, 9. 10, 12, 14, 15, 17,

38, 47, 52, 110

## EEO liability, 10-14 Essay appraisals, 23

:it

# 186

# Performance Appraisal

Feedback (see communication) Forced choice rating, 28-29 Four-fifths rule, 11

## Graphic rating scales, 19-22 Greenspan v. Automobile Club of

# Michigan, 10

# Griggs v. Duke Power Company, 5, 9

Intent to discriminate, 10-12

Job analysis, 6, 10, 15-16, 20, 29, 33,

38, 44-48, 51, 52, 80, 81, 83, 106, 109-110

## Functional Job Analysis (FJA), 45 Guidelines Oriented Job Analysis

(GOJA), 45-46

# Position Analysis Questionnaire

(PAQ), 45-46

# Versatile Job Analysis System

# (VERJAS), 45

Knowledge of results (see communication)

# Management by objectives (MBO), 33-

36, 77

# McDonnell Douglas Corp. v Green, 18

Peer appraisal, 36-37 Performali-e standards, 29-30 Placement (see Appraisal-purposes of) Prima facie case, 12, 14

Ranking systems (see comparative

# methods)

# Raters

## selection of, 74-75 training of, 80-81, l' motivation of, 36-87, 93

Rater errors, 6, 36, 53, 71-72, 76, 78,

79, 86, 90, 106

186

# Ra'tng scales

development of, 48-53 measurement considerations, 52-53 weighting, 51-52 Reliability, 48, 50, 51-53 Sell appraisal. 37 Shakedown administration, 106 Supervisory appraisal, 36 Systemic discrimination (see disparate

# impact)

Tests, 3, 9, 14, 44, 75, 99, 103, 110 Texas Dept. of Community Affairs v.

# Burdine, 18

Theory X and Theory Y, 104 Tide VII (also see Civil Rights Act), 5,

9, 10, 12, 15

Training (see Raters) Trait rating scales, 20, 21

# Uniform Guidelines (see EEOC)

Validity, 6, 14-15, 17, 20, 38, 44, 50,

51,52, 53, 84, 85, 105-106, 109, 110

# content, 14, 15 52, 109 convergent/discriminant, 53 cnterion-related, 52-53 face, 53

Wade v. Mississippi Extension Service,

10

Watson v. Fort Worth Bank and Trust,

18

## Yates v. Board 4 Regents of Lamar University System, 18

# About the Editors and Contributors

Bettye B. Burkhalter is Professor in the College of Education and Director of the Auburn University Economic Development Institute She teaches Personnel Adminis- tration courses at the graduate level and has had extensive expenence in private busi- ness and in industrial and governmental affairs. She received Ed.D. and Ph.D. degrees from The University of Alabama and was selected for the the Loree Research Award for her Ph.D. research in the area of Human Resource Management (HRM). Dr. Burkhalter has consulted widely with both public and industrial organizations in the area of performance appraisal.

James A. Buford, Jr. is Adjunct Professor in the College of Business and Management Scientist and Coordinator of Management Development, Cooperative Extension Service, Auburn University. He received a Ph.D. degree from The University of Georgia and is accredited by the Personnel Accreditation Institute. He has taught, con- ducted research, and consulted widely in the area of performance appraisal. Dr. Buford has designed legally defensible performance appraisal systems in both the public and private sectors.

Following are the affiliations of the other contributors appearing in Performance Appraisal. Concepts and Techniques for Postsecondary Education.

Richard J. Federinko is President of Southern Union State Junior College which enrolls 2,500 students at its three campuses. He received his Ph.D. degree in Higher Education Administration from Florida State University.

Mark E. Meadows is Professor and Head, Counseling and Counseling Psychology Department, in the Auburn University College of Education. He received his Ed.D. in Counseling and Student Personnel from The University of Georgia.

Edith A. Miller is an Associate Professor in the Department of Educational Founda- tions, Leadership, and Technology at Auburn University. She received her Ed.D. degree in Educational Psychology from The University of Georgia.

William I. Sauser, Jr. is Associate Vice President for Extension and Professor at Auburn University. He received his Ph.D. in Industrial/Organizational Psychology from the Georgia Institute of Technology.

,, 1. I, 4, I,

1, II, twiV1WIN.,

# ERIC Clearinghouse for Junior Col leges

187

tit i; 0 S

ItNi+1131,1444.4.0eK

44:1.^A,Ae

AtA^Ato1.5.4%.,44114,11V AtIA.JAMASAWYgOVAN